{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \ud83c\udfaf Backpropagation: Teaching the Network to Learn\n",
    "\n",
    "**The Most Important Concept in Deep Learning!**\n",
    "\n",
    "Welcome to what many consider the **hardest** topic in neural networks. But don't worry! We're going to break it down into tiny, digestible pieces using lots of analogies and visualizations. By the end, you'll understand how neural networks actually learn.\n",
    "\n",
    "---\n",
    "\n",
    "## \ud83d\udcd6 What We'll Learn\n",
    "\n",
    "1. **The Problem**: We know the error, but how do we improve?\n",
    "2. **Gradient Descent**: Finding the downhill direction\n",
    "3. **The Chain Rule**: The secret sauce of backpropagation\n",
    "4. **Backpropagation**: Working backward through the network\n",
    "5. **Implementation**: Building it from scratch\n",
    "6. **Common Issues**: What can go wrong\n",
    "\n",
    "---\n",
    "\n",
    "## \ud83e\udd14 The Problem: We Know We're Wrong, But How Do We Get Better?\n",
    "\n",
    "Imagine you're learning to throw darts:\n",
    "- You throw a dart \ud83c\udfaf\n",
    "- It misses the bullseye by 5 inches to the right\n",
    "- **You know you're wrong** (the dart missed)\n",
    "- **But HOW should you adjust your throw?**\n",
    "\n",
    "This is exactly where we are with neural networks:\n",
    "- We have a network that makes predictions\n",
    "- We calculate the loss (how wrong we are)\n",
    "- **But which weights should we change? And by how much?**\n",
    "\n",
    "**Backpropagation is the answer!** It tells us exactly how to adjust each weight to reduce the error.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np  # For numerical operations\n",
    "import matplotlib.pyplot as plt  # For creating visualizations\n",
    "from matplotlib.animation import FuncAnimation  # For animated plots\n",
    "from IPython.display import HTML  # For displaying animations in notebook\n",
    "from mpl_toolkits.mplot3d import Axes3D  # For 3D plots\n",
    "\n",
    "# Set random seed for reproducibility (so we get same results every time)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Configure matplotlib for better-looking plots\n",
    "plt.style.use('seaborn-v0_8-darkgrid')  # Nice looking plot style\n",
    "plt.rcParams['figure.figsize'] = (12, 6)  # Default figure size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## \ud83c\udfd4\ufe0f Part 1: Gradient Descent - Finding the Way Downhill\n",
    "\n",
    "### The Mountain Analogy \ud83c\udfd4\ufe0f\n",
    "\n",
    "Imagine you're **blindfolded** on a mountain and need to get to the bottom (lowest point). How do you do it?\n",
    "\n",
    "1. **Feel the ground around you** - which direction slopes down?\n",
    "2. **Take a step in that direction** - the steepest downward direction\n",
    "3. **Repeat** until you reach the bottom\n",
    "\n",
    "This is **exactly** what gradient descent does!\n",
    "\n",
    "- **Mountain height** = Loss (error)\n",
    "- **Your position** = Current weights\n",
    "- **Feeling the slope** = Computing gradients\n",
    "- **Taking a step** = Updating weights\n",
    "- **Bottom of mountain** = Minimum loss (best weights)\n",
    "\n",
    "### \ud83d\udca1 Key Insight\n",
    "\n",
    "The **gradient** tells us:\n",
    "1. **Direction**: Which way to move (uphill or downhill)\n",
    "2. **Steepness**: How steep the slope is\n",
    "\n",
    "To minimize loss, we move in the **opposite direction** of the gradient (downhill)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's visualize a simple loss curve (1D example)\n",
    "# Imagine this is the loss as we change one weight\n",
    "\n",
    "def simple_loss_function(weight):\n",
    "    \"\"\"A simple quadratic loss function: (weight - 3)^2\n",
    "    The minimum is at weight = 3\"\"\"\n",
    "    return (weight - 3) ** 2\n",
    "\n",
    "def gradient_of_loss(weight):\n",
    "    \"\"\"The gradient (derivative) of our loss function\n",
    "    This tells us the slope at any point\"\"\"\n",
    "    return 2 * (weight - 3)\n",
    "\n",
    "# Create a range of weight values\n",
    "weights = np.linspace(0, 6, 100)  # 100 points from 0 to 6\n",
    "losses = simple_loss_function(weights)  # Calculate loss at each point\n",
    "\n",
    "# Create the plot\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Plot 1: Loss curve\n",
    "ax1.plot(weights, losses, 'b-', linewidth=2, label='Loss Function')\n",
    "ax1.axvline(x=3, color='r', linestyle='--', label='Minimum (optimal weight)')\n",
    "ax1.set_xlabel('Weight Value', fontsize=12)\n",
    "ax1.set_ylabel('Loss (Error)', fontsize=12)\n",
    "ax1.set_title('Loss Curve: Our Goal is to Reach the Bottom', fontsize=14, fontweight='bold')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Gradient (slope) at different points\n",
    "gradients = gradient_of_loss(weights)\n",
    "ax2.plot(weights, gradients, 'g-', linewidth=2, label='Gradient (Slope)')\n",
    "ax2.axhline(y=0, color='r', linestyle='--', label='Zero gradient (minimum)')\n",
    "ax2.axvline(x=3, color='r', linestyle='--', alpha=0.5)\n",
    "ax2.set_xlabel('Weight Value', fontsize=12)\n",
    "ax2.set_ylabel('Gradient', fontsize=12)\n",
    "ax2.set_title('Gradient Shows Us Which Way is Downhill', fontsize=14, fontweight='bold')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\ud83d\udcca Understanding the plots:\")\n",
    "print(\"Left: The loss curve - we want to reach the minimum (red line)\")\n",
    "print(\"Right: The gradient at each point\")\n",
    "print(\"  \u2022 Positive gradient \u2192 slope goes uphill \u2192 move LEFT (decrease weight)\")\n",
    "print(\"  \u2022 Negative gradient \u2192 slope goes downhill \u2192 move RIGHT (increase weight)\")\n",
    "print(\"  \u2022 Zero gradient \u2192 we're at the minimum! \ud83c\udfaf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \ud83c\udfaf Quick Summary\n",
    "\n",
    "**Gradient**: The slope of the loss function. It tells us:\n",
    "- If **positive**: loss increases as weight increases \u2192 decrease the weight\n",
    "- If **negative**: loss decreases as weight increases \u2192 increase the weight\n",
    "- If **zero**: we're at a minimum! (could be local or global)\n",
    "\n",
    "---\n",
    "\n",
    "## \ud83d\udeb6 Taking Steps: The Learning Rate\n",
    "\n",
    "Now we know **which direction** to move. But **how big** should our steps be?\n",
    "\n",
    "This is controlled by the **learning rate** (often denoted as \u03b1 or lr).\n",
    "\n",
    "### \ud83d\udc22 Learning Rate Too Small\n",
    "- Baby steps\n",
    "- Very slow progress\n",
    "- Might take forever to reach the minimum\n",
    "\n",
    "### \ud83d\udc30 Learning Rate Too Large\n",
    "- Giant leaps\n",
    "- Might overshoot the minimum\n",
    "- Could bounce around and never converge\n",
    "- Might even make things worse!\n",
    "\n",
    "### \ud83c\udfaf Learning Rate Just Right\n",
    "- Moderate steps\n",
    "- Steady progress toward minimum\n",
    "- Converges efficiently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see gradient descent in action with different learning rates!\n",
    "\n",
    "def gradient_descent_1d(starting_weight, learning_rate, num_steps):\n",
    "    \"\"\"Perform gradient descent to find the minimum\n",
    "    \n",
    "    Args:\n",
    "        starting_weight: Where we start\n",
    "        learning_rate: How big our steps are\n",
    "        num_steps: How many steps to take\n",
    "    \n",
    "    Returns:\n",
    "        history: List of (weight, loss) at each step\n",
    "    \"\"\"\n",
    "    weight = starting_weight  # Current weight\n",
    "    history = []  # Track our journey\n",
    "    \n",
    "    for step in range(num_steps):\n",
    "        # Calculate current loss\n",
    "        loss = simple_loss_function(weight)\n",
    "        history.append((weight, loss))\n",
    "        \n",
    "        # Calculate gradient (slope) at current position\n",
    "        grad = gradient_of_loss(weight)\n",
    "        \n",
    "        # Update weight: move in OPPOSITE direction of gradient\n",
    "        # (because we want to go downhill, not uphill!)\n",
    "        weight = weight - learning_rate * grad\n",
    "    \n",
    "    return history\n",
    "\n",
    "# Try three different learning rates\n",
    "learning_rates = [0.01, 0.3, 1.5]  # Too small, just right, too large\n",
    "starting_weight = 0.5  # We all start at the same place\n",
    "num_steps = 20  # Take 20 steps\n",
    "\n",
    "# Create the plot\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
    "titles = ['\ud83d\udc22 Too Small (lr=0.01)', '\ud83c\udfaf Just Right (lr=0.3)', '\ud83d\udc30 Too Large (lr=1.5)']\n",
    "\n",
    "for idx, (ax, lr, title) in enumerate(zip(axes, learning_rates, titles)):\n",
    "    # Run gradient descent\n",
    "    history = gradient_descent_1d(starting_weight, lr, num_steps)\n",
    "    weights_hist = [w for w, l in history]\n",
    "    losses_hist = [l for w, l in history]\n",
    "    \n",
    "    # Plot the loss curve\n",
    "    weights = np.linspace(0, 6, 100)\n",
    "    losses = simple_loss_function(weights)\n",
    "    ax.plot(weights, losses, 'b-', alpha=0.3, linewidth=2)\n",
    "    \n",
    "    # Plot the path taken by gradient descent\n",
    "    ax.plot(weights_hist, losses_hist, 'ro-', linewidth=2, markersize=8, label='GD path')\n",
    "    ax.plot(weights_hist[0], losses_hist[0], 'go', markersize=15, label='Start')\n",
    "    ax.plot(weights_hist[-1], losses_hist[-1], 'r*', markersize=20, label='End')\n",
    "    \n",
    "    # Mark the true minimum\n",
    "    ax.axvline(x=3, color='purple', linestyle='--', alpha=0.5, label='True minimum')\n",
    "    \n",
    "    ax.set_xlabel('Weight', fontsize=11)\n",
    "    ax.set_ylabel('Loss', fontsize=11)\n",
    "    ax.set_title(title, fontsize=13, fontweight='bold')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.set_ylim(-0.5, 15)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\ud83c\udf93 What we learned:\")\n",
    "print(\"Left: Learning rate too small \u2192 slow but steady progress\")\n",
    "print(\"Middle: Learning rate just right \u2192 efficient convergence\")\n",
    "print(\"Right: Learning rate too large \u2192 overshooting and instability!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \u26a0\ufe0f Common Mistake\n",
    "\n",
    "**Don't forget to negate the gradient!**\n",
    "\n",
    "```python\n",
    "# \u274c WRONG - moves uphill!\n",
    "weight = weight + learning_rate * gradient\n",
    "\n",
    "# \u2705 CORRECT - moves downhill\n",
    "weight = weight - learning_rate * gradient\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## \ud83d\udd17 Part 2: The Chain Rule - Connecting the Dots\n",
    "\n",
    "Before we tackle backpropagation, we need to understand the **chain rule**. This is the mathematical tool that makes backpropagation possible.\n",
    "\n",
    "### \ud83d\ude97 Real-World Analogy: The Domino Effect\n",
    "\n",
    "Imagine you're planning a road trip:\n",
    "\n",
    "1. **Your driving speed** affects **distance traveled**\n",
    "2. **Distance traveled** affects **fuel consumed**\n",
    "3. **Fuel consumed** affects **total cost**\n",
    "\n",
    "```\n",
    "Speed \u2192 Distance \u2192 Fuel \u2192 Cost\n",
    "```\n",
    "\n",
    "If you want to know: **\"How does my speed affect my total cost?\"**\n",
    "\n",
    "You need to consider the **chain of effects**:\n",
    "- Speed affects distance (faster = more miles)\n",
    "- Distance affects fuel (more miles = more fuel)\n",
    "- Fuel affects cost (more fuel = more money)\n",
    "\n",
    "The chain rule lets us calculate this total effect by **multiplying** the individual effects!\n",
    "\n",
    "### \ud83d\udcd0 Simple Mathematical Example\n",
    "\n",
    "Let's use actual numbers to make this concrete:\n",
    "\n",
    "Suppose:\n",
    "- You drive at **60 mph** for **2 hours**\n",
    "- Distance = Speed \u00d7 Time\n",
    "- Cost = Distance \u00d7 $0.50 per mile\n",
    "\n",
    "**Chain**: `Speed \u2192 Distance \u2192 Cost`\n",
    "\n",
    "Let's calculate the derivatives (rates of change):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple chain rule example with numbers\n",
    "\n",
    "# Given values\n",
    "time_hours = 2  # We drive for 2 hours\n",
    "cost_per_mile = 0.50  # $0.50 per mile\n",
    "\n",
    "# Functions\n",
    "def distance(speed):\n",
    "    \"\"\"Distance = Speed \u00d7 Time\"\"\"\n",
    "    return speed * time_hours\n",
    "\n",
    "def cost(distance):\n",
    "    \"\"\"Cost = Distance \u00d7 Cost per mile\"\"\"\n",
    "    return distance * cost_per_mile\n",
    "\n",
    "# Let's evaluate at speed = 60 mph\n",
    "speed = 60\n",
    "d = distance(speed)  # Calculate distance\n",
    "c = cost(d)  # Calculate cost\n",
    "\n",
    "print(\"\ud83d\ude97 Forward Calculation (from speed to cost):\")\n",
    "print(f\"Speed: {speed} mph\")\n",
    "print(f\"Distance: {d} miles\")\n",
    "print(f\"Cost: ${c}\")\n",
    "print()\n",
    "\n",
    "# Now let's calculate derivatives (how much things change)\n",
    "print(\"\ud83d\udcca Derivatives (rates of change):\")\n",
    "print()\n",
    "\n",
    "# How does distance change with speed?\n",
    "# If speed increases by 1 mph, distance increases by time_hours miles\n",
    "d_distance_d_speed = time_hours\n",
    "print(f\"\u2202distance/\u2202speed = {d_distance_d_speed}\")\n",
    "print(f\"  \u2192 If speed \u2191 by 1 mph, distance \u2191 by {d_distance_d_speed} miles\")\n",
    "print()\n",
    "\n",
    "# How does cost change with distance?\n",
    "# If distance increases by 1 mile, cost increases by $0.50\n",
    "d_cost_d_distance = cost_per_mile\n",
    "print(f\"\u2202cost/\u2202distance = {d_cost_d_distance}\")\n",
    "print(f\"  \u2192 If distance \u2191 by 1 mile, cost \u2191 by ${d_cost_d_distance}\")\n",
    "print()\n",
    "\n",
    "# CHAIN RULE: How does cost change with speed?\n",
    "# We multiply the two derivatives!\n",
    "d_cost_d_speed = d_distance_d_speed * d_cost_d_distance\n",
    "print(\"\u26d3\ufe0f Chain Rule:\")\n",
    "print(f\"\u2202cost/\u2202speed = (\u2202cost/\u2202distance) \u00d7 (\u2202distance/\u2202speed)\")\n",
    "print(f\"\u2202cost/\u2202speed = {d_cost_d_distance} \u00d7 {d_distance_d_speed} = {d_cost_d_speed}\")\n",
    "print(f\"  \u2192 If speed \u2191 by 1 mph, cost \u2191 by ${d_cost_d_speed}\")\n",
    "print()\n",
    "\n",
    "# Verify with actual calculation\n",
    "print(\"\u2705 Verification:\")\n",
    "speed_plus_1 = speed + 1\n",
    "cost_plus_1 = cost(distance(speed_plus_1))\n",
    "actual_change = cost_plus_1 - c\n",
    "print(f\"Cost at {speed} mph: ${c}\")\n",
    "print(f\"Cost at {speed_plus_1} mph: ${cost_plus_1}\")\n",
    "print(f\"Actual change: ${actual_change}\")\n",
    "print(f\"Predicted change (chain rule): ${d_cost_d_speed}\")\n",
    "print(f\"Match! \u2713\" if abs(actual_change - d_cost_d_speed) < 0.01 else \"Mismatch \u2717\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \ud83d\udca1 Key Insight: The Chain Rule Formula\n",
    "\n",
    "If we have a chain: `A \u2192 B \u2192 C`\n",
    "\n",
    "To find how `C` changes with `A`, we multiply:\n",
    "\n",
    "$$\\frac{\\partial C}{\\partial A} = \\frac{\\partial C}{\\partial B} \\times \\frac{\\partial B}{\\partial A}$$\n",
    "\n",
    "In plain English:\n",
    "- **How C changes with A** = (**How C changes with B**) \u00d7 (**How B changes with A**)\n",
    "\n",
    "For longer chains: `A \u2192 B \u2192 C \u2192 D`, we keep multiplying:\n",
    "\n",
    "$$\\frac{\\partial D}{\\partial A} = \\frac{\\partial D}{\\partial C} \\times \\frac{\\partial C}{\\partial B} \\times \\frac{\\partial B}{\\partial A}$$\n",
    "\n",
    "**This is the foundation of backpropagation!**\n",
    "\n",
    "---\n",
    "\n",
    "## \ud83d\udd04 Part 3: Backpropagation - Putting It All Together\n",
    "\n",
    "Now we're ready for the main event! **Backpropagation** is just applying the chain rule systematically to a neural network.\n",
    "\n",
    "### \ud83e\udde0 The Neural Network Chain\n",
    "\n",
    "In a neural network, we have a chain like this:\n",
    "\n",
    "```\n",
    "Weights \u2192 Weighted Sum \u2192 Activation \u2192 Output \u2192 Loss\n",
    "```\n",
    "\n",
    "We want to know: **How does the loss change if we change a weight?**\n",
    "\n",
    "We use the chain rule, working **backward** from loss to weights:\n",
    "\n",
    "1. **Start at loss**: We know the error\n",
    "2. **Work backward**: How did each layer contribute to this error?\n",
    "3. **Assign blame**: Each weight gets a \"blame score\" (gradient)\n",
    "4. **Update weights**: Adjust weights to reduce their \"blame\"\n",
    "\n",
    "### \ud83d\udccb Step-by-Step: 2-Layer Network Example\n",
    "\n",
    "Let's build a tiny network and do backpropagation by hand!\n",
    "\n",
    "**Network Architecture:**\n",
    "- Input: 2 neurons (x\u2081, x\u2082)\n",
    "- Hidden layer: 2 neurons (h\u2081, h\u2082) with sigmoid activation\n",
    "- Output: 1 neuron (y) with sigmoid activation\n",
    "- Loss: Mean Squared Error (MSE)\n",
    "\n",
    "```\n",
    "Input     Hidden      Output\n",
    " x\u2081 \u2500\u2500\u2510   h\u2081 \u2500\u2500\u2510\n",
    "      \u251c\u2500\u2500\u2192    \u251c\u2500\u2500\u2192  y  \u2192 Loss\n",
    " x\u2082 \u2500\u2500\u2518   h\u2082 \u2500\u2500\u2518\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's implement activation functions and their derivatives\n",
    "# (We learned about these in Notebook 3!)\n",
    "\n",
    "def sigmoid(x):\n",
    "    \"\"\"Sigmoid activation function: squashes values to (0, 1)\"\"\"\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    \"\"\"Derivative of sigmoid: sigmoid(x) * (1 - sigmoid(x))\n",
    "    This tells us how fast sigmoid is changing at point x\"\"\"\n",
    "    s = sigmoid(x)\n",
    "    return s * (1 - s)\n",
    "\n",
    "# Visualize sigmoid and its derivative\n",
    "x = np.linspace(-6, 6, 100)\n",
    "y_sigmoid = sigmoid(x)\n",
    "y_derivative = sigmoid_derivative(x)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "ax1.plot(x, y_sigmoid, 'b-', linewidth=2, label='sigmoid(x)')\n",
    "ax1.set_xlabel('x', fontsize=12)\n",
    "ax1.set_ylabel('sigmoid(x)', fontsize=12)\n",
    "ax1.set_title('Sigmoid Activation Function', fontsize=14, fontweight='bold')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.legend()\n",
    "\n",
    "ax2.plot(x, y_derivative, 'r-', linewidth=2, label=\"sigmoid'(x)\")\n",
    "ax2.set_xlabel('x', fontsize=12)\n",
    "ax2.set_ylabel(\"sigmoid'(x)\", fontsize=12)\n",
    "ax2.set_title('Derivative of Sigmoid (needed for backprop!)', fontsize=14, fontweight='bold')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\ud83d\udca1 Why we need the derivative:\")\n",
    "print(\"During backpropagation, we need to know how the activation function\")\n",
    "print(\"contributes to the gradient. The derivative tells us this!\")\n",
    "print(\"Notice: derivative is highest around x=0, and very small for large |x|\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \ud83d\udd22 Numerical Example: Complete Forward and Backward Pass\n",
    "\n",
    "Let's do a complete example with actual numbers so you can see every step!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple 2-layer neural network with manual backpropagation\n",
    "# We'll use tiny numbers and print everything!\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"\ud83e\udde0 COMPLETE BACKPROPAGATION EXAMPLE\")\n",
    "print(\"=\"*60)\n",
    "print()\n",
    "\n",
    "# --- SETUP ---\n",
    "print(\"\ud83d\udccb SETUP\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Input (2 features)\n",
    "X = np.array([0.5, 0.8])  # Our input data\n",
    "print(f\"Input X: {X}\")\n",
    "\n",
    "# True output (what we want the network to predict)\n",
    "y_true = 1.0\n",
    "print(f\"True output: {y_true}\")\n",
    "print()\n",
    "\n",
    "# Weights (randomly initialized, but we'll use fixed values for clarity)\n",
    "# Weights from input to hidden layer (2x2 matrix)\n",
    "W1 = np.array([[0.1, 0.3],   # Weights from x1 to [h1, h2]\n",
    "               [0.2, 0.4]])   # Weights from x2 to [h1, h2]\n",
    "b1 = np.array([0.1, 0.2])     # Biases for hidden layer\n",
    "\n",
    "print(\"Weights input\u2192hidden (W1):\")\n",
    "print(W1)\n",
    "print(f\"Biases hidden (b1): {b1}\")\n",
    "print()\n",
    "\n",
    "# Weights from hidden to output layer (2x1 matrix)\n",
    "W2 = np.array([[0.5],   # Weight from h1 to output\n",
    "               [0.6]])   # Weight from h2 to output\n",
    "b2 = np.array([0.1])     # Bias for output\n",
    "\n",
    "print(\"Weights hidden\u2192output (W2):\")\n",
    "print(W2)\n",
    "print(f\"Bias output (b2): {b2}\")\n",
    "print()\n",
    "\n",
    "learning_rate = 0.5  # How big our weight updates will be\n",
    "print(f\"Learning rate: {learning_rate}\")\n",
    "print()\n",
    "\n",
    "# --- FORWARD PASS ---\n",
    "print(\"=\"*60)\n",
    "print(\"\u27a1\ufe0f FORWARD PASS (Input \u2192 Prediction)\")\n",
    "print(\"=\"*60)\n",
    "print()\n",
    "\n",
    "# Hidden layer\n",
    "print(\"\ud83d\udd35 Hidden Layer:\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Weighted sum at hidden layer: z1 = X \u00b7 W1 + b1\n",
    "z1 = np.dot(X, W1) + b1\n",
    "print(f\"Weighted sum z1 = X\u00b7W1 + b1\")\n",
    "print(f\"  = {X} \u00b7 {W1.T} + {b1}\")\n",
    "print(f\"  = {z1}\")\n",
    "print()\n",
    "\n",
    "# Activation: apply sigmoid\n",
    "h = sigmoid(z1)\n",
    "print(f\"Hidden activation h = sigmoid(z1)\")\n",
    "print(f\"  = sigmoid({z1})\")\n",
    "print(f\"  = {h}\")\n",
    "print()\n",
    "\n",
    "# Output layer\n",
    "print(\"\ud83d\udd34 Output Layer:\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Weighted sum at output: z2 = h \u00b7 W2 + b2\n",
    "z2 = np.dot(h, W2) + b2\n",
    "print(f\"Weighted sum z2 = h\u00b7W2 + b2\")\n",
    "print(f\"  = {h} \u00b7 {W2.T} + {b2}\")\n",
    "print(f\"  = {z2}\")\n",
    "print()\n",
    "\n",
    "# Final prediction: apply sigmoid\n",
    "y_pred = sigmoid(z2)\n",
    "print(f\"Prediction y_pred = sigmoid(z2)\")\n",
    "print(f\"  = sigmoid({z2})\")\n",
    "print(f\"  = {y_pred}\")\n",
    "print()\n",
    "\n",
    "# Loss calculation (Mean Squared Error)\n",
    "print(\"\ud83d\udca5 Loss Calculation:\")\n",
    "print(\"-\" * 60)\n",
    "loss = 0.5 * (y_pred - y_true) ** 2  # MSE\n",
    "print(f\"Loss = 0.5 \u00d7 (y_pred - y_true)\u00b2\")\n",
    "print(f\"     = 0.5 \u00d7 ({y_pred[0]:.4f} - {y_true})\u00b2\")\n",
    "print(f\"     = {loss[0]:.6f}\")\n",
    "print()\n",
    "\n",
    "# --- BACKWARD PASS (BACKPROPAGATION!) ---\n",
    "print(\"=\"*60)\n",
    "print(\"\u2b05\ufe0f BACKWARD PASS (Error \u2192 Weight Updates)\")\n",
    "print(\"=\"*60)\n",
    "print()\n",
    "\n",
    "print(\"\ud83c\udfaf Our goal: Calculate how much each weight contributed to the error\")\n",
    "print(\"Then adjust weights in the opposite direction!\")\n",
    "print()\n",
    "\n",
    "# Step 1: Gradient of loss with respect to prediction\n",
    "print(\"Step 1\ufe0f\u20e3: How does loss change with prediction?\")\n",
    "print(\"-\" * 60)\n",
    "dL_dy = y_pred - y_true  # Derivative of MSE: (y_pred - y_true)\n",
    "print(f\"\u2202Loss/\u2202y_pred = y_pred - y_true\")\n",
    "print(f\"              = {y_pred[0]:.4f} - {y_true}\")\n",
    "print(f\"              = {dL_dy[0]:.4f}\")\n",
    "print(\"This tells us if prediction is too high (+) or too low (-)\")\n",
    "print()\n",
    "\n",
    "# Step 2: Gradient at output layer (before activation)\n",
    "print(\"Step 2\ufe0f\u20e3: How does loss change with output layer weighted sum?\")\n",
    "print(\"-\" * 60)\n",
    "# Chain rule: dL/dz2 = dL/dy \u00d7 dy/dz2\n",
    "dy_dz2 = sigmoid_derivative(z2)  # Derivative of sigmoid\n",
    "dL_dz2 = dL_dy * dy_dz2\n",
    "print(f\"\u2202Loss/\u2202z2 = (\u2202Loss/\u2202y) \u00d7 (\u2202y/\u2202z2)\")\n",
    "print(f\"          = {dL_dy[0]:.4f} \u00d7 sigmoid'({z2[0]:.4f})\")\n",
    "print(f\"          = {dL_dy[0]:.4f} \u00d7 {dy_dz2[0]:.4f}\")\n",
    "print(f\"          = {dL_dz2[0]:.4f}\")\n",
    "print(\"Chain rule in action! We multiplied two gradients.\")\n",
    "print()\n",
    "\n",
    "# Step 3: Gradients for W2 and b2\n",
    "print(\"Step 3\ufe0f\u20e3: How does loss change with output weights W2 and bias b2?\")\n",
    "print(\"-\" * 60)\n",
    "# dL/dW2 = dL/dz2 \u00d7 dz2/dW2 = dL/dz2 \u00d7 h (because z2 = h\u00b7W2 + b2)\n",
    "dL_dW2 = np.outer(h, dL_dz2)  # Outer product\n",
    "print(f\"\u2202Loss/\u2202W2 = (\u2202Loss/\u2202z2) \u00d7 (\u2202z2/\u2202W2)\")\n",
    "print(f\"          = {dL_dz2[0]:.4f} \u00d7 {h}\")\n",
    "print(f\"          = {dL_dW2.flatten()}\")\n",
    "print()\n",
    "\n",
    "dL_db2 = dL_dz2  # dz2/db2 = 1, so gradient is just dL_dz2\n",
    "print(f\"\u2202Loss/\u2202b2 = {dL_db2[0]:.4f}\")\n",
    "print()\n",
    "\n",
    "# Step 4: Gradient flowing back to hidden layer\n",
    "print(\"Step 4\ufe0f\u20e3: How does loss change with hidden layer activations?\")\n",
    "print(\"-\" * 60)\n",
    "# dL/dh = dL/dz2 \u00d7 dz2/dh = dL/dz2 \u00d7 W2\n",
    "dL_dh = np.dot(dL_dz2, W2.T)\n",
    "print(f\"\u2202Loss/\u2202h = (\u2202Loss/\u2202z2) \u00d7 W2\u1d40\")\n",
    "print(f\"         = {dL_dz2[0]:.4f} \u00d7 {W2.T}\")\n",
    "print(f\"         = {dL_dh}\")\n",
    "print(\"The error is propagated back through the weights!\")\n",
    "print()\n",
    "\n",
    "# Step 5: Gradient at hidden layer (before activation)\n",
    "print(\"Step 5\ufe0f\u20e3: How does loss change with hidden layer weighted sum?\")\n",
    "print(\"-\" * 60)\n",
    "# dL/dz1 = dL/dh \u00d7 dh/dz1\n",
    "dh_dz1 = sigmoid_derivative(z1)\n",
    "dL_dz1 = dL_dh * dh_dz1\n",
    "print(f\"\u2202Loss/\u2202z1 = (\u2202Loss/\u2202h) \u00d7 (\u2202h/\u2202z1)\")\n",
    "print(f\"          = {dL_dh} \u00d7 sigmoid'({z1})\")\n",
    "print(f\"          = {dL_dh} \u00d7 {dh_dz1}\")\n",
    "print(f\"          = {dL_dz1}\")\n",
    "print()\n",
    "\n",
    "# Step 6: Gradients for W1 and b1\n",
    "print(\"Step 6\ufe0f\u20e3: How does loss change with input weights W1 and bias b1?\")\n",
    "print(\"-\" * 60)\n",
    "# dL/dW1 = dL/dz1 \u00d7 dz1/dW1 = dL/dz1 \u00d7 X\n",
    "dL_dW1 = np.outer(X, dL_dz1)\n",
    "print(f\"\u2202Loss/\u2202W1 = (\u2202Loss/\u2202z1) \u00d7 X\u1d40\")\n",
    "print(f\"          = {X} \u00d7 {dL_dz1}\")\n",
    "print(\"Result:\")\n",
    "print(dL_dW1)\n",
    "print()\n",
    "\n",
    "dL_db1 = dL_dz1\n",
    "print(f\"\u2202Loss/\u2202b1 = {dL_db1}\")\n",
    "print()\n",
    "\n",
    "# --- WEIGHT UPDATE ---\n",
    "print(\"=\"*60)\n",
    "print(\"\ud83d\udd04 WEIGHT UPDATE (Gradient Descent Step)\")\n",
    "print(\"=\"*60)\n",
    "print()\n",
    "\n",
    "print(\"Formula: new_weight = old_weight - learning_rate \u00d7 gradient\")\n",
    "print()\n",
    "\n",
    "# Update all weights\n",
    "W2_new = W2 - learning_rate * dL_dW2\n",
    "b2_new = b2 - learning_rate * dL_db2\n",
    "W1_new = W1 - learning_rate * dL_dW1\n",
    "b1_new = b1 - learning_rate * dL_db1\n",
    "\n",
    "print(\"Output layer updates:\")\n",
    "print(f\"W2: {W2.flatten()} \u2192 {W2_new.flatten()}\")\n",
    "print(f\"b2: {b2} \u2192 {b2_new}\")\n",
    "print()\n",
    "print(\"Hidden layer updates:\")\n",
    "print(f\"W1:\")\n",
    "print(f\"  Old:\\n{W1}\")\n",
    "print(f\"  New:\\n{W1_new}\")\n",
    "print(f\"b1: {b1} \u2192 {b1_new}\")\n",
    "print()\n",
    "\n",
    "# Verify improvement\n",
    "print(\"=\"*60)\n",
    "print(\"\u2705 VERIFICATION: Did we improve?\")\n",
    "print(\"=\"*60)\n",
    "print()\n",
    "\n",
    "# Forward pass with new weights\n",
    "z1_new = np.dot(X, W1_new) + b1_new\n",
    "h_new = sigmoid(z1_new)\n",
    "z2_new = np.dot(h_new, W2_new) + b2_new\n",
    "y_pred_new = sigmoid(z2_new)\n",
    "loss_new = 0.5 * (y_pred_new - y_true) ** 2\n",
    "\n",
    "print(f\"Before update:\")\n",
    "print(f\"  Prediction: {y_pred[0]:.6f}\")\n",
    "print(f\"  Loss: {loss[0]:.6f}\")\n",
    "print()\n",
    "print(f\"After update:\")\n",
    "print(f\"  Prediction: {y_pred_new[0]:.6f}\")\n",
    "print(f\"  Loss: {loss_new[0]:.6f}\")\n",
    "print()\n",
    "print(f\"Improvement: {loss[0] - loss_new[0]:.6f} (loss decreased by {((loss[0] - loss_new[0]) / loss[0] * 100):.2f}%)\")\n",
    "print()\n",
    "print(\"\ud83c\udf89 Success! The loss went down, meaning we're learning!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \ud83c\udfaf Quick Summary: What Just Happened?\n",
    "\n",
    "1. **Forward Pass**: Computed prediction from inputs\n",
    "2. **Loss**: Measured how wrong we were\n",
    "3. **Backward Pass**: Used chain rule to compute gradients\n",
    "   - Started from loss\n",
    "   - Worked backward through each layer\n",
    "   - Calculated how much each weight contributed to error\n",
    "4. **Weight Update**: Adjusted weights to reduce error\n",
    "5. **Result**: Loss decreased! \ud83c\udf89\n",
    "\n",
    "---\n",
    "\n",
    "## \ud83d\udee0\ufe0f Part 4: Complete Implementation from Scratch\n",
    "\n",
    "Now let's put it all together in a clean, reusable implementation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoLayerNetwork:\n",
    "    \"\"\"A simple 2-layer neural network with backpropagation\n",
    "    \n",
    "    This class implements:\n",
    "    - Forward propagation\n",
    "    - Loss calculation\n",
    "    - Backpropagation\n",
    "    - Weight updates\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, output_size, learning_rate=0.1):\n",
    "        \"\"\"Initialize the network with random weights\n",
    "        \n",
    "        Args:\n",
    "            input_size: Number of input features\n",
    "            hidden_size: Number of neurons in hidden layer\n",
    "            output_size: Number of output neurons\n",
    "            learning_rate: Step size for gradient descent\n",
    "        \"\"\"\n",
    "        # Initialize weights with small random values\n",
    "        # (We multiply by 0.5 to keep values small)\n",
    "        self.W1 = np.random.randn(input_size, hidden_size) * 0.5\n",
    "        self.b1 = np.zeros(hidden_size)  # Biases start at zero\n",
    "        \n",
    "        self.W2 = np.random.randn(hidden_size, output_size) * 0.5\n",
    "        self.b2 = np.zeros(output_size)\n",
    "        \n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "        # Storage for intermediate values (needed for backprop)\n",
    "        self.cache = {}\n",
    "    \n",
    "    def forward(self, X):\n",
    "        \"\"\"Forward pass: compute predictions\n",
    "        \n",
    "        Args:\n",
    "            X: Input data (batch_size, input_size)\n",
    "        \n",
    "        Returns:\n",
    "            y_pred: Predictions (batch_size, output_size)\n",
    "        \"\"\"\n",
    "        # Hidden layer\n",
    "        z1 = np.dot(X, self.W1) + self.b1  # Weighted sum\n",
    "        h = sigmoid(z1)  # Activation\n",
    "        \n",
    "        # Output layer\n",
    "        z2 = np.dot(h, self.W2) + self.b2  # Weighted sum\n",
    "        y_pred = sigmoid(z2)  # Activation\n",
    "        \n",
    "        # Save intermediate values for backpropagation\n",
    "        self.cache = {\n",
    "            'X': X,\n",
    "            'z1': z1,\n",
    "            'h': h,\n",
    "            'z2': z2,\n",
    "            'y_pred': y_pred\n",
    "        }\n",
    "        \n",
    "        return y_pred\n",
    "    \n",
    "    def compute_loss(self, y_pred, y_true):\n",
    "        \"\"\"Compute Mean Squared Error loss\n",
    "        \n",
    "        Args:\n",
    "            y_pred: Predictions from network\n",
    "            y_true: True labels\n",
    "        \n",
    "        Returns:\n",
    "            loss: Average loss across all samples\n",
    "        \"\"\"\n",
    "        # MSE = mean of (prediction - true)^2\n",
    "        return np.mean((y_pred - y_true) ** 2)\n",
    "    \n",
    "    def backward(self, y_true):\n",
    "        \"\"\"Backward pass: compute gradients using backpropagation\n",
    "        \n",
    "        Args:\n",
    "            y_true: True labels\n",
    "        \n",
    "        Returns:\n",
    "            gradients: Dictionary of gradients for all parameters\n",
    "        \"\"\"\n",
    "        # Get cached values from forward pass\n",
    "        X = self.cache['X']\n",
    "        z1 = self.cache['z1']\n",
    "        h = self.cache['h']\n",
    "        z2 = self.cache['z2']\n",
    "        y_pred = self.cache['y_pred']\n",
    "        \n",
    "        batch_size = X.shape[0]  # Number of samples\n",
    "        \n",
    "        # --- Backward pass through output layer ---\n",
    "        \n",
    "        # Gradient of loss w.r.t. predictions\n",
    "        dL_dy = 2 * (y_pred - y_true) / batch_size  # Average over batch\n",
    "        \n",
    "        # Gradient of loss w.r.t. z2 (before activation)\n",
    "        # Chain rule: dL/dz2 = dL/dy \u00d7 dy/dz2\n",
    "        dy_dz2 = sigmoid_derivative(z2)\n",
    "        dL_dz2 = dL_dy * dy_dz2\n",
    "        \n",
    "        # Gradients for W2 and b2\n",
    "        dL_dW2 = np.dot(h.T, dL_dz2)  # (hidden_size, output_size)\n",
    "        dL_db2 = np.sum(dL_dz2, axis=0)  # Sum across batch\n",
    "        \n",
    "        # --- Backward pass through hidden layer ---\n",
    "        \n",
    "        # Gradient of loss w.r.t. hidden activations\n",
    "        # Chain rule: dL/dh = dL/dz2 \u00d7 dz2/dh = dL/dz2 \u00d7 W2\n",
    "        dL_dh = np.dot(dL_dz2, self.W2.T)\n",
    "        \n",
    "        # Gradient of loss w.r.t. z1 (before activation)\n",
    "        # Chain rule: dL/dz1 = dL/dh \u00d7 dh/dz1\n",
    "        dh_dz1 = sigmoid_derivative(z1)\n",
    "        dL_dz1 = dL_dh * dh_dz1\n",
    "        \n",
    "        # Gradients for W1 and b1\n",
    "        dL_dW1 = np.dot(X.T, dL_dz1)  # (input_size, hidden_size)\n",
    "        dL_db1 = np.sum(dL_dz1, axis=0)  # Sum across batch\n",
    "        \n",
    "        # Return all gradients\n",
    "        return {\n",
    "            'dW1': dL_dW1,\n",
    "            'db1': dL_db1,\n",
    "            'dW2': dL_dW2,\n",
    "            'db2': dL_db2\n",
    "        }\n",
    "    \n",
    "    def update_weights(self, gradients):\n",
    "        \"\"\"Update weights using gradient descent\n",
    "        \n",
    "        Args:\n",
    "            gradients: Dictionary of gradients from backward pass\n",
    "        \"\"\"\n",
    "        # Update each parameter: param = param - learning_rate \u00d7 gradient\n",
    "        self.W1 -= self.learning_rate * gradients['dW1']\n",
    "        self.b1 -= self.learning_rate * gradients['db1']\n",
    "        self.W2 -= self.learning_rate * gradients['dW2']\n",
    "        self.b2 -= self.learning_rate * gradients['db2']\n",
    "    \n",
    "    def train_step(self, X, y_true):\n",
    "        \"\"\"Complete training step: forward, backward, update\n",
    "        \n",
    "        Args:\n",
    "            X: Input data\n",
    "            y_true: True labels\n",
    "        \n",
    "        Returns:\n",
    "            loss: Current loss value\n",
    "        \"\"\"\n",
    "        # Forward pass\n",
    "        y_pred = self.forward(X)\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = self.compute_loss(y_pred, y_true)\n",
    "        \n",
    "        # Backward pass\n",
    "        gradients = self.backward(y_true)\n",
    "        \n",
    "        # Update weights\n",
    "        self.update_weights(gradients)\n",
    "        \n",
    "        return loss\n",
    "\n",
    "print(\"\u2705 TwoLayerNetwork class implemented!\")\n",
    "print(\"This class can:\")\n",
    "print(\"  \u2022 Forward propagate (make predictions)\")\n",
    "print(\"  \u2022 Compute loss\")\n",
    "print(\"  \u2022 Backpropagate (compute gradients)\")\n",
    "print(\"  \u2022 Update weights\")\n",
    "print(\"\\nLet's test it on the XOR problem!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \ud83e\uddea Testing on XOR Problem\n",
    "\n",
    "XOR (exclusive OR) is a classic problem that can't be solved by a single neuron (it's not linearly separable). But our 2-layer network can learn it!\n",
    "\n",
    "**XOR Truth Table:**\n",
    "```\n",
    "Input 1 | Input 2 | Output\n",
    "--------|---------|--------\n",
    "   0    |    0    |   0\n",
    "   0    |    1    |   1\n",
    "   1    |    0    |   1\n",
    "   1    |    1    |   0\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XOR dataset\n",
    "X_xor = np.array([\n",
    "    [0, 0],\n",
    "    [0, 1],\n",
    "    [1, 0],\n",
    "    [1, 1]\n",
    "])\n",
    "\n",
    "y_xor = np.array([\n",
    "    [0],\n",
    "    [1],\n",
    "    [1],\n",
    "    [0]\n",
    "])\n",
    "\n",
    "print(\"XOR Problem:\")\n",
    "print(\"Inputs:\\n\", X_xor)\n",
    "print(\"\\nTargets:\\n\", y_xor.flatten())\n",
    "print()\n",
    "\n",
    "# Create and train network\n",
    "np.random.seed(42)  # For reproducibility\n",
    "network = TwoLayerNetwork(\n",
    "    input_size=2,\n",
    "    hidden_size=4,  # 4 hidden neurons\n",
    "    output_size=1,\n",
    "    learning_rate=0.5\n",
    ")\n",
    "\n",
    "# Train for many iterations\n",
    "num_iterations = 5000\n",
    "losses = []\n",
    "\n",
    "print(\"Training network on XOR...\")\n",
    "print()\n",
    "\n",
    "for i in range(num_iterations):\n",
    "    # Train on entire dataset\n",
    "    loss = network.train_step(X_xor, y_xor)\n",
    "    losses.append(loss)\n",
    "    \n",
    "    # Print progress every 1000 iterations\n",
    "    if (i + 1) % 1000 == 0:\n",
    "        print(f\"Iteration {i+1:4d} | Loss: {loss:.6f}\")\n",
    "\n",
    "print(\"\\nTraining complete!\")\n",
    "print()\n",
    "\n",
    "# Test the network\n",
    "predictions = network.forward(X_xor)\n",
    "\n",
    "print(\"Final Results:\")\n",
    "print(\"=\"*50)\n",
    "print(\"Input 1 | Input 2 | Target | Prediction | Rounded\")\n",
    "print(\"-\"*50)\n",
    "for i in range(len(X_xor)):\n",
    "    x1, x2 = X_xor[i]\n",
    "    target = y_xor[i, 0]\n",
    "    pred = predictions[i, 0]\n",
    "    rounded = round(pred)\n",
    "    print(f\"   {x1}    |    {x2}    |   {target}    |   {pred:.4f}   |    {rounded}\")\n",
    "\n",
    "print()\n",
    "accuracy = np.mean((predictions > 0.5) == y_xor) * 100\n",
    "print(f\"Accuracy: {accuracy:.1f}%\")\n",
    "print()\n",
    "print(\"\ud83c\udf89 The network learned XOR through backpropagation!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the training process\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Plot 1: Loss over time\n",
    "ax1.plot(losses, 'b-', linewidth=2)\n",
    "ax1.set_xlabel('Iteration', fontsize=12)\n",
    "ax1.set_ylabel('Loss (MSE)', fontsize=12)\n",
    "ax1.set_title('Loss Decreases Over Time (Learning!)', fontsize=14, fontweight='bold')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.set_yscale('log')  # Log scale to see details\n",
    "\n",
    "# Plot 2: Decision boundary\n",
    "# Create a grid of points\n",
    "xx, yy = np.meshgrid(np.linspace(-0.5, 1.5, 100),\n",
    "                     np.linspace(-0.5, 1.5, 100))\n",
    "grid_points = np.c_[xx.ravel(), yy.ravel()]\n",
    "\n",
    "# Predict for all grid points\n",
    "Z = network.forward(grid_points)\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "# Plot decision boundary\n",
    "contour = ax2.contourf(xx, yy, Z, levels=20, cmap='RdYlBu', alpha=0.7)\n",
    "ax2.contour(xx, yy, Z, levels=[0.5], colors='black', linewidths=2)\n",
    "\n",
    "# Plot the XOR points\n",
    "scatter = ax2.scatter(X_xor[:, 0], X_xor[:, 1], c=y_xor.flatten(),\n",
    "                     cmap='RdYlBu', s=200, edgecolors='black', linewidths=3)\n",
    "\n",
    "ax2.set_xlabel('Input 1', fontsize=12)\n",
    "ax2.set_ylabel('Input 2', fontsize=12)\n",
    "ax2.set_title('Decision Boundary: Network Learned XOR!', fontsize=14, fontweight='bold')\n",
    "plt.colorbar(contour, ax=ax2, label='Prediction')\n",
    "\n",
    "# Add labels for each point\n",
    "for i, (x, y, label) in enumerate(zip(X_xor[:, 0], X_xor[:, 1], y_xor.flatten())):\n",
    "    ax2.text(x+0.05, y+0.05, f'({int(x)},{int(y)})\u2192{int(label)}',\n",
    "             fontsize=10, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\ud83d\udcca Understanding the visualizations:\")\n",
    "print(\"Left: Loss curve shows learning progress - it goes down!\")\n",
    "print(\"Right: Decision boundary separates the two classes\")\n",
    "print(\"  \u2022 Blue regions = network predicts 0\")\n",
    "print(\"  \u2022 Red regions = network predicts 1\")\n",
    "print(\"  \u2022 The network learned the non-linear XOR pattern!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \ud83d\udca1 Key Insight: Why Backpropagation Works\n",
    "\n",
    "Backpropagation works because:\n",
    "\n",
    "1. **Chain Rule**: Allows us to decompose complex derivatives\n",
    "2. **Systematic**: Works backward layer by layer\n",
    "3. **Efficient**: Each gradient computed only once\n",
    "4. **General**: Works for any network architecture\n",
    "\n",
    "Without backpropagation, we couldn't train deep neural networks!\n",
    "\n",
    "---\n",
    "\n",
    "## \u26a0\ufe0f Part 5: Common Issues with Backpropagation\n",
    "\n",
    "### 1. Vanishing Gradients \ud83d\udcc9\n",
    "\n",
    "**Problem**: Gradients become extremely small as they propagate backward\n",
    "\n",
    "**Why it happens**:\n",
    "- Sigmoid derivative is at most 0.25\n",
    "- Multiply many small numbers \u2192 very small gradient\n",
    "- Deep networks: gradient = product of many derivatives\n",
    "\n",
    "**Example**: In a 5-layer network with sigmoid:\n",
    "- Each layer multiplies gradient by \u2264 0.25\n",
    "- Final gradient \u2264 0.25\u2075 = 0.00098 (very small!)\n",
    "- Early layers barely update \u2192 slow learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate vanishing gradients with sigmoid\n",
    "\n",
    "# Simulate gradients flowing through multiple sigmoid layers\n",
    "num_layers = [1, 2, 3, 5, 10]  # Different network depths\n",
    "initial_gradient = 1.0  # Start with gradient of 1\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# For each network depth\n",
    "for n in num_layers:\n",
    "    gradients = [initial_gradient]\n",
    "    \n",
    "    # Simulate gradient flowing back through n layers\n",
    "    current_grad = initial_gradient\n",
    "    for layer in range(n):\n",
    "        # Sigmoid derivative at z=0 is 0.25 (maximum value)\n",
    "        # In practice, it's often smaller\n",
    "        current_grad *= 0.25  # Multiply by sigmoid derivative\n",
    "        gradients.append(current_grad)\n",
    "    \n",
    "    # Plot gradient at each layer\n",
    "    layers = list(range(len(gradients)))\n",
    "    ax1.plot(layers, gradients, 'o-', linewidth=2, markersize=8, label=f'{n} layers')\n",
    "\n",
    "ax1.set_xlabel('Layer (from output to input)', fontsize=12)\n",
    "ax1.set_ylabel('Gradient Magnitude', fontsize=12)\n",
    "ax1.set_title('Vanishing Gradients with Sigmoid', fontsize=14, fontweight='bold')\n",
    "ax1.set_yscale('log')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Compare sigmoid vs ReLU derivatives\n",
    "x = np.linspace(-5, 5, 100)\n",
    "sigmoid_deriv = sigmoid_derivative(x)\n",
    "relu_deriv = (x > 0).astype(float)  # ReLU derivative: 0 if x<0, 1 if x>0\n",
    "\n",
    "ax2.plot(x, sigmoid_deriv, 'b-', linewidth=2, label='Sigmoid derivative')\n",
    "ax2.plot(x, relu_deriv, 'r-', linewidth=2, label='ReLU derivative')\n",
    "ax2.set_xlabel('x', fontsize=12)\n",
    "ax2.set_ylabel('Derivative', fontsize=12)\n",
    "ax2.set_title('Why ReLU Helps: Derivative is 0 or 1', fontsize=14, fontweight='bold')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "ax2.set_ylim(-0.1, 1.1)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\u26a0\ufe0f Vanishing Gradient Problem:\")\n",
    "print(\"Left: Gradients shrink exponentially in deep networks with sigmoid\")\n",
    "print(\"Right: ReLU has constant derivative of 1 (when x > 0)\")\n",
    "print(\"\\nSolution: Use ReLU instead of sigmoid in hidden layers!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Exploding Gradients \ud83d\udca5\n",
    "\n",
    "**Problem**: Gradients become extremely large\n",
    "\n",
    "**Why it happens**:\n",
    "- Large weight values\n",
    "- Multiply many large numbers \u2192 explosion\n",
    "- Network becomes unstable\n",
    "\n",
    "**Solutions**:\n",
    "- **Gradient clipping**: Cap gradients at a maximum value\n",
    "- **Better weight initialization**: Start with smaller weights\n",
    "- **Batch normalization**: Normalize activations\n",
    "\n",
    "### 3. Dead ReLU Problem \ud83d\udc80\n",
    "\n",
    "**Problem**: ReLU neurons can \"die\" and stop learning\n",
    "\n",
    "**Why it happens**:\n",
    "- If a neuron's output is always negative, ReLU always outputs 0\n",
    "- Gradient is always 0 \u2192 no weight updates \u2192 neuron is \"dead\"\n",
    "\n",
    "**Solution**: Use Leaky ReLU or other variants\n",
    "\n",
    "---\n",
    "\n",
    "## \ud83c\udfae Interactive Experiments\n",
    "\n",
    "### Experiment 1: Effect of Learning Rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \ud83d\udccc Gradient Clipping in Detail\n",
    "\n",
    "**Gradient clipping** is a technique to prevent exploding gradients by capping the gradient magnitude to a maximum value. This keeps training stable and prevents numerical overflow.\n",
    "\n",
    "#### Two Common Approaches:\n",
    "\n",
    "**1. Clip by Value** (element-wise clipping):\n",
    "- Clip each gradient element individually to a range `[-threshold, threshold]`\n",
    "- Simple and easy to implement\n",
    "- Formula: `gradient = clip(gradient, -threshold, threshold)`\n",
    "\n",
    "**2. Clip by Norm** (global clipping):\n",
    "- Calculate the total magnitude (norm) of all gradients\n",
    "- If norm exceeds threshold, scale down ALL gradients proportionally\n",
    "- Preserves the direction of the gradient vector\n",
    "- Formula: `if ||gradient|| > threshold: gradient = gradient * (threshold / ||gradient||)`\n",
    "\n",
    "#### When to Use Gradient Clipping:\n",
    "\n",
    "\u2705 **Recurrent Neural Networks (RNNs)**: Very common - RNNs are prone to exploding gradients\n",
    "\n",
    "\u2705 **Unstable Training**: When you see loss values shooting up suddenly or oscillating wildly\n",
    "\n",
    "\u2705 **NaN or Inf Losses**: When gradients become so large they cause numerical overflow\n",
    "\n",
    "\u2705 **Very Deep Networks**: When gradients accumulate through many layers\n",
    "\n",
    "\u274c **Not Always Needed**: Well-initialized shallow networks with ReLU often don't need it\n",
    "\n",
    "#### Typical Threshold Values:\n",
    "\n",
    "- **Clip by value**: 1.0 to 5.0\n",
    "- **Clip by norm**: 1.0 to 10.0 (depends on network size)\n",
    "- Start conservative (lower values) and increase if learning is too slow\n",
    "\n",
    "Let's see both approaches in action:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Clipping Implementation Examples\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def clip_gradient_by_value(gradient, threshold=1.0):\n",
    "    \"\"\"Clip gradients element-wise to [-threshold, threshold]\n",
    "    \n",
    "    Args:\n",
    "        gradient: Gradient array (any shape)\n",
    "        threshold: Maximum absolute value for any gradient element\n",
    "    \n",
    "    Returns:\n",
    "        Clipped gradient\n",
    "    \"\"\"\n",
    "    return np.clip(gradient, -threshold, threshold)\n",
    "\n",
    "def clip_gradient_by_norm(gradient, max_norm=1.0):\n",
    "    \"\"\"Clip gradients by scaling to have maximum norm\n",
    "    \n",
    "    Args:\n",
    "        gradient: Gradient array (any shape)\n",
    "        max_norm: Maximum allowed norm (L2 norm)\n",
    "    \n",
    "    Returns:\n",
    "        Clipped gradient (preserves direction)\n",
    "    \"\"\"\n",
    "    # Calculate L2 norm (magnitude) of gradient\n",
    "    grad_norm = np.linalg.norm(gradient)\n",
    "    \n",
    "    # If norm exceeds threshold, scale down proportionally\n",
    "    if grad_norm > max_norm:\n",
    "        gradient = gradient * (max_norm / grad_norm)\n",
    "    \n",
    "    return gradient\n",
    "\n",
    "# Example: Simulate exploding gradients\n",
    "print(\"\ud83d\udd25 Gradient Clipping Examples\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Create a gradient that's too large (exploding!)\n",
    "exploding_gradient = np.array([5.0, -8.0, 12.0, -15.0, 20.0])\n",
    "\n",
    "print(\"\\n\ud83d\udcca Original (exploding) gradient:\")\n",
    "print(f\"  Values: {exploding_gradient}\")\n",
    "print(f\"  Norm (magnitude): {np.linalg.norm(exploding_gradient):.2f}\")\n",
    "print(f\"  Max absolute value: {np.max(np.abs(exploding_gradient)):.2f}\")\n",
    "\n",
    "# Method 1: Clip by value\n",
    "clipped_by_value = clip_gradient_by_value(exploding_gradient, threshold=3.0)\n",
    "print(\"\\n\u2702\ufe0f Method 1: Clip by Value (threshold=3.0)\")\n",
    "print(f\"  Values: {clipped_by_value}\")\n",
    "print(f\"  Norm: {np.linalg.norm(clipped_by_value):.2f}\")\n",
    "print(f\"  Max absolute value: {np.max(np.abs(clipped_by_value)):.2f}\")\n",
    "print(f\"  \u2192 Each element capped at [-3, 3]\")\n",
    "\n",
    "# Method 2: Clip by norm\n",
    "clipped_by_norm = clip_gradient_by_norm(exploding_gradient, max_norm=5.0)\n",
    "print(\"\\n\u2702\ufe0f Method 2: Clip by Norm (max_norm=5.0)\")\n",
    "print(f\"  Values: {clipped_by_norm}\")\n",
    "print(f\"  Norm: {np.linalg.norm(clipped_by_norm):.2f}\")\n",
    "print(f\"  Max absolute value: {np.max(np.abs(clipped_by_norm)):.2f}\")\n",
    "print(f\"  \u2192 Direction preserved, scaled to norm=5.0\")\n",
    "\n",
    "print(\"\\n\ud83d\udd0d Key Difference:\")\n",
    "print(\"  \u2022 Clip by Value: Each element independently clamped\")\n",
    "print(\"  \u2022 Clip by Norm: Entire vector scaled proportionally\")\n",
    "print(\"  \u2022 Clip by Norm better preserves gradient direction!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the effect of gradient clipping\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Generate a range of gradient values (some exploding)\n",
    "original_gradients = np.linspace(-20, 20, 100)\n",
    "\n",
    "# Apply different clipping strategies\n",
    "threshold_value = 5.0\n",
    "clipped_by_value = np.clip(original_gradients, -threshold_value, threshold_value)\n",
    "\n",
    "# For norm clipping on 1D, it's just the same as value clipping\n",
    "# But let's show the effect on a 2D gradient\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Plot 1: Clip by value effect\n",
    "ax1.plot(original_gradients, original_gradients, 'b-', linewidth=2, label='Original', alpha=0.5)\n",
    "ax1.plot(original_gradients, clipped_by_value, 'r-', linewidth=2, label=f'Clipped (threshold={threshold_value})')\n",
    "ax1.axhline(y=threshold_value, color='gray', linestyle='--', alpha=0.5)\n",
    "ax1.axhline(y=-threshold_value, color='gray', linestyle='--', alpha=0.5)\n",
    "ax1.set_xlabel('Original Gradient Value', fontsize=12)\n",
    "ax1.set_ylabel('After Clipping', fontsize=12)\n",
    "ax1.set_title('Clip by Value: Caps Extreme Values', fontsize=14, fontweight='bold')\n",
    "ax1.legend(fontsize=11)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.set_ylim([-25, 25])\n",
    "\n",
    "# Plot 2: 2D visualization showing direction preservation\n",
    "# Create a grid of 2D gradient vectors\n",
    "angles = np.linspace(0, 2*np.pi, 8)\n",
    "max_norm = 5.0\n",
    "\n",
    "for angle in angles:\n",
    "    # Create a gradient vector that's too large\n",
    "    magnitude = 15.0\n",
    "    grad_x = magnitude * np.cos(angle)\n",
    "    grad_y = magnitude * np.sin(angle)\n",
    "    \n",
    "    # Original vector (exploding)\n",
    "    ax2.arrow(0, 0, grad_x, grad_y, head_width=0.8, head_length=1.0, \n",
    "             fc='red', ec='red', alpha=0.3, linewidth=1.5, label='Original' if angle == 0 else '')\n",
    "    \n",
    "    # Clipped by norm (scaled down, preserving direction)\n",
    "    grad_norm = np.sqrt(grad_x**2 + grad_y**2)\n",
    "    if grad_norm > max_norm:\n",
    "        grad_x_clipped = grad_x * (max_norm / grad_norm)\n",
    "        grad_y_clipped = grad_y * (max_norm / grad_norm)\n",
    "    else:\n",
    "        grad_x_clipped = grad_x\n",
    "        grad_y_clipped = grad_y\n",
    "    \n",
    "    ax2.arrow(0, 0, grad_x_clipped, grad_y_clipped, head_width=0.5, head_length=0.6,\n",
    "             fc='blue', ec='blue', alpha=0.7, linewidth=2, label='Clipped' if angle == 0 else '')\n",
    "\n",
    "# Draw the max norm circle\n",
    "circle = plt.Circle((0, 0), max_norm, fill=False, color='green', linestyle='--', linewidth=2, label=f'Max norm={max_norm}')\n",
    "ax2.add_patch(circle)\n",
    "\n",
    "ax2.set_xlim([-20, 20])\n",
    "ax2.set_ylim([-20, 20])\n",
    "ax2.set_xlabel('Gradient X', fontsize=12)\n",
    "ax2.set_ylabel('Gradient Y', fontsize=12)\n",
    "ax2.set_title('Clip by Norm: Preserves Direction', fontsize=14, fontweight='bold')\n",
    "ax2.set_aspect('equal')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "ax2.legend(fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\ud83d\udcca Visualization Insights:\")\n",
    "print(\"Left: Clip by value creates a 'plateau' effect at the threshold\")\n",
    "print(\"Right: Clip by norm scales all vectors to stay within the circle\")\n",
    "print(\"       \u2192 Blue arrows (clipped) point in same direction as red (original)\")\n",
    "print(\"       \u2192 This is why clip by norm is preferred for most applications!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \ufffd\ufffd Practical Tips for Gradient Clipping\n",
    "\n",
    "**When Training:**\n",
    "\n",
    "1. **Start with clip by norm** - it's the most commonly used and effective\n",
    "2. **Choose threshold based on your problem**:\n",
    "   - RNNs: typically 1.0 to 5.0\n",
    "   - Deep CNNs: typically 5.0 to 10.0\n",
    "   - If unsure, start with 1.0 and increase if training is too slow\n",
    "\n",
    "3. **Monitor gradient norms** during training to see if clipping is helping\n",
    "4. **Signs you need gradient clipping**:\n",
    "   - Loss suddenly jumps to very high values or NaN\n",
    "   - Model parameters become NaN or Inf\n",
    "   - Training is unstable with wild oscillations\n",
    "\n",
    "**Common Mistakes to Avoid:**\n",
    "\n",
    "\u274c Setting threshold too low \u2192 Learning becomes too slow\n",
    "\n",
    "\u274c Setting threshold too high \u2192 Clipping doesn't help with exploding gradients\n",
    "\n",
    "\u274c Using clip by value when clip by norm would be better\n",
    "\n",
    "\u2705 **Best Practice**: Use clip by norm with threshold around 1-5 for RNNs, monitor training, and adjust if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train networks with different learning rates\n",
    "learning_rates = [0.01, 0.1, 0.5, 2.0]\n",
    "num_iterations = 3000\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, lr in enumerate(learning_rates):\n",
    "    # Create network with specific learning rate\n",
    "    np.random.seed(42)  # Same initialization for fair comparison\n",
    "    network = TwoLayerNetwork(\n",
    "        input_size=2,\n",
    "        hidden_size=4,\n",
    "        output_size=1,\n",
    "        learning_rate=lr\n",
    "    )\n",
    "    \n",
    "    # Train\n",
    "    losses = []\n",
    "    for i in range(num_iterations):\n",
    "        loss = network.train_step(X_xor, y_xor)\n",
    "        losses.append(loss)\n",
    "    \n",
    "    # Plot\n",
    "    ax = axes[idx]\n",
    "    ax.plot(losses, linewidth=2)\n",
    "    ax.set_xlabel('Iteration', fontsize=11)\n",
    "    ax.set_ylabel('Loss', fontsize=11)\n",
    "    ax.set_title(f'Learning Rate = {lr}', fontsize=13, fontweight='bold')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.set_ylim(0, 0.3)\n",
    "    \n",
    "    # Final loss\n",
    "    final_loss = losses[-1]\n",
    "    ax.text(0.6, 0.9, f'Final: {final_loss:.4f}',\n",
    "            transform=ax.transAxes, fontsize=11,\n",
    "            bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\ud83c\udfaf Try it yourself!\")\n",
    "print(\"Change the learning_rates list above and re-run to see different behaviors.\")\n",
    "print(\"\\nWhat to look for:\")\n",
    "print(\"\u2022 Too small (0.01): Slow, steady decrease\")\n",
    "print(\"\u2022 Just right (0.1-0.5): Fast convergence\")\n",
    "print(\"\u2022 Too large (2.0): Unstable, might diverge\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 2: Visualizing Gradient Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize how gradients flow through the network\n",
    "\n",
    "# Create and train a small network\n",
    "np.random.seed(42)\n",
    "network = TwoLayerNetwork(input_size=2, hidden_size=3, output_size=1, learning_rate=0.5)\n",
    "\n",
    "# Do one forward pass\n",
    "y_pred = network.forward(X_xor)\n",
    "\n",
    "# Do one backward pass\n",
    "gradients = network.backward(y_xor)\n",
    "\n",
    "# Visualize the network and gradient magnitudes\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "# Layer positions\n",
    "layer_x = [0, 1, 2]  # Input, Hidden, Output\n",
    "layer_sizes = [2, 3, 1]  # Neurons in each layer\n",
    "\n",
    "# Draw neurons\n",
    "neuron_positions = {}\n",
    "for layer_idx, (x, size) in enumerate(zip(layer_x, layer_sizes)):\n",
    "    y_positions = np.linspace(0, 1, size + 2)[1:-1]  # Evenly spaced\n",
    "    for neuron_idx, y in enumerate(y_positions):\n",
    "        circle = plt.Circle((x, y), 0.08, color='lightblue', ec='black', linewidth=2)\n",
    "        ax.add_patch(circle)\n",
    "        neuron_positions[(layer_idx, neuron_idx)] = (x, y)\n",
    "        \n",
    "        # Label neurons\n",
    "        if layer_idx == 0:\n",
    "            ax.text(x-0.15, y, f'x{neuron_idx+1}', fontsize=10, ha='right')\n",
    "        elif layer_idx == 1:\n",
    "            ax.text(x, y-0.15, f'h{neuron_idx+1}', fontsize=10, ha='center')\n",
    "        else:\n",
    "            ax.text(x+0.15, y, 'y', fontsize=10, ha='left')\n",
    "\n",
    "# Draw connections with gradient-based colors\n",
    "# Connections from input to hidden\n",
    "max_grad_w1 = np.max(np.abs(gradients['dW1']))\n",
    "for i in range(2):  # Input neurons\n",
    "    for j in range(3):  # Hidden neurons\n",
    "        x1, y1 = neuron_positions[(0, i)]\n",
    "        x2, y2 = neuron_positions[(1, j)]\n",
    "        \n",
    "        # Color based on gradient magnitude\n",
    "        grad_magnitude = np.abs(gradients['dW1'][i, j])\n",
    "        color_intensity = grad_magnitude / max_grad_w1\n",
    "        color = plt.cm.Reds(color_intensity)\n",
    "        \n",
    "        ax.plot([x1, x2], [y1, y2], color=color, linewidth=2, alpha=0.7)\n",
    "\n",
    "# Connections from hidden to output\n",
    "max_grad_w2 = np.max(np.abs(gradients['dW2']))\n",
    "for i in range(3):  # Hidden neurons\n",
    "    for j in range(1):  # Output neurons\n",
    "        x1, y1 = neuron_positions[(1, i)]\n",
    "        x2, y2 = neuron_positions[(2, j)]\n",
    "        \n",
    "        grad_magnitude = np.abs(gradients['dW2'][i, j])\n",
    "        color_intensity = grad_magnitude / max_grad_w2\n",
    "        color = plt.cm.Reds(color_intensity)\n",
    "        \n",
    "        ax.plot([x1, x2], [y1, y2], color=color, linewidth=2, alpha=0.7)\n",
    "\n",
    "# Labels\n",
    "ax.text(0, -0.2, 'Input\\nLayer', fontsize=12, ha='center', fontweight='bold')\n",
    "ax.text(1, -0.2, 'Hidden\\nLayer', fontsize=12, ha='center', fontweight='bold')\n",
    "ax.text(2, -0.2, 'Output\\nLayer', fontsize=12, ha='center', fontweight='bold')\n",
    "\n",
    "ax.set_xlim(-0.5, 2.5)\n",
    "ax.set_ylim(-0.3, 1.2)\n",
    "ax.set_aspect('equal')\n",
    "ax.axis('off')\n",
    "ax.set_title('Gradient Flow Visualization\\n(Darker red = larger gradient)', \n",
    "             fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\ud83d\udcca Gradient magnitudes:\")\n",
    "print(f\"\\nInput \u2192 Hidden (W1):\")\n",
    "print(gradients['dW1'])\n",
    "print(f\"\\nHidden \u2192 Output (W2):\")\n",
    "print(gradients['dW2'])\n",
    "print(\"\\n\ud83d\udca1 Darker connections have larger gradients (will update more)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## \ud83c\udfaf Final Summary\n",
    "\n",
    "Congratulations! You've learned the most important algorithm in deep learning. Let's recap:\n",
    "\n",
    "### What is Backpropagation?\n",
    "\n",
    "**Backpropagation** is an algorithm for computing gradients efficiently using the chain rule:\n",
    "\n",
    "1. **Forward Pass**: Compute predictions layer by layer\n",
    "2. **Compute Loss**: Measure how wrong we are\n",
    "3. **Backward Pass**: Work backward computing gradients\n",
    "4. **Update Weights**: Adjust weights to reduce loss\n",
    "\n",
    "### Key Concepts\n",
    "\n",
    "\u2705 **Gradient Descent**: Follow the slope downhill to minimize loss\n",
    "\n",
    "\u2705 **Learning Rate**: Controls step size (too small = slow, too large = unstable)\n",
    "\n",
    "\u2705 **Chain Rule**: Multiply derivatives to propagate gradients backward\n",
    "\n",
    "\u2705 **Vanishing Gradients**: Problem with sigmoid (solution: use ReLU)\n",
    "\n",
    "\u2705 **Systematic Process**: Same algorithm works for any network architecture\n",
    "\n",
    "### Why It's Important\n",
    "\n",
    "- **Enables Learning**: Without backprop, we couldn't train neural networks\n",
    "- **Efficient**: Computes all gradients in one backward pass\n",
    "- **General**: Works for any differentiable function\n",
    "- **Foundation**: Powers all modern deep learning\n",
    "\n",
    "### What's Next?\n",
    "\n",
    "We've learned how to update weights **once**. But one update isn't enough!\n",
    "\n",
    "In the next notebook, we'll learn about the **training loop** - the process of:\n",
    "- Repeating forward/backward passes many times\n",
    "- Processing data in batches\n",
    "- Tracking progress over epochs\n",
    "- Choosing hyperparameters\n",
    "- Building complete, trainable networks\n",
    "\n",
    "---\n",
    "\n",
    "## \ud83c\udf93 Review Questions\n",
    "\n",
    "Test your understanding:\n",
    "\n",
    "1. **What does the gradient tell us?**\n",
    "   - The direction and magnitude of steepest increase in loss\n",
    "   - We move in the opposite direction to decrease loss\n",
    "\n",
    "2. **Why do we need the chain rule?**\n",
    "   - To compute how changes in early layers affect the final loss\n",
    "   - To propagate gradients backward through multiple layers\n",
    "\n",
    "3. **What's the vanishing gradient problem?**\n",
    "   - Gradients become very small in deep networks with sigmoid\n",
    "   - Early layers barely learn\n",
    "   - Solution: Use ReLU activation\n",
    "\n",
    "4. **Why is learning rate important?**\n",
    "   - Too small: slow learning\n",
    "   - Too large: unstable, might diverge\n",
    "   - Need to choose carefully\n",
    "\n",
    "5. **Can you explain backpropagation in one sentence?**\n",
    "   - Use the chain rule to compute gradients by working backward through the network, then update weights to reduce loss.\n",
    "\n",
    "---\n",
    "\n",
    "## \ud83d\udcaa Challenge Exercises\n",
    "\n",
    "Ready to test your skills?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Challenge 1: Implement ReLU and its derivative\n",
    "def relu(x):\n",
    "    \"\"\"TODO: Implement ReLU activation\n",
    "    ReLU(x) = max(0, x)\n",
    "    \"\"\"\n",
    "    pass  # Your code here!\n",
    "\n",
    "def relu_derivative(x):\n",
    "    \"\"\"TODO: Implement ReLU derivative\n",
    "    ReLU'(x) = 1 if x > 0, else 0\n",
    "    \"\"\"\n",
    "    pass  # Your code here!\n",
    "\n",
    "# Test your implementation\n",
    "# test_x = np.array([-2, -1, 0, 1, 2])\n",
    "# print(\"ReLU:\", relu(test_x))\n",
    "# print(\"ReLU':\", relu_derivative(test_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Challenge 2: Modify TwoLayerNetwork to use ReLU instead of sigmoid\n",
    "# Hint: You'll need to:\n",
    "# 1. Change activation function in forward pass\n",
    "# 2. Change derivative in backward pass\n",
    "# 3. Keep sigmoid for output layer (for binary classification)\n",
    "\n",
    "# Your code here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Challenge 3: Add momentum to gradient descent\n",
    "# Momentum helps accelerate learning in the right direction\n",
    "# Update rule: velocity = momentum * velocity + learning_rate * gradient\n",
    "#              weight = weight - velocity\n",
    "\n",
    "# Your code here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## \ud83c\udf89 Congratulations!\n",
    "\n",
    "You've conquered backpropagation - the hardest concept in neural networks!\n",
    "\n",
    "You now understand:\n",
    "- How neural networks learn from data\n",
    "- The mathematics behind gradient descent\n",
    "- How to implement backpropagation from scratch\n",
    "- Common problems and their solutions\n",
    "\n",
    "**This is a HUGE achievement!** Many people struggle with this topic, but you've made it through. \ud83c\udf1f\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "In **Notebook 8: Training Loop**, we'll put everything together and learn how to:\n",
    "- Train networks on real datasets\n",
    "- Choose hyperparameters effectively\n",
    "- Monitor training progress\n",
    "- Avoid overfitting\n",
    "- Build production-ready models\n",
    "\n",
    "You're almost there! One more notebook and you'll have built a complete neural network from scratch! \ud83d\ude80"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}