
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üéØ Backpropagation: Teaching the Network to Learn\n",
    "\n",
    "**The Most Important Concept in Deep Learning!**\n",
    "\n",
    "Welcome to what many consider the **hardest** topic in neural networks. But don't worry! We're going to break it down into tiny, digestible pieces using lots of analogies and visualizations. By the end, you'll understand how neural networks actually learn.\n",
    "\n",
    "---\n",
    "\n",
    "## üìñ What We'll Learn\n",
    "\n",
    "1. **The Problem**: We know the error, but how do we improve?\n",
    "2. **Gradient Descent**: Finding the downhill direction\n",
    "3. **The Chain Rule**: The secret sauce of backpropagation\n",
    "4. **Backpropagation**: Working backward through the network\n",
    "5. **Implementation**: Building it from scratch\n",
    "6. **Common Issues**: What can go wrong\n",
    "\n",
    "---\n",
    "\n",
    "## ü§î The Problem: We Know We're Wrong, But How Do We Get Better?\n",
    "\n",
    "Imagine you're learning to throw darts:\n",
    "- You throw a dart üéØ\n",
    "- It misses the bullseye by 5 inches to the right\n",
    "- **You know you're wrong** (the dart missed)\n",
    "- **But HOW should you adjust your throw?**\n",
    "\n",
    "This is exactly where we are with neural networks:\n",
    "- We have a network that makes predictions\n",
    "- We calculate the loss (how wrong we are)\n",
    "- **But which weights should we change? And by how much?**\n",
    "\n",
    "**Backpropagation is the answer!** It tells us exactly how to adjust each weight to reduce the error.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np  # For numerical operations\n",
    "import matplotlib.pyplot as plt  # For creating visualizations\n",
    "from matplotlib.animation import FuncAnimation  # For animated plots\n",
    "from IPython.display import HTML  # For displaying animations in notebook\n",
    "from mpl_toolkits.mplot3d import Axes3D  # For 3D plots\n",
    "\n",
    "# Set random seed for reproducibility (so we get same results every time)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Configure matplotlib for better-looking plots\n",
    "plt.style.use('seaborn-v0_8-darkgrid')  # Nice looking plot style\n",
    "plt.rcParams['figure.figsize'] = (12, 6)  # Default figure size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üèîÔ∏è Part 1: Gradient Descent - Finding the Way Downhill\n",
    "\n",
    "### The Mountain Analogy üèîÔ∏è\n",
    "\n",
    "Imagine you're **blindfolded** on a mountain and need to get to the bottom (lowest point). How do you do it?\n",
    "\n",
    "1. **Feel the ground around you** - which direction slopes down?\n",
    "2. **Take a step in that direction** - the steepest downward direction\n",
    "3. **Repeat** until you reach the bottom\n",
    "\n",
    "This is **exactly** what gradient descent does!\n",
    "\n",
    "- **Mountain height** = Loss (error)\n",
    "- **Your position** = Current weights\n",
    "- **Feeling the slope** = Computing gradients\n",
    "- **Taking a step** = Updating weights\n",
    "- **Bottom of mountain** = Minimum loss (best weights)\n",
    "\n",
    "### üí° Key Insight\n",
    "\n",
    "The **gradient** tells us:\n",
    "1. **Direction**: Which way to move (uphill or downhill)\n",
    "2. **Steepness**: How steep the slope is\n",
    "\n",
    "To minimize loss, we move in the **opposite direction** of the gradient (downhill)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's visualize a simple loss curve (1D example)\n",
    "# Imagine this is the loss as we change one weight\n",
    "\n",
    "def simple_loss_function(weight):\n",
    "    \"\"\"A simple quadratic loss function: (weight - 3)^2\n",
    "    The minimum is at weight = 3\"\"\"\n",
    "    return (weight - 3) ** 2\n",
    "\n",
    "def gradient_of_loss(weight):\n",
    "    \"\"\"The gradient (derivative) of our loss function\n",
    "    This tells us the slope at any point\"\"\"\n",
    "    return 2 * (weight - 3)\n",
    "\n",
    "# Create a range of weight values\n",
    "weights = np.linspace(0, 6, 100)  # 100 points from 0 to 6\n",
    "losses = simple_loss_function(weights)  # Calculate loss at each point\n",
    "\n",
    "# Create the plot\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Plot 1: Loss curve\n",
    "ax1.plot(weights, losses, 'b-', linewidth=2, label='Loss Function')\n",
    "ax1.axvline(x=3, color='r', linestyle='--', label='Minimum (optimal weight)')\n",
    "ax1.set_xlabel('Weight Value', fontsize=12)\n",
    "ax1.set_ylabel('Loss (Error)', fontsize=12)\n",
    "ax1.set_title('Loss Curve: Our Goal is to Reach the Bottom', fontsize=14, fontweight='bold')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Gradient (slope) at different points\n",
    "gradients = gradient_of_loss(weights)\n",
    "ax2.plot(weights, gradients, 'g-', linewidth=2, label='Gradient (Slope)')\n",
    "ax2.axhline(y=0, color='r', linestyle='--', label='Zero gradient (minimum)')\n",
    "ax2.axvline(x=3, color='r', linestyle='--', alpha=0.5)\n",
    "ax2.set_xlabel('Weight Value', fontsize=12)\n",
    "ax2.set_ylabel('Gradient', fontsize=12)\n",
    "ax2.set_title('Gradient Shows Us Which Way is Downhill', fontsize=14, fontweight='bold')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"üìä Understanding the plots:\")\n",
    "print(\"Left: The loss curve - we want to reach the minimum (red line)\")\n",
    "print(\"Right: The gradient at each point\")\n",
    "print(\"  ‚Ä¢ Positive gradient ‚Üí slope goes uphill ‚Üí move LEFT (decrease weight)\")\n",
    "print(\"  ‚Ä¢ Negative gradient ‚Üí slope goes downhill ‚Üí move RIGHT (increase weight)\")\n",
    "print(\"  ‚Ä¢ Zero gradient ‚Üí we're at the minimum! üéØ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üéØ Quick Summary\n",
    "\n",
    "**Gradient**: The slope of the loss function. It tells us:\n",
    "- If **positive**: loss increases as weight increases ‚Üí decrease the weight\n",
    "- If **negative**: loss decreases as weight increases ‚Üí increase the weight\n",
    "- If **zero**: we're at a minimum! (could be local or global)\n",
    "\n",
    "---\n",
    "\n",
    "## üö∂ Taking Steps: The Learning Rate\n",
    "\n",
    "Now we know **which direction** to move. But **how big** should our steps be?\n",
    "\n",
    "This is controlled by the **learning rate** (often denoted as Œ± or lr).\n",
    "\n",
    "### üê¢ Learning Rate Too Small\n",
    "- Baby steps\n",
    "- Very slow progress\n",
    "- Might take forever to reach the minimum\n",
    "\n",
    "### üê∞ Learning Rate Too Large\n",
    "- Giant leaps\n",
    "- Might overshoot the minimum\n",
    "- Could bounce around and never converge\n",
    "- Might even make things worse!\n",
    "\n",
    "### üéØ Learning Rate Just Right\n",
    "- Moderate steps\n",
    "- Steady progress toward minimum\n",
    "- Converges efficiently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see gradient descent in action with different learning rates!\n",
    "\n",
    "def gradient_descent_1d(starting_weight, learning_rate, num_steps):\n",
    "    \"\"\"Perform gradient descent to find the minimum\n",
    "    \n",
    "    Args:\n",
    "        starting_weight: Where we start\n",
    "        learning_rate: How big our steps are\n",
    "        num_steps: How many steps to take\n",
    "    \n",
    "    Returns:\n",
    "        history: List of (weight, loss) at each step\n",
    "    \"\"\"\n",
    "    weight = starting_weight  # Current weight\n",
    "    history = []  # Track our journey\n",
    "    \n",
    "    for step in range(num_steps):\n",
    "        # Calculate current loss\n",
    "        loss = simple_loss_function(weight)\n",
    "        history.append((weight, loss))\n",
    "        \n",
    "        # Calculate gradient (slope) at current position\n",
    "        grad = gradient_of_loss(weight)\n",
    "        \n",
    "        # Update weight: move in OPPOSITE direction of gradient\n",
    "        # (because we want to go downhill, not uphill!)\n",
    "        weight = weight - learning_rate * grad\n",
    "    \n",
    "    return history\n",
    "\n",
    "# Try three different learning rates\n",
    "learning_rates = [0.01, 0.3, 1.5]  # Too small, just right, too large\n",
    "starting_weight = 0.5  # We all start at the same place\n",
    "num_steps = 20  # Take 20 steps\n",
    "\n",
    "# Create the plot\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
    "titles = ['üê¢ Too Small (lr=0.01)', 'üéØ Just Right (lr=0.3)', 'üê∞ Too Large (lr=1.5)']\n",
    "\n",
    "for idx, (ax, lr, title) in enumerate(zip(axes, learning_rates, titles)):\n",
    "    # Run gradient descent\n",
    "    history = gradient_descent_1d(starting_weight, lr, num_steps)\n",
    "    weights_hist = [w for w, l in history]\n",
    "    losses_hist = [l for w, l in history]\n",
    "    \n",
    "    # Plot the loss curve\n",
    "    weights = np.linspace(0, 6, 100)\n",
    "    losses = simple_loss_function(weights)\n",
    "    ax.plot(weights, losses, 'b-', alpha=0.3, linewidth=2)\n",
    "    \n",
    "    # Plot the path taken by gradient descent\n",
    "    ax.plot(weights_hist, losses_hist, 'ro-', linewidth=2, markersize=8, label='GD path')\n",
    "    ax.plot(weights_hist[0], losses_hist[0], 'go', markersize=15, label='Start')\n",
    "    ax.plot(weights_hist[-1], losses_hist[-1], 'r*', markersize=20, label='End')\n",
    "    \n",
    "    # Mark the true minimum\n",
    "    ax.axvline(x=3, color='purple', linestyle='--', alpha=0.5, label='True minimum')\n",
    "    \n",
    "    ax.set_xlabel('Weight', fontsize=11)\n",
    "    ax.set_ylabel('Loss', fontsize=11)\n",
    "    ax.set_title(title, fontsize=13, fontweight='bold')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.set_ylim(-0.5, 15)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüéì What we learned:\")\n",
    "print(\"Left: Learning rate too small ‚Üí slow but steady progress\")\n",
    "print(\"Middle: Learning rate just right ‚Üí efficient convergence\")\n",
    "print(\"Right: Learning rate too large ‚Üí overshooting and instability!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚ö†Ô∏è Common Mistake\n",
    "\n",
    "**Don't forget to negate the gradient!**\n",
    "\n",
    "```python\n",
    "# ‚ùå WRONG - moves uphill!\n",
    "weight = weight + learning_rate * gradient\n",
    "\n",
    "# ‚úÖ CORRECT - moves downhill\n",
    "weight = weight - learning_rate * gradient\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## üîó Part 2: The Chain Rule - Connecting the Dots\n",
    "\n",
    "Before we tackle backpropagation, we need to understand the **chain rule**. This is the mathematical tool that makes backpropagation possible.\n",
    "\n",
    "### üöó Real-World Analogy: The Domino Effect\n",
    "\n",
    "Imagine you're planning a road trip:\n",
    "\n",
    "1. **Your driving speed** affects **distance traveled**\n",
    "2. **Distance traveled** affects **fuel consumed**\n",
    "3. **Fuel consumed** affects **total cost**\n",
    "\n",
    "```\n",
    "Speed ‚Üí Distance ‚Üí Fuel ‚Üí Cost\n",
    "```\n",
    "\n",
    "If you want to know: **\"How does my speed affect my total cost?\"**\n",
    "\n",
    "You need to consider the **chain of effects**:\n",
    "- Speed affects distance (faster = more miles)\n",
    "- Distance affects fuel (more miles = more fuel)\n",
    "- Fuel affects cost (more fuel = more money)\n",
    "\n",
    "The chain rule lets us calculate this total effect by **multiplying** the individual effects!\n",
    "\n",
    "### üìê Simple Mathematical Example\n",
    "\n",
    "Let's use actual numbers to make this concrete:\n",
    "\n",
    "Suppose:\n",
    "- You drive at **60 mph** for **2 hours**\n",
    "- Distance = Speed √ó Time\n",
    "- Cost = Distance √ó $0.50 per mile\n",
    "\n",
    "**Chain**: `Speed ‚Üí Distance ‚Üí Cost`\n",
    "\n",
    "Let's calculate the derivatives (rates of change):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple chain rule example with numbers\n",
    "\n",
    "# Given values\n",
    "time_hours = 2  # We drive for 2 hours\n",
    "cost_per_mile = 0.50  # $0.50 per mile\n",
    "\n",
    "# Functions\n",
    "def distance(speed):\n",
    "    \"\"\"Distance = Speed √ó Time\"\"\"\n",
    "    return speed * time_hours\n",
    "\n",
    "def cost(distance):\n",
    "    \"\"\"Cost = Distance √ó Cost per mile\"\"\"\n",
    "    return distance * cost_per_mile\n",
    "\n",
    "# Let's evaluate at speed = 60 mph\n",
    "speed = 60\n",
    "d = distance(speed)  # Calculate distance\n",
    "c = cost(d)  # Calculate cost\n",
    "\n",
    "print(\"üöó Forward Calculation (from speed to cost):\")\n",
    "print(f\"Speed: {speed} mph\")\n",
    "print(f\"Distance: {d} miles\")\n",
    "print(f\"Cost: ${c}\")\n",
    "print()\n",
    "\n",
    "# Now let's calculate derivatives (how much things change)\n",
    "print(\"üìä Derivatives (rates of change):\")\n",
    "print()\n",
    "\n",
    "# How does distance change with speed?\n",
    "# If speed increases by 1 mph, distance increases by time_hours miles\n",
    "d_distance_d_speed = time_hours\n",
    "print(f\"‚àÇdistance/‚àÇspeed = {d_distance_d_speed}\")\n",
    "print(f\"  ‚Üí If speed ‚Üë by 1 mph, distance ‚Üë by {d_distance_d_speed} miles\")\n",
    "print()\n",
    "\n",
    "# How does cost change with distance?\n",
    "# If distance increases by 1 mile, cost increases by $0.50\n",
    "d_cost_d_distance = cost_per_mile\n",
    "print(f\"‚àÇcost/‚àÇdistance = {d_cost_d_distance}\")\n",
    "print(f\"  ‚Üí If distance ‚Üë by 1 mile, cost ‚Üë by ${d_cost_d_distance}\")\n",
    "print()\n",
    "\n",
    "# CHAIN RULE: How does cost change with speed?\n",
    "# We multiply the two derivatives!\n",
    "d_cost_d_speed = d_distance_d_speed * d_cost_d_distance\n",
    "print(\"‚õìÔ∏è Chain Rule:\")\n",
    "print(f\"‚àÇcost/‚àÇspeed = (‚àÇcost/‚àÇdistance) √ó (‚àÇdistance/‚àÇspeed)\")\n",
    "print(f\"‚àÇcost/‚àÇspeed = {d_cost_d_distance} √ó {d_distance_d_speed} = {d_cost_d_speed}\")\n",
    "print(f\"  ‚Üí If speed ‚Üë by 1 mph, cost ‚Üë by ${d_cost_d_speed}\")\n",
    "print()\n",
    "\n",
    "# Verify with actual calculation\n",
    "print(\"‚úÖ Verification:\")\n",
    "speed_plus_1 = speed + 1\n",
    "cost_plus_1 = cost(distance(speed_plus_1))\n",
    "actual_change = cost_plus_1 - c\n",
    "print(f\"Cost at {speed} mph: ${c}\")\n",
    "print(f\"Cost at {speed_plus_1} mph: ${cost_plus_1}\")\n",
    "print(f\"Actual change: ${actual_change}\")\n",
    "print(f\"Predicted change (chain rule): ${d_cost_d_speed}\")\n",
    "print(f\"Match! ‚úì\" if abs(actual_change - d_cost_d_speed) < 0.01 else \"Mismatch ‚úó\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üí° Key Insight: The Chain Rule Formula\n",
    "\n",
    "If we have a chain: `A ‚Üí B ‚Üí C`\n",
    "\n",
    "To find how `C` changes with `A`, we multiply:\n",
    "\n",
    "$$\\frac{\\partial C}{\\partial A} = \\frac{\\partial C}{\\partial B} \\times \\frac{\\partial B}{\\partial A}$$\n",
    "\n",
    "In plain English:\n",
    "- **How C changes with A** = (**How C changes with B**) √ó (**How B changes with A**)\n",
    "\n",
    "For longer chains: `A ‚Üí B ‚Üí C ‚Üí D`, we keep multiplying:\n",
    "\n",
    "$$\\frac{\\partial D}{\\partial A} = \\frac{\\partial D}{\\partial C} \\times \\frac{\\partial C}{\\partial B} \\times \\frac{\\partial B}{\\partial A}$$\n",
    "\n",
    "**This is the foundation of backpropagation!**\n",
    "\n",
    "---\n",
    "\n",
    "## üîÑ Part 3: Backpropagation - Putting It All Together\n",
    "\n",
    "Now we're ready for the main event! **Backpropagation** is just applying the chain rule systematically to a neural network.\n",
    "\n",
    "### üß† The Neural Network Chain\n",
    "\n",
    "In a neural network, we have a chain like this:\n",
    "\n",
    "```\n",
    "Weights ‚Üí Weighted Sum ‚Üí Activation ‚Üí Output ‚Üí Loss\n",
    "```\n",
    "\n",
    "We want to know: **How does the loss change if we change a weight?**\n",
    "\n",
    "We use the chain rule, working **backward** from loss to weights:\n",
    "\n",
    "1. **Start at loss**: We know the error\n",
    "2. **Work backward**: How did each layer contribute to this error?\n",
    "3. **Assign blame**: Each weight gets a \"blame score\" (gradient)\n",
    "4. **Update weights**: Adjust weights to reduce their \"blame\"\n",
    "\n",
    "### üìã Step-by-Step: 2-Layer Network Example\n",
    "\n",
    "Let's build a tiny network and do backpropagation by hand!\n",
    "\n",
    "**Network Architecture:**\n",
    "- Input: 2 neurons (x‚ÇÅ, x‚ÇÇ)\n",
    "- Hidden layer: 2 neurons (h‚ÇÅ, h‚ÇÇ) with sigmoid activation\n",
    "- Output: 1 neuron (y) with sigmoid activation\n",
    "- Loss: Mean Squared Error (MSE)\n",
    "\n",
    "```\n",
    "Input     Hidden      Output\n",
    " x‚ÇÅ ‚îÄ‚îÄ‚îê   h‚ÇÅ ‚îÄ‚îÄ‚îê\n",
    "      ‚îú‚îÄ‚îÄ‚Üí    ‚îú‚îÄ‚îÄ‚Üí  y  ‚Üí Loss\n",
    " x‚ÇÇ ‚îÄ‚îÄ‚îò   h‚ÇÇ ‚îÄ‚îÄ‚îò\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's implement activation functions and their derivatives\n",
    "# (We learned about these in Notebook 3!)\n",
    "\n",
    "def sigmoid(x):\n",
    "    \"\"\"Sigmoid activation function: squashes values to (0, 1)\"\"\"\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    \"\"\"Derivative of sigmoid: sigmoid(x) * (1 - sigmoid(x))\n",
    "    This tells us how fast sigmoid is changing at point x\"\"\"\n",
    "    s = sigmoid(x)\n",
    "    return s * (1 - s)\n",
    "\n",
    "# Visualize sigmoid and its derivative\n",
    "x = np.linspace(-6, 6, 100)\n",
    "y_sigmoid = sigmoid(x)\n",
    "y_derivative = sigmoid_derivative(x)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "ax1.plot(x, y_sigmoid, 'b-', linewidth=2, label='sigmoid(x)')\n",
    "ax1.set_xlabel('x', fontsize=12)\n",
    "ax1.set_ylabel('sigmoid(x)', fontsize=12)\n",
    "ax1.set_title('Sigmoid Activation Function', fontsize=14, fontweight='bold')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.legend()\n",
    "\n",
    "ax2.plot(x, y_derivative, 'r-', linewidth=2, label=\"sigmoid'(x)\")\n",
    "ax2.set_xlabel('x', fontsize=12)\n",
    "ax2.set_ylabel(\"sigmoid'(x)\", fontsize=12)\n",
    "ax2.set_title('Derivative of Sigmoid (needed for backprop!)', fontsize=14, fontweight='bold')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"üí° Why we need the derivative:\")\n",
    "print(\"During backpropagation, we need to know how the activation function\")\n",
    "print(\"contributes to the gradient. The derivative tells us this!\")\n",
    "print(\"Notice: derivative is highest around x=0, and very small for large |x|\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üî¢ Numerical Example: Complete Forward and Backward Pass\n",
    "\n",
    "Let's do a complete example with actual numbers so you can see every step!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple 2-layer neural network with manual backpropagation\n",
    "# We'll use tiny numbers and print everything!\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"üß† COMPLETE BACKPROPAGATION EXAMPLE\")\n",
    "print(\"=\"*60)\n",
    "print()\n",
    "\n",
    "# --- SETUP ---\n",
    "print(\"üìã SETUP\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Input (2 features)\n",
    "X = np.array([0.5, 0.8])  # Our input data\n",
    "print(f\"Input X: {X}\")\n",
    "\n",
    "# True output (what we want the network to predict)\n",
    "y_true = 1.0\n",
    "print(f\"True output: {y_true}\")\n",
    "print()\n",
    "\n",
    "# Weights (randomly initialized, but we'll use fixed values for clarity)\n",
    "# Weights from input to hidden layer (2x2 matrix)\n",
    "W1 = np.array([[0.1, 0.3],   # Weights from x1 to [h1, h2]\n",
    "               [0.2, 0.4]])   # Weights from x2 to [h1, h2]\n",
    "b1 = np.array([0.1, 0.2])     # Biases for hidden layer\n",
    "\n",
    "print(\"Weights input‚Üíhidden (W1):\")\n",
    "print(W1)\n",
    "print(f\"Biases hidden (b1): {b1}\")\n",
    "print()\n",
    "\n",
    "# Weights from hidden to output layer (2x1 matrix)\n",
    "W2 = np.array([[0.5],   # Weight from h1 to output\n",
    "               [0.6]])   # Weight from h2 to output\n",
    "b2 = np.array([0.1])     # Bias for output\n",
    "\n",
    "print(\"Weights hidden‚Üíoutput (W2):\")\n",
    "print(W2)\n",
    "print(f\"Bias output (b2): {b2}\")\n",
    "print()\n",
    "\n",
    "learning_rate = 0.5  # How big our weight updates will be\n",
    "print(f\"Learning rate: {learning_rate}\")\n",
    "print()\n",
    "\n",
    "# --- FORWARD PASS ---\n",
    "print(\"=\"*60)\n",
    "print(\"‚û°Ô∏è FORWARD PASS (Input ‚Üí Prediction)\")\n",
    "print(\"=\"*60)\n",
    "print()\n",
    "\n",
    "# Hidden layer\n",
    "print(\"üîµ Hidden Layer:\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Weighted sum at hidden layer: z1 = X ¬∑ W1 + b1\n",
    "z1 = np.dot(X, W1) + b1\n",
    "print(f\"Weighted sum z1 = X¬∑W1 + b1\")\n",
    "print(f\"  = {X} ¬∑ {W1.T} + {b1}\")\n",
    "print(f\"  = {z1}\")\n",
    "print()\n",
    "\n",
    "# Activation: apply sigmoid\n",
    "h = sigmoid(z1)\n",
    "print(f\"Hidden activation h = sigmoid(z1)\")\n",
    "print(f\"  = sigmoid({z1})\")\n",
    "print(f\"  = {h}\")\n",
    "print()\n",
    "\n",
    "# Output layer\n",
    "print(\"üî¥ Output Layer:\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Weighted sum at output: z2 = h ¬∑ W2 + b2\n",
    "z2 = np.dot(h, W2) + b2\n",
    "print(f\"Weighted sum z2 = h¬∑W2 + b2\")\n",
    "print(f\"  = {h} ¬∑ {W2.T} + {b2}\")\n",
    "print(f\"  = {z2}\")\n",
    "print()\n",
    "\n",
    "# Final prediction: apply sigmoid\n",
    "y_pred = sigmoid(z2)\n",
    "print(f\"Prediction y_pred = sigmoid(z2)\")\n",
    "print(f\"  = sigmoid({z2})\")\n",
    "print(f\"  = {y_pred}\")\n",
    "print()\n",
    "\n",
    "# Loss calculation (Mean Squared Error)\n",
    "print(\"üí• Loss Calculation:\")\n",
    "print(\"-\" * 60)\n",
    "loss = 0.5 * (y_pred - y_true) ** 2  # MSE\n",
    "print(f\"Loss = 0.5 √ó (y_pred - y_true)¬≤\")\n",
    "print(f\"     = 0.5 √ó ({y_pred[0]:.4f} - {y_true})¬≤\")\n",
    "print(f\"     = {loss[0]:.6f}\")\n",
    "print()\n",
    "\n",
    "# --- BACKWARD PASS (BACKPROPAGATION!) ---\n",
    "print(\"=\"*60)\n",
    "print(\"‚¨ÖÔ∏è BACKWARD PASS (Error ‚Üí Weight Updates)\")\n",
    "print(\"=\"*60)\n",
    "print()\n",
    "\n",
    "print(\"üéØ Our goal: Calculate how much each weight contributed to the error\")\n",
    "print(\"Then adjust weights in the opposite direction!\")\n",
    "print()\n",
    "\n",
    "# Step 1: Gradient of loss with respect to prediction\n",
    "print(\"Step 1Ô∏è‚É£: How does loss change with prediction?\")\n",
    "print(\"-\" * 60)\n",
    "dL_dy = y_pred - y_true  # Derivative of MSE: (y_pred - y_true)\n",
    "print(f\"‚àÇLoss/‚àÇy_pred = y_pred - y_true\")\n",
    "print(f\"              = {y_pred[0]:.4f} - {y_true}\")\n",
    "print(f\"              = {dL_dy[0]:.4f}\")\n",
    "print(\"This tells us if prediction is too high (+) or too low (-)\")\n",
    "print()\n",
    "\n",
    "# Step 2: Gradient at output layer (before activation)\n",
    "print(\"Step 2Ô∏è‚É£: How does loss change with output layer weighted sum?\")\n",
    "print(\"-\" * 60)\n",
    "# Chain rule: dL/dz2 = dL/dy √ó dy/dz2\n",
    "dy_dz2 = sigmoid_derivative(z2)  # Derivative of sigmoid\n",
    "dL_dz2 = dL_dy * dy_dz2\n",
    "print(f\"‚àÇLoss/‚àÇz2 = (‚àÇLoss/‚àÇy) √ó (‚àÇy/‚àÇz2)\")\n",
    "print(f\"          = {dL_dy[0]:.4f} √ó sigmoid'({z2[0]:.4f})\")\n",
    "print(f\"          = {dL_dy[0]:.4f} √ó {dy_dz2[0]:.4f}\")\n",
    "print(f\"          = {dL_dz2[0]:.4f}\")\n",
    "print(\"Chain rule in action! We multiplied two gradients.\")\n",
    "print()\n",
    "\n",
    "# Step 3: Gradients for W2 and b2\n",
    "print(\"Step 3Ô∏è‚É£: How does loss change with output weights W2 and bias b2?\")\n",
    "print(\"-\" * 60)\n",
    "# dL/dW2 = dL/dz2 √ó dz2/dW2 = dL/dz2 √ó h (because z2 = h¬∑W2 + b2)\n",
    "dL_dW2 = np.outer(h, dL_dz2)  # Outer product\n",
    "print(f\"‚àÇLoss/‚àÇW2 = (‚àÇLoss/‚àÇz2) √ó (‚àÇz2/‚àÇW2)\")\n",
    "print(f\"          = {dL_dz2[0]:.4f} √ó {h}\")\n",
    "print(f\"          = {dL_dW2.flatten()}\")\n",
    "print()\n",
    "\n",
    "dL_db2 = dL_dz2  # dz2/db2 = 1, so gradient is just dL_dz2\n",
    "print(f\"‚àÇLoss/‚àÇb2 = {dL_db2[0]:.4f}\")\n",
    "print()\n",
    "\n",
    "# Step 4: Gradient flowing back to hidden layer\n",
    "print(\"Step 4Ô∏è‚É£: How does loss change with hidden layer activations?\")\n",
    "print(\"-\" * 60)\n",
    "# dL/dh = dL/dz2 √ó dz2/dh = dL/dz2 √ó W2\n",
    "dL_dh = np.dot(dL_dz2, W2.T)\n",
    "print(f\"‚àÇLoss/‚àÇh = (‚àÇLoss/‚àÇz2) √ó W2·µÄ\")\n",
    "print(f\"         = {dL_dz2[0]:.4f} √ó {W2.T}\")\n",
    "print(f\"         = {dL_dh}\")\n",
    "print(\"The error is propagated back through the weights!\")\n",
    "print()\n",
    "\n",
    "# Step 5: Gradient at hidden layer (before activation)\n",
    "print(\"Step 5Ô∏è‚É£: How does loss change with hidden layer weighted sum?\")\n",
    "print(\"-\" * 60)\n",
    "# dL/dz1 = dL/dh √ó dh/dz1\n",
    "dh_dz1 = sigmoid_derivative(z1)\n",
    "dL_dz1 = dL_dh * dh_dz1\n",
    "print(f\"‚àÇLoss/‚àÇz1 = (‚àÇLoss/‚àÇh) √ó (‚àÇh/‚àÇz1)\")\n",
    "print(f\"          = {dL_dh} √ó sigmoid'({z1})\")\n",
    "print(f\"          = {dL_dh} √ó {dh_dz1}\")\n",
    "print(f\"          = {dL_dz1}\")\n",
    "print()\n",
    "\n",
    "# Step 6: Gradients for W1 and b1\n",
    "print(\"Step 6Ô∏è‚É£: How does loss change with input weights W1 and bias b1?\")\n",
    "print(\"-\" * 60)\n",
    "# dL/dW1 = dL/dz1 √ó dz1/dW1 = dL/dz1 √ó X\n",
    "dL_dW1 = np.outer(X, dL_dz1)\n",
    "print(f\"‚àÇLoss/‚àÇW1 = (‚àÇLoss/‚àÇz1) √ó X·µÄ\")\n",
    "print(f\"          = {X} √ó {dL_dz1}\")\n",
    "print(\"Result:\")\n",
    "print(dL_dW1)\n",
    "print()\n",
    "\n",
    "dL_db1 = dL_dz1\n",
    "print(f\"‚àÇLoss/‚àÇb1 = {dL_db1}\")\n",
    "print()\n",
    "\n",
    "# --- WEIGHT UPDATE ---\n",
    "print(\"=\"*60)\n",
    "print(\"üîÑ WEIGHT UPDATE (Gradient Descent Step)\")\n",
    "print(\"=\"*60)\n",
    "print()\n",
    "\n",
    "print(\"Formula: new_weight = old_weight - learning_rate √ó gradient\")\n",
    "print()\n",
    "\n",
    "# Update all weights\n",
    "W2_new = W2 - learning_rate * dL_dW2\n",
    "b2_new = b2 - learning_rate * dL_db2\n",
    "W1_new = W1 - learning_rate * dL_dW1\n",
    "b1_new = b1 - learning_rate * dL_db1\n",
    "\n",
    "print(\"Output layer updates:\")\n",
    "print(f\"W2: {W2.flatten()} ‚Üí {W2_new.flatten()}\")\n",
    "print(f\"b2: {b2} ‚Üí {b2_new}\")\n",
    "print()\n",
    "print(\"Hidden layer updates:\")\n",
    "print(f\"W1:\")\n",
    "print(f\"  Old:\\n{W1}\")\n",
    "print(f\"  New:\\n{W1_new}\")\n",
    "print(f\"b1: {b1} ‚Üí {b1_new}\")\n",
    "print()\n",
    "\n",
    "# Verify improvement\n",
    "print(\"=\"*60)\n",
    "print(\"‚úÖ VERIFICATION: Did we improve?\")\n",
    "print(\"=\"*60)\n",
    "print()\n",
    "\n",
    "# Forward pass with new weights\n",
    "z1_new = np.dot(X, W1_new) + b1_new\n",
    "h_new = sigmoid(z1_new)\n",
    "z2_new = np.dot(h_new, W2_new) + b2_new\n",
    "y_pred_new = sigmoid(z2_new)\n",
    "loss_new = 0.5 * (y_pred_new - y_true) ** 2\n",
    "\n",
    "print(f\"Before update:\")\n",
    "print(f\"  Prediction: {y_pred[0]:.6f}\")\n",
    "print(f\"  Loss: {loss[0]:.6f}\")\n",
    "print()\n",
    "print(f\"After update:\")\n",
    "print(f\"  Prediction: {y_pred_new[0]:.6f}\")\n",
    "print(f\"  Loss: {loss_new[0]:.6f}\")\n",
    "print()\n",
    "print(f\"Improvement: {loss[0] - loss_new[0]:.6f} (loss decreased by {((loss[0] - loss_new[0]) / loss[0] * 100):.2f}%)\")\n",
    "print()\n",
    "print(\"üéâ Success! The loss went down, meaning we're learning!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üéØ Quick Summary: What Just Happened?\n",
    "\n",
    "1. **Forward Pass**: Computed prediction from inputs\n",
    "2. **Loss**: Measured how wrong we were\n",
    "3. **Backward Pass**: Used chain rule to compute gradients\n",
    "   - Started from loss\n",
    "   - Worked backward through each layer\n",
    "   - Calculated how much each weight contributed to error\n",
    "4. **Weight Update**: Adjusted weights to reduce error\n",
    "5. **Result**: Loss decreased! üéâ\n",
    "\n",
    "---\n",
    "\n",
    "## üõ†Ô∏è Part 4: Complete Implementation from Scratch\n",
    "\n",
    "Now let's put it all together in a clean, reusable implementation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoLayerNetwork:\n",
    "    \"\"\"A simple 2-layer neural network with backpropagation\n",
    "    \n",
    "    This class implements:\n",
    "    - Forward propagation\n",
    "    - Loss calculation\n",
    "    - Backpropagation\n",
    "    - Weight updates\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, output_size, learning_rate=0.1):\n",
    "        \"\"\"Initialize the network with random weights\n",
    "        \n",
    "        Args:\n",
    "            input_size: Number of input features\n",
    "            hidden_size: Number of neurons in hidden layer\n",
    "            output_size: Number of output neurons\n",
    "            learning_rate: Step size for gradient descent\n",
    "        \"\"\"\n",
    "        # Initialize weights with small random values\n",
    "        # (We multiply by 0.5 to keep values small)\n",
    "        self.W1 = np.random.randn(input_size, hidden_size) * 0.5\n",
    "        self.b1 = np.zeros(hidden_size)  # Biases start at zero\n",
    "        \n",
    "        self.W2 = np.random.randn(hidden_size, output_size) * 0.5\n",
    "        self.b2 = np.zeros(output_size)\n",
    "        \n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "        # Storage for intermediate values (needed for backprop)\n",
    "        self.cache = {}\n",
    "    \n",
    "    def forward(self, X):\n",
    "        \"\"\"Forward pass: compute predictions\n",
    "        \n",
    "        Args:\n",
    "            X: Input data (batch_size, input_size)\n",
    "        \n",
    "        Returns:\n",
    "            y_pred: Predictions (batch_size, output_size)\n",
    "        \"\"\"\n",
    "        # Hidden layer\n",
    "        z1 = np.dot(X, self.W1) + self.b1  # Weighted sum\n",
    "        h = sigmoid(z1)  # Activation\n",
    "        \n",
    "        # Output layer\n",
    "        z2 = np.dot(h, self.W2) + self.b2  # Weighted sum\n",
    "        y_pred = sigmoid(z2)  # Activation\n",
    "        \n",
    "        # Save intermediate values for backpropagation\n",
    "        self.cache = {\n",
    "            'X': X,\n",
    "            'z1': z1,\n",
    "            'h': h,\n",
    "            'z2': z2,\n",
    "            'y_pred': y_pred\n",
    "        }\n",
    "        \n",
    "        return y_pred\n",
    "    \n",
    "    def compute_loss(self, y_pred, y_true):\n",
    "        \"\"\"Compute Mean Squared Error loss\n",
    "        \n",
    "        Args:\n",
    "            y_pred: Predictions from network\n",
    "            y_true: True labels\n",
    "        \n",
    "        Returns:\n",
    "            loss: Average loss across all samples\n",
    "        \"\"\"\n",
    "        # MSE = mean of (prediction - true)^2\n",
    "        return np.mean((y_pred - y_true) ** 2)\n",
    "    \n",
    "    def backward(self, y_true):\n",
    "        \"\"\"Backward pass: compute gradients using backpropagation\n",
    "        \n",
    "        Args:\n",
    "            y_true: True labels\n",
    "        \n",
    "        Returns:\n",
    "            gradients: Dictionary of gradients for all parameters\n",
    "        \"\"\"\n",
    "        # Get cached values from forward pass\n",
    "        X = self.cache['X']\n",
    "        z1 = self.cache['z1']\n",
    "        h = self.cache['h']\n",
    "        z2 = self.cache['z2']\n",
    "        y_pred = self.cache['y_pred']\n",
    "        \n",
    "        batch_size = X.shape[0]  # Number of samples\n",
    "        \n",
    "        # --- Backward pass through output layer ---\n",
    "        \n",
    "        # Gradient of loss w.r.t. predictions\n",
    "        dL_dy = 2 * (y_pred - y_true) / batch_size  # Average over batch\n",
    "        \n",
    "        # Gradient of loss w.r.t. z2 (before activation)\n",
    "        # Chain rule: dL/dz2 = dL/dy √ó dy/dz2\n",
    "        dy_dz2 = sigmoid_derivative(z2)\n",
    "        dL_dz2 = dL_dy * dy_dz2\n",
    "        \n",
    "        # Gradients for W2 and b2\n",
    "        dL_dW2 = np.dot(h.T, dL_dz2)  # (hidden_size, output_size)\n",
    "        dL_db2 = np.sum(dL_dz2, axis=0)  # Sum across batch\n",
    "        \n",
    "        # --- Backward pass through hidden layer ---\n",
    "        \n",
    "        # Gradient of loss w.r.t. hidden activations\n",
    "        # Chain rule: dL/dh = dL/dz2 √ó dz2/dh = dL/dz2 √ó W2\n",
    "        dL_dh = np.dot(dL_dz2, self.W2.T)\n",
    "        \n",
    "        # Gradient of loss w.r.t. z1 (before activation)\n",
    "        # Chain rule: dL/dz1 = dL/dh √ó dh/dz1\n",
    "        dh_dz1 = sigmoid_derivative(z1)\n",
    "        dL_dz1 = dL_dh * dh_dz1\n",
    "        \n",
    "        # Gradients for W1 and b1\n",
    "        dL_dW1 = np.dot(X.T, dL_dz1)  # (input_size, hidden_size)\n",
    "        dL_db1 = np.sum(dL_dz1, axis=0)  # Sum across batch\n",
    "        \n",
    "        # Return all gradients\n",
    "        return {\n",
    "            'dW1': dL_dW1,\n",
    "            'db1': dL_db1,\n",
    "            'dW2': dL_dW2,\n",
    "            'db2': dL_db2\n",
    "        }\n",
    "    \n",
    "    def update_weights(self, gradients):\n",
    "        \"\"\"Update weights using gradient descent\n",
    "        \n",
    "        Args:\n",
    "            gradients: Dictionary of gradients from backward pass\n",
    "        \"\"\"\n",
    "        # Update each parameter: param = param - learning_rate √ó gradient\n",
    "        self.W1 -= self.learning_rate * gradients['dW1']\n",
    "        self.b1 -= self.learning_rate * gradients['db1']\n",
    "        self.W2 -= self.learning_rate * gradients['dW2']\n",
    "        self.b2 -= self.learning_rate * gradients['db2']\n",
    "    \n",
    "    def train_step(self, X, y_true):\n",
    "        \"\"\"Complete training step: forward, backward, update\n",
    "        \n",
    "        Args:\n",
    "            X: Input data\n",
    "            y_true: True labels\n",
    "        \n",
    "        Returns:\n",
    "            loss: Current loss value\n",
    "        \"\"\"\n",
    "        # Forward pass\n",
    "        y_pred = self.forward(X)\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = self.compute_loss(y_pred, y_true)\n",
    "        \n",
    "        # Backward pass\n",
    "        gradients = self.backward(y_true)\n",
    "        \n",
    "        # Update weights\n",
    "        self.update_weights(gradients)\n",
    "        \n",
    "        return loss\n",
    "\n",
    "print(\"‚úÖ TwoLayerNetwork class implemented!\")\n",
    "print(\"This class can:\")\n",
    "print(\"  ‚Ä¢ Forward propagate (make predictions)\")\n",
    "print(\"  ‚Ä¢ Compute loss\")\n",
    "print(\"  ‚Ä¢ Backpropagate (compute gradients)\")\n",
    "print(\"  ‚Ä¢ Update weights\")\n",
    "print(\"\\nLet's test it on the XOR problem!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üß™ Testing on XOR Problem\n",
    "\n",
    "XOR (exclusive OR) is a classic problem that can't be solved by a single neuron (it's not linearly separable). But our 2-layer network can learn it!\n",
    "\n",
    "**XOR Truth Table:**\n",
    "```\n",
    "Input 1 | Input 2 | Output\n",
    "--------|---------|--------\n",
    "   0    |    0    |   0\n",
    "   0    |    1    |   1\n",
    "   1    |    0    |   1\n",
    "   1    |    1    |   0\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XOR dataset\n",
    "X_xor = np.array([\n",
    "    [0, 0],\n",
    "    [0, 1],\n",
    "    [1, 0],\n",
    "    [1, 1]\n",
    "])\n",
    "\n",
    "y_xor = np.array([\n",
    "    [0],\n",
    "    [1],\n",
    "    [1],\n",
    "    [0]\n",
    "])\n",
    "\n",
    "print(\"XOR Problem:\")\n",
    "print(\"Inputs:\\n\", X_xor)\n",
    "print(\"\\nTargets:\\n\", y_xor.flatten())\n",
    "print()\n",
    "\n",
    "# Create and train network\n",
    "np.random.seed(42)  # For reproducibility\n",
    "network = TwoLayerNetwork(\n",
    "    input_size=2,\n",
    "    hidden_size=4,  # 4 hidden neurons\n",
    "    output_size=1,\n",
    "    learning_rate=0.5\n",
    ")\n",
    "\n",
    "# Train for many iterations\n",
    "num_iterations = 5000\n",
    "losses = []\n",
    "\n",
    "print(\"Training network on XOR...\")\n",
    "print()\n",
    "\n",
    "for i in range(num_iterations):\n",
    "    # Train on entire dataset\n",
    "    loss = network.train_step(X_xor, y_xor)\n",
    "    losses.append(loss)\n",
    "    \n",
    "    # Print progress every 1000 iterations\n",
    "    if (i + 1) % 1000 == 0:\n",
    "        print(f\"Iteration {i+1:4d} | Loss: {loss:.6f}\")\n",
    "\n",
    "print(\"\\nTraining complete!\")\n",
    "print()\n",
    "\n",
    "# Test the network\n",
    "predictions = network.forward(X_xor)\n",
    "\n",
    "print(\"Final Results:\")\n",
    "print(\"=\"*50)\n",
    "print(\"Input 1 | Input 2 | Target | Prediction | Rounded\")\n",
    "print(\"-\"*50)\n",
    "for i in range(len(X_xor)):\n",
    "    x1, x2 = X_xor[i]\n",
    "    target = y_xor[i, 0]\n",
    "    pred = predictions[i, 0]\n",
    "    rounded = round(pred)\n",
    "    print(f\"   {x1}    |    {x2}    |   {target}    |   {pred:.4f}   |    {rounded}\")\n",
    "\n",
    "print()\n",
    "accuracy = np.mean((predictions > 0.5) == y_xor) * 100\n",
    "print(f\"Accuracy: {accuracy:.1f}%\")\n",
    "print()\n",
    "print(\"üéâ The network learned XOR through backpropagation!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the training process\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Plot 1: Loss over time\n",
    "ax1.plot(losses, 'b-', linewidth=2)\n",
    "ax1.set_xlabel('Iteration', fontsize=12)\n",
    "ax1.set_ylabel('Loss (MSE)', fontsize=12)\n",
    "ax1.set_title('Loss Decreases Over Time (Learning!)', fontsize=14, fontweight='bold')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.set_yscale('log')  # Log scale to see details\n",
    "\n",
    "# Plot 2: Decision boundary\n",
    "# Create a grid of points\n",
    "xx, yy = np.meshgrid(np.linspace(-0.5, 1.5, 100),\n",
    "                     np.linspace(-0.5, 1.5, 100))\n",
    "grid_points = np.c_[xx.ravel(), yy.ravel()]\n",
    "\n",
    "# Predict for all grid points\n",
    "Z = network.forward(grid_points)\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "# Plot decision boundary\n",
    "contour = ax2.contourf(xx, yy, Z, levels=20, cmap='RdYlBu', alpha=0.7)\n",
    "ax2.contour(xx, yy, Z, levels=[0.5], colors='black', linewidths=2)\n",
    "\n",
    "# Plot the XOR points\n",
    "scatter = ax2.scatter(X_xor[:, 0], X_xor[:, 1], c=y_xor.flatten(),\n",
    "                     cmap='RdYlBu', s=200, edgecolors='black', linewidths=3)\n",
    "\n",
    "ax2.set_xlabel('Input 1', fontsize=12)\n",
    "ax2.set_ylabel('Input 2', fontsize=12)\n",
    "ax2.set_title('Decision Boundary: Network Learned XOR!', fontsize=14, fontweight='bold')\n",
    "plt.colorbar(contour, ax=ax2, label='Prediction')\n",
    "\n",
    "# Add labels for each point\n",
    "for i, (x, y, label) in enumerate(zip(X_xor[:, 0], X_xor[:, 1], y_xor.flatten())):\n",
    "    ax2.text(x+0.05, y+0.05, f'({int(x)},{int(y)})‚Üí{int(label)}',\n",
    "             fontsize=10, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüìä Understanding the visualizations:\")\n",
    "print(\"Left: Loss curve shows learning progress - it goes down!\")\n",
    "print(\"Right: Decision boundary separates the two classes\")\n",
    "print(\"  ‚Ä¢ Blue regions = network predicts 0\")\n",
    "print(\"  ‚Ä¢ Red regions = network predicts 1\")\n",
    "print(\"  ‚Ä¢ The network learned the non-linear XOR pattern!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üí° Key Insight: Why Backpropagation Works\n",
    "\n",
    "Backpropagation works because:\n",
    "\n",
    "1. **Chain Rule**: Allows us to decompose complex derivatives\n",
    "2. **Systematic**: Works backward layer by layer\n",
    "3. **Efficient**: Each gradient computed only once\n",
    "4. **General**: Works for any network architecture\n",
    "\n",
    "Without backpropagation, we couldn't train deep neural networks!\n",
    "\n",
    "---\n",
    "\n",
    "## ‚ö†Ô∏è Part 5: Common Issues with Backpropagation\n",
    "\n",
    "### 1. Vanishing Gradients üìâ\n",
    "\n",
    "**Problem**: Gradients become extremely small as they propagate backward\n",
    "\n",
    "**Why it happens**:\n",
    "- Sigmoid derivative is at most 0.25\n",
    "- Multiply many small numbers ‚Üí very small gradient\n",
    "- Deep networks: gradient = product of many derivatives\n",
    "\n",
    "**Example**: In a 5-layer network with sigmoid:\n",
    "- Each layer multiplies gradient by ‚â§ 0.25\n",
    "- Final gradient ‚â§ 0.25‚Åµ = 0.00098 (very small!)\n",
    "- Early layers barely update ‚Üí slow learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate vanishing gradients with sigmoid\n",
    "\n",
    "# Simulate gradients flowing through multiple sigmoid layers\n",
    "num_layers = [1, 2, 3, 5, 10]  # Different network depths\n",
    "initial_gradient = 1.0  # Start with gradient of 1\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# For each network depth\n",
    "for n in num_layers:\n",
    "    gradients = [initial_gradient]\n",
    "    \n",
    "    # Simulate gradient flowing back through n layers\n",
    "    current_grad = initial_gradient\n",
    "    for layer in range(n):\n",
    "        # Sigmoid derivative at z=0 is 0.25 (maximum value)\n",
    "        # In practice, it's often smaller\n",
    "        current_grad *= 0.25  # Multiply by sigmoid derivative\n",
    "        gradients.append(current_grad)\n",
    "    \n",
    "    # Plot gradient at each layer\n",
    "    layers = list(range(len(gradients)))\n",
    "    ax1.plot(layers, gradients, 'o-', linewidth=2, markersize=8, label=f'{n} layers')\n",
    "\n",
    "ax1.set_xlabel('Layer (from output to input)', fontsize=12)\n",
    "ax1.set_ylabel('Gradient Magnitude', fontsize=12)\n",
    "ax1.set_title('Vanishing Gradients with Sigmoid', fontsize=14, fontweight='bold')\n",
    "ax1.set_yscale('log')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Compare sigmoid vs ReLU derivatives\n",
    "x = np.linspace(-5, 5, 100)\n",
    "sigmoid_deriv = sigmoid_derivative(x)\n",
    "relu_deriv = (x > 0).astype(float)  # ReLU derivative: 0 if x<0, 1 if x>0\n",
    "\n",
    "ax2.plot(x, sigmoid_deriv, 'b-', linewidth=2, label='Sigmoid derivative')\n",
    "ax2.plot(x, relu_deriv, 'r-', linewidth=2, label='ReLU derivative')\n",
    "ax2.set_xlabel('x', fontsize=12)\n",
    "ax2.set_ylabel('Derivative', fontsize=12)\n",
    "ax2.set_title('Why ReLU Helps: Derivative is 0 or 1', fontsize=14, fontweight='bold')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "ax2.set_ylim(-0.1, 1.1)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"‚ö†Ô∏è Vanishing Gradient Problem:\")\n",
    "print(\"Left: Gradients shrink exponentially in deep networks with sigmoid\")\n",
    "print(\"Right: ReLU has constant derivative of 1 (when x > 0)\")\n",
    "print(\"\\nSolution: Use ReLU instead of sigmoid in hidden layers!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Exploding Gradients üí•\n",
    "\n",
    "**Problem**: Gradients become extremely large\n",
    "\n",
    "**Why it happens**:\n",
    "- Large weight values\n",
    "- Multiply many large numbers ‚Üí explosion\n",
    "- Network becomes unstable\n",
    "\n",
    "**Solutions**:\n",
    "- **Gradient clipping**: Cap gradients at a maximum value\n",
    "- **Better weight initialization**: Start with smaller weights\n",
    "- **Batch normalization**: Normalize activations\n",
    "\n",
    "### 3. Dead ReLU Problem üíÄ\n",
    "\n",
    "**Problem**: ReLU neurons can \"die\" and stop learning\n",
    "\n",
    "**Why it happens**:\n",
    "- If a neuron's output is always negative, ReLU always outputs 0\n",
    "- Gradient is always 0 ‚Üí no weight updates ‚Üí neuron is \"dead\"\n",
    "\n",
    "**Solution**: Use Leaky ReLU or other variants\n",
    "\n",
    "---\n",
    "\n",
    "## üéÆ Interactive Experiments\n",
    "\n",
    "### Experiment 1: Effect of Learning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train networks with different learning rates\n",
    "learning_rates = [0.01, 0.1, 0.5, 2.0]\n",
    "num_iterations = 3000\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, lr in enumerate(learning_rates):\n",
    "    # Create network with specific learning rate\n",
    "    np.random.seed(42)  # Same initialization for fair comparison\n",
    "    network = TwoLayerNetwork(\n",
    "        input_size=2,\n",
    "        hidden_size=4,\n",
    "        output_size=1,\n",
    "        learning_rate=lr\n",
    "    )\n",
    "    \n",
    "    # Train\n",
    "    losses = []\n",
    "    for i in range(num_iterations):\n",
    "        loss = network.train_step(X_xor, y_xor)\n",
    "        losses.append(loss)\n",
    "    \n",
    "    # Plot\n",
    "    ax = axes[idx]\n",
    "    ax.plot(losses, linewidth=2)\n",
    "    ax.set_xlabel('Iteration', fontsize=11)\n",
    "    ax.set_ylabel('Loss', fontsize=11)\n",
    "    ax.set_title(f'Learning Rate = {lr}', fontsize=13, fontweight='bold')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.set_ylim(0, 0.3)\n",
    "    \n",
    "    # Final loss\n",
    "    final_loss = losses[-1]\n",
    "    ax.text(0.6, 0.9, f'Final: {final_loss:.4f}',\n",
    "            transform=ax.transAxes, fontsize=11,\n",
    "            bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"üéØ Try it yourself!\")\n",
    "print(\"Change the learning_rates list above and re-run to see different behaviors.\")\n",
    "print(\"\\nWhat to look for:\")\n",
    "print(\"‚Ä¢ Too small (0.01): Slow, steady decrease\")\n",
    "print(\"‚Ä¢ Just right (0.1-0.5): Fast convergence\")\n",
    "print(\"‚Ä¢ Too large (2.0): Unstable, might diverge\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 2: Visualizing Gradient Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize how gradients flow through the network\n",
    "\n",
    "# Create and train a small network\n",
    "np.random.seed(42)\n",
    "network = TwoLayerNetwork(input_size=2, hidden_size=3, output_size=1, learning_rate=0.5)\n",
    "\n",
    "# Do one forward pass\n",
    "y_pred = network.forward(X_xor)\n",
    "\n",
    "# Do one backward pass\n",
    "gradients = network.backward(y_xor)\n",
    "\n",
    "# Visualize the network and gradient magnitudes\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "# Layer positions\n",
    "layer_x = [0, 1, 2]  # Input, Hidden, Output\n",
    "layer_sizes = [2, 3, 1]  # Neurons in each layer\n",
    "\n",
    "# Draw neurons\n",
    "neuron_positions = {}\n",
    "for layer_idx, (x, size) in enumerate(zip(layer_x, layer_sizes)):\n",
    "    y_positions = np.linspace(0, 1, size + 2)[1:-1]  # Evenly spaced\n",
    "    for neuron_idx, y in enumerate(y_positions):\n",
    "        circle = plt.Circle((x, y), 0.08, color='lightblue', ec='black', linewidth=2)\n",
    "        ax.add_patch(circle)\n",
    "        neuron_positions[(layer_idx, neuron_idx)] = (x, y)\n",
    "        \n",
    "        # Label neurons\n",
    "        if layer_idx == 0:\n",
    "            ax.text(x-0.15, y, f'x{neuron_idx+1}', fontsize=10, ha='right')\n",
    "        elif layer_idx == 1:\n",
    "            ax.text(x, y-0.15, f'h{neuron_idx+1}', fontsize=10, ha='center')\n",
    "        else:\n",
    "            ax.text(x+0.15, y, 'y', fontsize=10, ha='left')\n",
    "\n",
    "# Draw connections with gradient-based colors\n",
    "# Connections from input to hidden\n",
    "max_grad_w1 = np.max(np.abs(gradients['dW1']))\n",
    "for i in range(2):  # Input neurons\n",
    "    for j in range(3):  # Hidden neurons\n",
    "        x1, y1 = neuron_positions[(0, i)]\n",
    "        x2, y2 = neuron_positions[(1, j)]\n",
    "        \n",
    "        # Color based on gradient magnitude\n",
    "        grad_magnitude = np.abs(gradients['dW1'][i, j])\n",
    "        color_intensity = grad_magnitude / max_grad_w1\n",
    "        color = plt.cm.Reds(color_intensity)\n",
    "        \n",
    "        ax.plot([x1, x2], [y1, y2], color=color, linewidth=2, alpha=0.7)\n",
    "\n",
    "# Connections from hidden to output\n",
    "max_grad_w2 = np.max(np.abs(gradients['dW2']))\n",
    "for i in range(3):  # Hidden neurons\n",
    "    for j in range(1):  # Output neurons\n",
    "        x1, y1 = neuron_positions[(1, i)]\n",
    "        x2, y2 = neuron_positions[(2, j)]\n",
    "        \n",
    "        grad_magnitude = np.abs(gradients['dW2'][i, j])\n",
    "        color_intensity = grad_magnitude / max_grad_w2\n",
    "        color = plt.cm.Reds(color_intensity)\n",
    "        \n",
    "        ax.plot([x1, x2], [y1, y2], color=color, linewidth=2, alpha=0.7)\n",
    "\n",
    "# Labels\n",
    "ax.text(0, -0.2, 'Input\\nLayer', fontsize=12, ha='center', fontweight='bold')\n",
    "ax.text(1, -0.2, 'Hidden\\nLayer', fontsize=12, ha='center', fontweight='bold')\n",
    "ax.text(2, -0.2, 'Output\\nLayer', fontsize=12, ha='center', fontweight='bold')\n",
    "\n",
    "ax.set_xlim(-0.5, 2.5)\n",
    "ax.set_ylim(-0.3, 1.2)\n",
    "ax.set_aspect('equal')\n",
    "ax.axis('off')\n",
    "ax.set_title('Gradient Flow Visualization\\n(Darker red = larger gradient)', \n",
    "             fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"üìä Gradient magnitudes:\")\n",
    "print(f\"\\nInput ‚Üí Hidden (W1):\")\n",
    "print(gradients['dW1'])\n",
    "print(f\"\\nHidden ‚Üí Output (W2):\")\n",
    "print(gradients['dW2'])\n",
    "print(\"\\nüí° Darker connections have larger gradients (will update more)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéØ Final Summary\n",
    "\n",
    "Congratulations! You've learned the most important algorithm in deep learning. Let's recap:\n",
    "\n",
    "### What is Backpropagation?\n",
    "\n",
    "**Backpropagation** is an algorithm for computing gradients efficiently using the chain rule:\n",
    "\n",
    "1. **Forward Pass**: Compute predictions layer by layer\n",
    "2. **Compute Loss**: Measure how wrong we are\n",
    "3. **Backward Pass**: Work backward computing gradients\n",
    "4. **Update Weights**: Adjust weights to reduce loss\n",
    "\n",
    "### Key Concepts\n",
    "\n",
    "‚úÖ **Gradient Descent**: Follow the slope downhill to minimize loss\n",
    "\n",
    "‚úÖ **Learning Rate**: Controls step size (too small = slow, too large = unstable)\n",
    "\n",
    "‚úÖ **Chain Rule**: Multiply derivatives to propagate gradients backward\n",
    "\n",
    "‚úÖ **Vanishing Gradients**: Problem with sigmoid (solution: use ReLU)\n",
    "\n",
    "‚úÖ **Systematic Process**: Same algorithm works for any network architecture\n",
    "\n",
    "### Why It's Important\n",
    "\n",
    "- **Enables Learning**: Without backprop, we couldn't train neural networks\n",
    "- **Efficient**: Computes all gradients in one backward pass\n",
    "- **General**: Works for any differentiable function\n",
    "- **Foundation**: Powers all modern deep learning\n",
    "\n",
    "### What's Next?\n",
    "\n",
    "We've learned how to update weights **once**. But one update isn't enough!\n",
    "\n",
    "In the next notebook, we'll learn about the **training loop** - the process of:\n",
    "- Repeating forward/backward passes many times\n",
    "- Processing data in batches\n",
    "- Tracking progress over epochs\n",
    "- Choosing hyperparameters\n",
    "- Building complete, trainable networks\n",
    "\n",
    "---\n",
    "\n",
    "## üéì Review Questions\n",
    "\n",
    "Test your understanding:\n",
    "\n",
    "1. **What does the gradient tell us?**\n",
    "   - The direction and magnitude of steepest increase in loss\n",
    "   - We move in the opposite direction to decrease loss\n",
    "\n",
    "2. **Why do we need the chain rule?**\n",
    "   - To compute how changes in early layers affect the final loss\n",
    "   - To propagate gradients backward through multiple layers\n",
    "\n",
    "3. **What's the vanishing gradient problem?**\n",
    "   - Gradients become very small in deep networks with sigmoid\n",
    "   - Early layers barely learn\n",
    "   - Solution: Use ReLU activation\n",
    "\n",
    "4. **Why is learning rate important?**\n",
    "   - Too small: slow learning\n",
    "   - Too large: unstable, might diverge\n",
    "   - Need to choose carefully\n",
    "\n",
    "5. **Can you explain backpropagation in one sentence?**\n",
    "   - Use the chain rule to compute gradients by working backward through the network, then update weights to reduce loss.\n",
    "\n",
    "---\n",
    "\n",
    "## üí™ Challenge Exercises\n",
    "\n",
    "Ready to test your skills?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Challenge 1: Implement ReLU and its derivative\n",
    "def relu(x):\n",
    "    \"\"\"TODO: Implement ReLU activation\n",
    "    ReLU(x) = max(0, x)\n",
    "    \"\"\"\n",
    "    pass  # Your code here!\n",
    "\n",
    "def relu_derivative(x):\n",
    "    \"\"\"TODO: Implement ReLU derivative\n",
    "    ReLU'(x) = 1 if x > 0, else 0\n",
    "    \"\"\"\n",
    "    pass  # Your code here!\n",
    "\n",
    "# Test your implementation\n",
    "# test_x = np.array([-2, -1, 0, 1, 2])\n",
    "# print(\"ReLU:\", relu(test_x))\n",
    "# print(\"ReLU':\", relu_derivative(test_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Challenge 2: Modify TwoLayerNetwork to use ReLU instead of sigmoid\n",
    "# Hint: You'll need to:\n",
    "# 1. Change activation function in forward pass\n",
    "# 2. Change derivative in backward pass\n",
    "# 3. Keep sigmoid for output layer (for binary classification)\n",
    "\n",
    "# Your code here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Challenge 3: Add momentum to gradient descent\n",
    "# Momentum helps accelerate learning in the right direction\n",
    "# Update rule: velocity = momentum * velocity + learning_rate * gradient\n",
    "#              weight = weight - velocity\n",
    "\n",
    "# Your code here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéâ Congratulations!\n",
    "\n",
    "You've conquered backpropagation - the hardest concept in neural networks!\n",
    "\n",
    "You now understand:\n",
    "- How neural networks learn from data\n",
    "- The mathematics behind gradient descent\n",
    "- How to implement backpropagation from scratch\n",
    "- Common problems and their solutions\n",
    "\n",
    "**This is a HUGE achievement!** Many people struggle with this topic, but you've made it through. üåü\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "In **Notebook 8: Training Loop**, we'll put everything together and learn how to:\n",
    "- Train networks on real datasets\n",
    "- Choose hyperparameters effectively\n",
    "- Monitor training progress\n",
    "- Avoid overfitting\n",
    "- Build production-ready models\n",
    "\n",
    "You're almost there! One more notebook and you'll have built a complete neural network from scratch! üöÄ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}