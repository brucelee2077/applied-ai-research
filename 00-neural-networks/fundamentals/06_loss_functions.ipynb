{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 6: Loss Functions\n",
    "\n",
    "## Measuring How Wrong We Are üìè\n",
    "\n",
    "Welcome back! In our journey so far, we've learned:\n",
    "- What neural networks are (Notebook 1)\n",
    "- How neurons work (Notebook 2)\n",
    "- Activation functions (Notebook 3)\n",
    "- Creating layers (Notebook 4)\n",
    "- Forward propagation (Notebook 5)\n",
    "\n",
    "Now we can make predictions... but they're terrible! Why? Because our weights are random.\n",
    "\n",
    "**The Big Question**: How do we measure how wrong our predictions are?\n",
    "\n",
    "**The Answer**: Loss Functions! üéØ\n",
    "\n",
    "### üéì The Report Card Analogy\n",
    "\n",
    "Think of a loss function like a teacher grading your test:\n",
    "- **Your Answer**: What the network predicted\n",
    "- **Correct Answer**: What the actual target is\n",
    "- **Score**: How far off you were (the loss)\n",
    "\n",
    "The **lower the loss**, the **better the predictions**!\n",
    "\n",
    "### üó∫Ô∏è The GPS Analogy\n",
    "\n",
    "Imagine you're trying to reach a destination:\n",
    "- **Current Position**: Your prediction\n",
    "- **Destination**: The target value\n",
    "- **Distance**: The loss (how far you are from the goal)\n",
    "\n",
    "Your goal: **Minimize the distance** (loss) to reach the destination!\n",
    "\n",
    "Let's learn how to measure this distance! üîß"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import our essential tools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"‚úÖ Libraries imported successfully!\")\n",
    "print(\"üì¶ NumPy version:\", np.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Why Do We Need Loss Functions?\n",
    "\n",
    "Our network makes predictions, but we need to:\n",
    "1. **Quantify errors**: Turn bad prediction into a number\n",
    "2. **Compare predictions**: Know which is better\n",
    "3. **Guide learning**: Tell the network which direction to improve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Mean Squared Error (MSE) üìä\n",
    "\n",
    "### üéØ Use Case: Regression Problems\n",
    "\n",
    "**When to use MSE**: Predicting continuous numbers like house prices, temperature, stock prices.\n",
    "\n",
    "### üìê Formula: MSE = (1/n) √ó Œ£(predicted - actual)¬≤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_squared_error(y_true, y_pred):\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    errors = y_pred - y_true\n",
    "    squared_errors = errors ** 2\n",
    "    mse = np.mean(squared_errors)\n",
    "    return mse\n",
    "\n",
    "print(\"‚úÖ MSE function defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Binary Cross-Entropy üîÄ\n",
    "\n",
    "### üéØ Use Case: Binary Classification\n",
    "\n",
    "**When to use**: Classifying into TWO classes (Spam vs Not Spam, Cat vs Dog)\n",
    "\n",
    "### üìê Formula: BCE = -[y√ólog(p) + (1-y)√ólog(1-p)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_cross_entropy(y_true, y_pred, epsilon=1e-15):\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    y_pred = np.clip(y_pred, epsilon, 1 - epsilon)\n",
    "    loss = -(y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred))\n",
    "    bce = np.mean(loss)\n",
    "    return bce\n",
    "\n",
    "print(\"‚úÖ Binary Cross-Entropy function defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Categorical Cross-Entropy üé®\n",
    "\n",
    "### üéØ Use Case: Multi-Class Classification\n",
    "\n",
    "**When to use**: Classifying into 3+ classes (digit recognition, image classification)\n",
    "\n",
    "### üìê Formula: CCE = -Œ£Œ£ y√ólog(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorical_cross_entropy(y_true, y_pred, epsilon=1e-15):\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    y_pred = np.clip(y_pred, epsilon, 1 - epsilon)\n",
    "    sample_losses = -np.sum(y_true * np.log(y_pred), axis=1)\n",
    "    cce = np.mean(sample_losses)\n",
    "    return cce\n",
    "\n",
    "def softmax(x):\n",
    "    exp_x = np.exp(x - np.max(x, axis=-1, keepdims=True))\n",
    "    return exp_x / np.sum(exp_x, axis=-1, keepdims=True)\n",
    "\n",
    "print(\"‚úÖ Categorical Cross-Entropy function defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### üéâ What We Learned:\n",
    "\n",
    "1. **Mean Squared Error (MSE)**: For regression\n",
    "2. **Binary Cross-Entropy**: For binary classification  \n",
    "3. **Categorical Cross-Entropy**: For multi-class classification\n",
    "\n",
    "### üîÆ What's Next?\n",
    "\n",
    "Now we know how to measure errors. Next: **Backpropagation** - how to fix them!\n",
    "\n",
    "Ready to learn how networks actually LEARN? üöÄ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}