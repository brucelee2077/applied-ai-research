{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {},
   "source": [
    "# üìâ Pooling Layers - Smarter Downsampling\n",
    "\n",
    "Welcome to pooling! The unsung hero of CNNs! üéâ\n",
    "\n",
    "In the previous notebooks, we learned about convolution - the star of CNNs. Now let's meet its supporting actor: **pooling**! While not as flashy, pooling plays a crucial role in making CNNs work efficiently.\n",
    "\n",
    "## üéØ What You'll Learn\n",
    "\n",
    "By the end of this notebook, you'll understand:\n",
    "- **What is pooling** and why we need it\n",
    "- **Max pooling** - keeping the strongest signals\n",
    "- **Average pooling** - smooth downsampling\n",
    "- **When to use each** type of pooling\n",
    "- **Translation invariance** - why pooling helps recognition\n",
    "- **Implementing pooling** from scratch in NumPy\n",
    "- **Global pooling** - a special case\n",
    "- **Alternatives** to pooling in modern CNNs\n",
    "\n",
    "**Prerequisites:** Notebooks 01-02 (What are CNNs, Convolution Operation)\n",
    "\n",
    "---\n",
    "\n",
    "## üñºÔ∏è The Photo Resizing Analogy\n",
    "\n",
    "Think of pooling like **resizing a photo**:\n",
    "- **Original**: 1000√ó1000 pixels (huge!)\n",
    "- **Thumbnail**: 100√ó100 pixels (manageable!)\n",
    "\n",
    "But how do we shrink it?\n",
    "- **Max pooling**: Take the brightest pixel from each region\n",
    "- **Average pooling**: Take the average color of each region\n",
    "\n",
    "Both make the image smaller while preserving important information! üìê\n",
    "\n",
    "Let's explore! üöÄ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import our tools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Configure matplotlib for better plots\n",
    "plt.rcParams['figure.figsize'] = (14, 6)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "print(\"‚úÖ Libraries imported successfully!\")\n",
    "print(f\"üì¶ NumPy version: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "what-is-pooling",
   "metadata": {},
   "source": [
    "---\n",
    "## ü§î What is Pooling?\n",
    "\n",
    "### üéØ The Core Idea\n",
    "\n",
    "**Pooling** is a downsampling operation that:\n",
    "- **Reduces spatial dimensions** (makes feature maps smaller)\n",
    "- **Keeps important information** (doesn't throw away everything)\n",
    "- **Has no learnable parameters** (just a fixed operation)\n",
    "\n",
    "### üìê How It Works\n",
    "\n",
    "1. **Divide** feature map into non-overlapping regions (e.g., 2√ó2 blocks)\n",
    "2. **Apply** pooling operation to each region\n",
    "3. **Output** one value per region\n",
    "\n",
    "**Result**: Smaller feature map! üéØ\n",
    "\n",
    "### ü§∑ Why Do We Need Pooling?\n",
    "\n",
    "**Problem without pooling:**\n",
    "```\n",
    "Input: 224√ó224√ó3\n",
    "After Conv1: 224√ó224√ó64\n",
    "After Conv2: 224√ó224√ó128\n",
    "After Conv3: 224√ó224√ó256\n",
    "...\n",
    "```\n",
    "\n",
    "Feature maps stay HUGE! üò±\n",
    "- Too much memory\n",
    "- Too much computation\n",
    "- Too many parameters in FC layers\n",
    "\n",
    "**Solution: Pooling!**\n",
    "```\n",
    "Input: 224√ó224√ó3\n",
    "Conv1: 224√ó224√ó64 ‚Üí Pool: 112√ó112√ó64  ‚úÖ Halved!\n",
    "Conv2: 112√ó112√ó128 ‚Üí Pool: 56√ó56√ó128  ‚úÖ Halved!\n",
    "Conv3: 56√ó56√ó256 ‚Üí Pool: 28√ó28√ó256    ‚úÖ Halved!\n",
    "```\n",
    "\n",
    "Much more manageable! üéâ\n",
    "\n",
    "### üéÅ Benefits of Pooling\n",
    "\n",
    "‚úÖ **Reduces computational cost** (smaller feature maps)\n",
    "‚úÖ **Provides translation invariance** (small shifts don't matter)\n",
    "‚úÖ **Increases receptive field** (each neuron sees more of the image)\n",
    "‚úÖ **Helps prevent overfitting** (reduces parameters in FC layers)\n",
    "‚úÖ **Makes network more robust** (less sensitive to exact positions)\n",
    "\n",
    "Let's see pooling in action!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pooling-visual-intro",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a simple example to show pooling effect\n",
    "simple_image = np.array([\n",
    "    [1, 3, 2, 4],\n",
    "    [5, 6, 7, 8],\n",
    "    [9, 2, 1, 3],\n",
    "    [4, 5, 8, 7]\n",
    "])\n",
    "\n",
    "print(\"üñºÔ∏è  Simple 4√ó4 Image:\")\n",
    "print(simple_image)\n",
    "print(f\"\\nShape: {simple_image.shape}\")\n",
    "print(f\"Total elements: {simple_image.size}\")\n",
    "\n",
    "# Manually compute 2x2 max pooling\n",
    "pooled = np.array([\n",
    "    [np.max(simple_image[0:2, 0:2]), np.max(simple_image[0:2, 2:4])],\n",
    "    [np.max(simple_image[2:4, 0:2]), np.max(simple_image[2:4, 2:4])]\n",
    "])\n",
    "\n",
    "print(\"\\nüìâ After 2√ó2 Max Pooling:\")\n",
    "print(pooled)\n",
    "print(f\"\\nShape: {pooled.shape}\")\n",
    "print(f\"Total elements: {pooled.size}\")\n",
    "\n",
    "print(\"\\nüéØ What Happened:\")\n",
    "print(f\"   ‚Ä¢ Original: 4√ó4 = 16 values\")\n",
    "print(f\"   ‚Ä¢ After pooling: 2√ó2 = 4 values\")\n",
    "print(f\"   ‚Ä¢ Reduction: {(1 - pooled.size/simple_image.size)*100:.0f}% fewer values!\")\n",
    "print(\"\\nüí° Pooling kept the MAXIMUM value from each 2√ó2 region\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "max-pooling-section",
   "metadata": {},
   "source": [
    "---\n",
    "## üèÜ Max Pooling - Keep the Winner!\n",
    "\n",
    "### üéØ The Idea\n",
    "\n",
    "**Max pooling** takes the MAXIMUM value from each pooling window.\n",
    "\n",
    "```\n",
    "Input region:     Max pooling result:\n",
    "[1  3]              6\n",
    "[5  6]              ‚Üë\n",
    "                (takes maximum)\n",
    "```\n",
    "\n",
    "### ü§î Why Maximum?\n",
    "\n",
    "Think about what feature maps represent:\n",
    "- **High values** = strong feature detected\n",
    "- **Low values** = weak feature detected\n",
    "\n",
    "**Max pooling says:** \"I only care about the STRONGEST signal in this region!\"\n",
    "\n",
    "This makes sense because:\n",
    "- If a cat ear is detected somewhere in a region, that's what matters\n",
    "- Exact position within the region is less important\n",
    "- We want to preserve strong activations\n",
    "\n",
    "### üìê Max Pooling Algorithm\n",
    "\n",
    "```python\n",
    "for each non-overlapping window in the feature map:\n",
    "    output[i, j] = max(window)\n",
    "```\n",
    "\n",
    "**Common configuration**: 2√ó2 windows, stride 2\n",
    "- Result: Feature map size halved in each dimension\n",
    "- Channels remain unchanged\n",
    "\n",
    "Let's implement it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "max-pooling-implementation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_pool2d(input_data, pool_size=2, stride=2):\n",
    "    \"\"\"\n",
    "    Perform 2D max pooling.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    input_data : np.ndarray, shape (H, W) or (H, W, C)\n",
    "        Input feature map(s)\n",
    "    pool_size : int\n",
    "        Size of pooling window (pool_size √ó pool_size)\n",
    "    stride : int\n",
    "        Step size between pooling windows\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    output : np.ndarray\n",
    "        Pooled feature map(s)\n",
    "    \"\"\"\n",
    "    # Handle both 2D and 3D inputs\n",
    "    if input_data.ndim == 2:\n",
    "        # Add channel dimension\n",
    "        input_data = input_data[:, :, np.newaxis]\n",
    "        squeeze_output = True\n",
    "    else:\n",
    "        squeeze_output = False\n",
    "    \n",
    "    height, width, channels = input_data.shape\n",
    "    \n",
    "    # Calculate output dimensions\n",
    "    out_height = (height - pool_size) // stride + 1\n",
    "    out_width = (width - pool_size) // stride + 1\n",
    "    \n",
    "    # Initialize output\n",
    "    output = np.zeros((out_height, out_width, channels))\n",
    "    \n",
    "    # Perform max pooling\n",
    "    for c in range(channels):\n",
    "        for i in range(out_height):\n",
    "            for j in range(out_width):\n",
    "                # Calculate window boundaries\n",
    "                h_start = i * stride\n",
    "                h_end = h_start + pool_size\n",
    "                w_start = j * stride\n",
    "                w_end = w_start + pool_size\n",
    "                \n",
    "                # Extract window\n",
    "                window = input_data[h_start:h_end, w_start:w_end, c]\n",
    "                \n",
    "                # Take maximum\n",
    "                output[i, j, c] = np.max(window)\n",
    "    \n",
    "    # Remove channel dimension if input was 2D\n",
    "    if squeeze_output:\n",
    "        output = output[:, :, 0]\n",
    "    \n",
    "    return output\n",
    "\n",
    "# Test with our simple example\n",
    "print(\"üß™ Testing Max Pooling Implementation\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nOriginal 4√ó4 image:\")\n",
    "print(simple_image)\n",
    "\n",
    "pooled = max_pool2d(simple_image, pool_size=2, stride=2)\n",
    "\n",
    "print(\"\\nAfter 2√ó2 max pooling (stride=2):\")\n",
    "print(pooled)\n",
    "\n",
    "print(\"\\n‚úÖ Implementation works correctly!\")\n",
    "print(f\"\\nüìä Size reduction: {simple_image.shape} ‚Üí {pooled.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "visualize-max-pooling",
   "metadata": {},
   "source": [
    "### üé® Visualizing Max Pooling\n",
    "\n",
    "Let's see exactly what max pooling does at each position!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visualize-max-pool",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a more interesting 8√ó8 test image\n",
    "test_image = np.random.randint(0, 10, size=(8, 8))\n",
    "\n",
    "# Apply max pooling\n",
    "pooled_image = max_pool2d(test_image, pool_size=2, stride=2)\n",
    "\n",
    "# Visualize the process\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
    "\n",
    "# Plot 1: Original image with grid\n",
    "ax1 = axes[0]\n",
    "im1 = ax1.imshow(test_image, cmap='viridis', interpolation='nearest')\n",
    "ax1.set_title('Original Image (8√ó8)', fontsize=13, fontweight='bold')\n",
    "\n",
    "# Draw 2√ó2 pooling regions\n",
    "for i in range(0, 8, 2):\n",
    "    for j in range(0, 8, 2):\n",
    "        rect = Rectangle((j-0.5, i-0.5), 2, 2,\n",
    "                        linewidth=3, edgecolor='red', facecolor='none')\n",
    "        ax1.add_patch(rect)\n",
    "\n",
    "# Add values\n",
    "for i in range(8):\n",
    "    for j in range(8):\n",
    "        ax1.text(j, i, f'{test_image[i, j]}',\n",
    "                ha='center', va='center',\n",
    "                color='white', fontweight='bold', fontsize=9)\n",
    "\n",
    "ax1.set_xticks(range(8))\n",
    "ax1.set_yticks(range(8))\n",
    "ax1.grid(True, color='white', linewidth=0.5)\n",
    "plt.colorbar(im1, ax=ax1, fraction=0.046, pad=0.04)\n",
    "\n",
    "# Plot 2: Pooled image\n",
    "ax2 = axes[1]\n",
    "im2 = ax2.imshow(pooled_image, cmap='viridis', interpolation='nearest')\n",
    "ax2.set_title('After Max Pooling (4√ó4)', fontsize=13, fontweight='bold')\n",
    "\n",
    "# Add values\n",
    "for i in range(4):\n",
    "    for j in range(4):\n",
    "        ax2.text(j, i, f'{pooled_image[i, j]:.0f}',\n",
    "                ha='center', va='center',\n",
    "                color='white', fontweight='bold', fontsize=11)\n",
    "\n",
    "ax2.set_xticks(range(4))\n",
    "ax2.set_yticks(range(4))\n",
    "ax2.grid(True, color='white', linewidth=1)\n",
    "plt.colorbar(im2, ax=ax2, fraction=0.046, pad=0.04)\n",
    "\n",
    "# Plot 3: Show one pooling region in detail\n",
    "ax3 = axes[2]\n",
    "ax3.axis('off')\n",
    "ax3.set_xlim(0, 10)\n",
    "ax3.set_ylim(0, 10)\n",
    "ax3.set_title('Example: One Pooling Operation', fontsize=13, fontweight='bold')\n",
    "\n",
    "# Show a 2√ó2 region\n",
    "example_region = test_image[0:2, 0:2]\n",
    "example_max = pooled_image[0, 0]\n",
    "\n",
    "# Draw the region\n",
    "region_str = f\"Region:\\n\"\n",
    "for i in range(2):\n",
    "    region_str += \"  \".join([f\"{example_region[i, j]:2.0f}\" for j in range(2)]) + \"\\n\"\n",
    "\n",
    "ax3.text(5, 7, region_str, ha='center', va='top',\n",
    "        fontsize=14, family='monospace', fontweight='bold',\n",
    "        bbox=dict(boxstyle='round,pad=1', facecolor='lightblue',\n",
    "                 edgecolor='blue', linewidth=3))\n",
    "\n",
    "# Draw arrow\n",
    "ax3.annotate('', xy=(5, 4), xytext=(5, 5.5),\n",
    "            arrowprops=dict(arrowstyle='->', lw=3, color='red'))\n",
    "ax3.text(5, 4.8, 'max()', ha='center', fontsize=12, fontweight='bold', color='red')\n",
    "\n",
    "# Draw result\n",
    "ax3.text(5, 3, f\"Result: {example_max:.0f}\", ha='center', va='top',\n",
    "        fontsize=16, fontweight='bold',\n",
    "        bbox=dict(boxstyle='round,pad=1', facecolor='lightgreen',\n",
    "                 edgecolor='green', linewidth=3))\n",
    "\n",
    "ax3.text(5, 1, f'Maximum of {example_region.flatten().tolist()}\\nis {example_max:.0f}',\n",
    "        ha='center', fontsize=11, style='italic')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüéØ Key Observations:\")\n",
    "print(\"   ‚Ä¢ Each 2√ó2 region (red boxes) becomes one output value\")\n",
    "print(\"   ‚Ä¢ Output value = maximum from that region\")\n",
    "print(\"   ‚Ä¢ Spatial size reduced by factor of 2 (8√ó8 ‚Üí 4√ó4)\")\n",
    "print(\"   ‚Ä¢ Channels remain unchanged (applies independently to each channel)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "avg-pooling-section",
   "metadata": {},
   "source": [
    "---\n",
    "## üìä Average Pooling - Take the Mean\n",
    "\n",
    "### üéØ The Idea\n",
    "\n",
    "**Average pooling** takes the AVERAGE (mean) value from each pooling window.\n",
    "\n",
    "```\n",
    "Input region:     Average pooling result:\n",
    "[1  3]              3.75\n",
    "[5  6]               ‚Üë\n",
    "              (1+3+5+6)/4 = 3.75\n",
    "```\n",
    "\n",
    "### ü§î Why Average?\n",
    "\n",
    "Average pooling is **smoother** than max pooling:\n",
    "- Considers all values in the region (not just the max)\n",
    "- Less aggressive downsampling\n",
    "- Preserves more information about the overall pattern\n",
    "\n",
    "### üìä Max vs Average: When to Use?\n",
    "\n",
    "**Max Pooling** üèÜ:\n",
    "- Most common in modern CNNs\n",
    "- Good for detecting features (\"is this feature present?\")\n",
    "- Preserves strong activations\n",
    "- More translation invariant\n",
    "\n",
    "**Average Pooling** üìä:\n",
    "- Smoother, less aggressive\n",
    "- Good for preserving overall structure\n",
    "- Often used in final layers (global average pooling)\n",
    "- Less prone to noise\n",
    "\n",
    "Let's implement average pooling!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "avg-pooling-implementation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_pool2d(input_data, pool_size=2, stride=2):\n",
    "    \"\"\"\n",
    "    Perform 2D average pooling.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    input_data : np.ndarray, shape (H, W) or (H, W, C)\n",
    "        Input feature map(s)\n",
    "    pool_size : int\n",
    "        Size of pooling window\n",
    "    stride : int\n",
    "        Step size between pooling windows\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    output : np.ndarray\n",
    "        Pooled feature map(s)\n",
    "    \"\"\"\n",
    "    # Handle both 2D and 3D inputs\n",
    "    if input_data.ndim == 2:\n",
    "        input_data = input_data[:, :, np.newaxis]\n",
    "        squeeze_output = True\n",
    "    else:\n",
    "        squeeze_output = False\n",
    "    \n",
    "    height, width, channels = input_data.shape\n",
    "    \n",
    "    # Calculate output dimensions\n",
    "    out_height = (height - pool_size) // stride + 1\n",
    "    out_width = (width - pool_size) // stride + 1\n",
    "    \n",
    "    # Initialize output\n",
    "    output = np.zeros((out_height, out_width, channels))\n",
    "    \n",
    "    # Perform average pooling\n",
    "    for c in range(channels):\n",
    "        for i in range(out_height):\n",
    "            for j in range(out_width):\n",
    "                # Calculate window boundaries\n",
    "                h_start = i * stride\n",
    "                h_end = h_start + pool_size\n",
    "                w_start = j * stride\n",
    "                w_end = w_start + pool_size\n",
    "                \n",
    "                # Extract window\n",
    "                window = input_data[h_start:h_end, w_start:w_end, c]\n",
    "                \n",
    "                # Take average (mean)\n",
    "                output[i, j, c] = np.mean(window)\n",
    "    \n",
    "    if squeeze_output:\n",
    "        output = output[:, :, 0]\n",
    "    \n",
    "    return output\n",
    "\n",
    "# Test with our simple example\n",
    "print(\"üß™ Testing Average Pooling Implementation\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nOriginal 4√ó4 image:\")\n",
    "print(simple_image)\n",
    "\n",
    "avg_pooled = avg_pool2d(simple_image, pool_size=2, stride=2)\n",
    "\n",
    "print(\"\\nAfter 2√ó2 average pooling (stride=2):\")\n",
    "print(avg_pooled)\n",
    "\n",
    "print(\"\\n‚úÖ Implementation works correctly!\")\n",
    "\n",
    "# Show the calculation for one region\n",
    "region = simple_image[0:2, 0:2]\n",
    "print(f\"\\nüîç Example calculation for top-left region:\")\n",
    "print(f\"   Region: {region.flatten()}\")\n",
    "print(f\"   Average: ({' + '.join(map(str, region.flatten()))}) / 4 = {np.mean(region):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compare-pooling",
   "metadata": {},
   "source": [
    "### ‚öñÔ∏è Comparing Max and Average Pooling\n",
    "\n",
    "Let's see them side-by-side on the same image!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compare-max-avg",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a test image with clear features\n",
    "test_img = np.array([\n",
    "    [1, 2, 3, 4, 5, 6, 7, 8],\n",
    "    [2, 9, 3, 5, 6, 8, 7, 9],  # High value (9) in this region\n",
    "    [3, 4, 5, 6, 7, 8, 9, 1],\n",
    "    [4, 5, 6, 2, 8, 9, 1, 2],\n",
    "    [5, 6, 7, 8, 1, 2, 3, 4],\n",
    "    [6, 7, 8, 9, 2, 3, 4, 5],\n",
    "    [7, 8, 9, 1, 3, 4, 5, 6],\n",
    "    [8, 9, 1, 2, 4, 5, 6, 7]\n",
    "])\n",
    "\n",
    "# Apply both types of pooling\n",
    "max_pooled = max_pool2d(test_img, pool_size=2, stride=2)\n",
    "avg_pooled = avg_pool2d(test_img, pool_size=2, stride=2)\n",
    "\n",
    "# Visualize comparison\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
    "\n",
    "# Original\n",
    "im0 = axes[0].imshow(test_img, cmap='hot', interpolation='nearest')\n",
    "axes[0].set_title('Original Image (8√ó8)', fontsize=13, fontweight='bold')\n",
    "for i in range(8):\n",
    "    for j in range(8):\n",
    "        axes[0].text(j, i, f'{test_img[i, j]}',\n",
    "                    ha='center', va='center',\n",
    "                    color='white', fontweight='bold', fontsize=8)\n",
    "axes[0].grid(True, color='gray', linewidth=0.5)\n",
    "plt.colorbar(im0, ax=axes[0], fraction=0.046, pad=0.04)\n",
    "\n",
    "# Max pooling\n",
    "im1 = axes[1].imshow(max_pooled, cmap='hot', interpolation='nearest')\n",
    "axes[1].set_title('Max Pooling (4√ó4)\\n\"Keep strongest signals\"',\n",
    "                 fontsize=13, fontweight='bold')\n",
    "for i in range(4):\n",
    "    for j in range(4):\n",
    "        axes[1].text(j, i, f'{max_pooled[i, j]:.1f}',\n",
    "                    ha='center', va='center',\n",
    "                    color='white', fontweight='bold', fontsize=10)\n",
    "axes[1].grid(True, color='gray', linewidth=1)\n",
    "plt.colorbar(im1, ax=axes[1], fraction=0.046, pad=0.04)\n",
    "\n",
    "# Average pooling\n",
    "im2 = axes[2].imshow(avg_pooled, cmap='hot', interpolation='nearest')\n",
    "axes[2].set_title('Average Pooling (4√ó4)\\n\"Smooth downsampling\"',\n",
    "                 fontsize=13, fontweight='bold')\n",
    "for i in range(4):\n",
    "    for j in range(4):\n",
    "        axes[2].text(j, i, f'{avg_pooled[i, j]:.1f}',\n",
    "                    ha='center', va='center',\n",
    "                    color='white', fontweight='bold', fontsize=10)\n",
    "axes[2].grid(True, color='gray', linewidth=1)\n",
    "plt.colorbar(im2, ax=axes[2], fraction=0.046, pad=0.04)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Compare statistics\n",
    "print(\"\\nüìä Comparison Statistics:\")\n",
    "print(\"=\"*70)\n",
    "print(f\"{'Metric':<25} {'Max Pooling':<20} {'Average Pooling':<20}\")\n",
    "print(\"=\"*70)\n",
    "print(f\"{'Output range':<25} [{max_pooled.min():.1f}, {max_pooled.max():.1f}]\" + \n",
    "      f\"{' '*8} [{avg_pooled.min():.1f}, {avg_pooled.max():.1f}]\")\n",
    "print(f\"{'Mean value':<25} {max_pooled.mean():.2f}\" + \n",
    "      f\"{' '*15} {avg_pooled.mean():.2f}\")\n",
    "print(f\"{'Std deviation':<25} {max_pooled.std():.2f}\" + \n",
    "      f\"{' '*15} {avg_pooled.std():.2f}\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nüéØ Key Differences:\")\n",
    "print(\"   ‚Ä¢ Max pooling preserves high values (peaks)\")\n",
    "print(\"   ‚Ä¢ Average pooling is smoother (less extreme values)\")\n",
    "print(\"   ‚Ä¢ Max pooling has higher variance\")\n",
    "print(\"   ‚Ä¢ Average pooling mean ‚âà original mean\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "translation-invariance",
   "metadata": {},
   "source": [
    "---\n",
    "## üîÑ Translation Invariance - The Magic of Pooling\n",
    "\n",
    "### üéØ What is Translation Invariance?\n",
    "\n",
    "**Translation invariance** means: \"Small shifts in input don't change output\"\n",
    "\n",
    "**Why is this important?**\n",
    "- A cat is still a cat whether it's on the left or right of the image\n",
    "- We want the network to recognize objects regardless of their exact position\n",
    "- Small movements shouldn't dramatically change activations\n",
    "\n",
    "### üé® How Pooling Helps\n",
    "\n",
    "Pooling provides **local** translation invariance:\n",
    "```\n",
    "Region 1:        Region 2:        Both pool to:\n",
    "[1, 9]           [9, 1]              9\n",
    "[2, 3]           [3, 2]              ‚Üë\n",
    "                                 (max is 9)\n",
    "```\n",
    "\n",
    "The pattern shifted within the region, but the pooled output is the same! üéØ\n",
    "\n",
    "Let's demonstrate this!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demonstrate-invariance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an image with a bright spot\n",
    "def create_image_with_spot(spot_position, image_size=8):\n",
    "    \"\"\"Create image with a 2√ó2 bright spot at given position.\"\"\"\n",
    "    img = np.ones((image_size, image_size)) * 2\n",
    "    y, x = spot_position\n",
    "    img[y:y+2, x:x+2] = 9  # Bright spot\n",
    "    return img\n",
    "\n",
    "# Create images with spot at different positions (within same pooling region)\n",
    "spot_positions = [(0, 0), (0, 1), (1, 0), (1, 1)]\n",
    "images = [create_image_with_spot(pos) for pos in spot_positions]\n",
    "\n",
    "# Apply max pooling to all\n",
    "pooled_images = [max_pool2d(img, pool_size=2, stride=2) for img in images]\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "\n",
    "for idx, (img, pooled, pos) in enumerate(zip(images, pooled_images, spot_positions)):\n",
    "    # Original image\n",
    "    ax_orig = axes[0, idx]\n",
    "    im = ax_orig.imshow(img, cmap='hot', interpolation='nearest', vmin=0, vmax=10)\n",
    "    ax_orig.set_title(f'Spot at {pos}', fontsize=11, fontweight='bold')\n",
    "    ax_orig.set_xticks([])\n",
    "    ax_orig.set_yticks([])\n",
    "    \n",
    "    # Highlight the pooling region\n",
    "    rect = Rectangle((-0.5, -0.5), 2, 2,\n",
    "                    linewidth=3, edgecolor='cyan', facecolor='none')\n",
    "    ax_orig.add_patch(rect)\n",
    "    \n",
    "    # Pooled image\n",
    "    ax_pool = axes[1, idx]\n",
    "    ax_pool.imshow(pooled, cmap='hot', interpolation='nearest', vmin=0, vmax=10)\n",
    "    ax_pool.set_title(f'After pooling\\nTop-left: {pooled[0, 0]:.0f}',\n",
    "                     fontsize=11, fontweight='bold')\n",
    "    ax_pool.set_xticks([])\n",
    "    ax_pool.set_yticks([])\n",
    "    \n",
    "    # Add values to pooled image\n",
    "    for i in range(4):\n",
    "        for j in range(4):\n",
    "            ax_pool.text(j, i, f'{pooled[i, j]:.0f}',\n",
    "                        ha='center', va='center',\n",
    "                        color='white', fontweight='bold')\n",
    "\n",
    "plt.suptitle('Translation Invariance: Spot Moves, but Pooled Output Stays Same!',\n",
    "            fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüéØ Translation Invariance Demonstrated!\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nTop-left pooled values (all should be 9):\")\n",
    "for idx, (pos, pooled) in enumerate(zip(spot_positions, pooled_images)):\n",
    "    print(f\"   Spot at {pos}: Pooled value = {pooled[0, 0]:.0f}\")\n",
    "\n",
    "print(\"\\nüí° Key Insight:\")\n",
    "print(\"   Even though the bright spot moved within the region (cyan box),\")\n",
    "print(\"   the max pooled output STAYED THE SAME (9)!\")\n",
    "print(\"   This is translation invariance - small shifts don't change the output!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "global-pooling",
   "metadata": {},
   "source": [
    "---\n",
    "## üåç Global Pooling - Pool Everything!\n",
    "\n",
    "### üéØ What is Global Pooling?\n",
    "\n",
    "**Global pooling** pools the ENTIRE feature map into a single value!\n",
    "\n",
    "```\n",
    "Feature map:         Global pooling:\n",
    "[1  3  2  4]              \n",
    "[5  6  7  8]         ‚Üí   Single value\n",
    "[9  2  1  3]              (max or average)\n",
    "[4  5  8  7]\n",
    "```\n",
    "\n",
    "### ü§î Why Use Global Pooling?\n",
    "\n",
    "**Problem with fully-connected layers:**\n",
    "```\n",
    "Feature map: 7√ó7√ó512 = 25,088 neurons\n",
    "FC layer: 1000 outputs\n",
    "Parameters: 25,088 √ó 1,000 = 25 MILLION parameters! üò±\n",
    "```\n",
    "\n",
    "**Solution: Global Average Pooling (GAP)**\n",
    "```\n",
    "Feature map: 7√ó7√ó512\n",
    "‚Üì Global pool each channel\n",
    "Result: 1√ó1√ó512 = 512 values\n",
    "‚Üì FC layer\n",
    "Output: 1000 classes\n",
    "Parameters: 512 √ó 1,000 = 512k (50√ó fewer!) üéâ\n",
    "```\n",
    "\n",
    "### üéÅ Benefits of Global Average Pooling\n",
    "\n",
    "‚úÖ **Drastically reduces parameters** (helps prevent overfitting)\n",
    "‚úÖ **No spatial information to lose** (we're at the end anyway)\n",
    "‚úÖ **More robust to spatial translation** (completely position-invariant)\n",
    "‚úÖ **Forces features to be meaningful** (can't rely on position)\n",
    "\n",
    "Let's implement it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "global-pooling",
   "metadata": {},
   "outputs": [],
   "source": [
    "def global_avg_pool2d(input_data):\n",
    "    \"\"\"\n",
    "    Perform global average pooling.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    input_data : np.ndarray, shape (H, W, C)\n",
    "        Input feature maps\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    output : np.ndarray, shape (C,)\n",
    "        One value per channel\n",
    "    \"\"\"\n",
    "    if input_data.ndim == 2:\n",
    "        # Single channel\n",
    "        return np.mean(input_data)\n",
    "    else:\n",
    "        # Multiple channels - average each channel separately\n",
    "        return np.mean(input_data, axis=(0, 1))\n",
    "\n",
    "def global_max_pool2d(input_data):\n",
    "    \"\"\"\n",
    "    Perform global max pooling.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    input_data : np.ndarray, shape (H, W, C)\n",
    "        Input feature maps\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    output : np.ndarray, shape (C,)\n",
    "        One value per channel\n",
    "    \"\"\"\n",
    "    if input_data.ndim == 2:\n",
    "        return np.max(input_data)\n",
    "    else:\n",
    "        return np.max(input_data, axis=(0, 1))\n",
    "\n",
    "# Test with a multi-channel feature map\n",
    "print(\"üß™ Testing Global Pooling\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Simulate a 7√ó7√ó3 feature map (3 channels)\n",
    "feature_map = np.random.randn(7, 7, 3)\n",
    "\n",
    "print(f\"\\nInput feature map shape: {feature_map.shape}\")\n",
    "print(f\"Total values: {feature_map.size}\")\n",
    "\n",
    "# Apply global pooling\n",
    "gap_result = global_avg_pool2d(feature_map)\n",
    "gmp_result = global_max_pool2d(feature_map)\n",
    "\n",
    "print(f\"\\nAfter Global Average Pooling: {gap_result.shape}\")\n",
    "print(f\"Values: {gap_result}\")\n",
    "\n",
    "print(f\"\\nAfter Global Max Pooling: {gmp_result.shape}\")\n",
    "print(f\"Values: {gmp_result}\")\n",
    "\n",
    "print(\"\\nüéØ What Happened:\")\n",
    "print(f\"   ‚Ä¢ Original: 7√ó7√ó3 = {7*7*3} values\")\n",
    "print(f\"   ‚Ä¢ After global pooling: 3 values (one per channel)\")\n",
    "print(f\"   ‚Ä¢ Reduction: {(1 - 3/(7*7*3))*100:.1f}% fewer values!\")\n",
    "\n",
    "# Demonstrate parameter reduction\n",
    "print(\"\\nüí° Parameter Reduction Example:\")\n",
    "print(\"   Without GAP (7√ó7√ó512 ‚Üí 1000 classes):\")\n",
    "fc_params_without = 7 * 7 * 512 * 1000\n",
    "print(f\"     {fc_params_without:,} parameters\")\n",
    "\n",
    "print(\"\\n   With GAP (512 ‚Üí 1000 classes):\")\n",
    "fc_params_with = 512 * 1000\n",
    "print(f\"     {fc_params_with:,} parameters\")\n",
    "\n",
    "print(f\"\\n   Reduction: {fc_params_without / fc_params_with:.0f}√ó fewer parameters! üéâ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pooling-in-cnns",
   "metadata": {},
   "source": [
    "---\n",
    "## üèóÔ∏è Pooling in Real CNN Architectures\n",
    "\n",
    "### üìä Typical CNN Pattern\n",
    "\n",
    "```\n",
    "Conv ‚Üí ReLU ‚Üí Pool ‚Üí Conv ‚Üí ReLU ‚Üí Pool ‚Üí ... ‚Üí Flatten ‚Üí FC\n",
    "```\n",
    "\n",
    "**Each pooling layer:**\n",
    "- Reduces spatial dimensions (halves height and width)\n",
    "- Keeps channel dimension unchanged\n",
    "- Has zero learnable parameters\n",
    "\n",
    "### üéØ Common Configurations\n",
    "\n",
    "**Standard Max Pooling:**\n",
    "- Window: 2√ó2\n",
    "- Stride: 2\n",
    "- Result: Halves spatial dimensions\n",
    "\n",
    "**Overlapping Pooling:**\n",
    "- Window: 3√ó3\n",
    "- Stride: 2\n",
    "- Result: Overlapping regions, slightly more information preserved\n",
    "- Used in AlexNet\n",
    "\n",
    "**Global Pooling:**\n",
    "- Window: entire feature map\n",
    "- Used instead of FC layers\n",
    "- Common in modern architectures (ResNet, Inception)\n",
    "\n",
    "Let's trace through a typical CNN!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "trace-cnn-with-pooling",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate a typical CNN architecture with pooling\n",
    "def trace_cnn_with_pooling():\n",
    "    \"\"\"\n",
    "    Trace feature map sizes through a typical CNN.\n",
    "    \"\"\"\n",
    "    print(\"üèóÔ∏è  Typical CNN Architecture with Pooling\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"{'Layer':<20} {'Operation':<20} {'Output Shape':<20} {'Parameters':<15}\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Start with ImageNet-sized input\n",
    "    h, w, c = 224, 224, 3\n",
    "    \n",
    "    print(f\"{'Input':<20} {'-':<20} {f'{h}√ó{w}√ó{c}':<20} {0:<15}\")\n",
    "    \n",
    "    # Block 1\n",
    "    c = 64\n",
    "    params1 = 3 * 3 * 3 * c + c  # 3√ó3 conv from 3 to 64 channels\n",
    "    print(f\"{'Conv1 (3√ó3, 64)':<20} {'Convolution':<20} {f'{h}√ó{w}√ó{c}':<20} {params1:<15,}\")\n",
    "    print(f\"{'ReLU1':<20} {'Activation':<20} {f'{h}√ó{w}√ó{c}':<20} {0:<15}\")\n",
    "    \n",
    "    h, w = h // 2, w // 2\n",
    "    print(f\"{'MaxPool1 (2√ó2)':<20} {'Max Pooling':<20} {f'{h}√ó{w}√ó{c}':<20} {0:<15}\")\n",
    "    \n",
    "    # Block 2\n",
    "    c_prev = c\n",
    "    c = 128\n",
    "    params2 = 3 * 3 * c_prev * c + c\n",
    "    print(f\"{'Conv2 (3√ó3, 128)':<20} {'Convolution':<20} {f'{h}√ó{w}√ó{c}':<20} {params2:<15,}\")\n",
    "    print(f\"{'ReLU2':<20} {'Activation':<20} {f'{h}√ó{w}√ó{c}':<20} {0:<15}\")\n",
    "    \n",
    "    h, w = h // 2, w // 2\n",
    "    print(f\"{'MaxPool2 (2√ó2)':<20} {'Max Pooling':<20} {f'{h}√ó{w}√ó{c}':<20} {0:<15}\")\n",
    "    \n",
    "    # Block 3\n",
    "    c_prev = c\n",
    "    c = 256\n",
    "    params3 = 3 * 3 * c_prev * c + c\n",
    "    print(f\"{'Conv3 (3√ó3, 256)':<20} {'Convolution':<20} {f'{h}√ó{w}√ó{c}':<20} {params3:<15,}\")\n",
    "    print(f\"{'ReLU3':<20} {'Activation':<20} {f'{h}√ó{w}√ó{c}':<20} {0:<15}\")\n",
    "    \n",
    "    h, w = h // 2, w // 2\n",
    "    print(f\"{'MaxPool3 (2√ó2)':<20} {'Max Pooling':<20} {f'{h}√ó{w}√ó{c}':<20} {0:<15}\")\n",
    "    \n",
    "    # Global pooling\n",
    "    print(f\"{'GlobalAvgPool':<20} {'Global Pooling':<20} {f'1√ó1√ó{c}':<20} {0:<15}\")\n",
    "    \n",
    "    # Final FC\n",
    "    fc_params = c * 1000 + 1000\n",
    "    print(f\"{'FC (1000 classes)':<20} {'Fully Connected':<20} {'1000':<20} {fc_params:<15,}\")\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    total_params = params1 + params2 + params3 + fc_params\n",
    "    print(f\"\\nTotal parameters: {total_params:,}\")\n",
    "    \n",
    "    print(\"\\nüéØ Key Observations:\")\n",
    "    print(\"   ‚Ä¢ Pooling layers have 0 parameters (just operations)\")\n",
    "    print(\"   ‚Ä¢ Spatial dimensions: 224 ‚Üí 112 ‚Üí 56 ‚Üí 28 (halved each time)\")\n",
    "    print(\"   ‚Ä¢ Channels increase: 3 ‚Üí 64 ‚Üí 128 ‚Üí 256 (learning more features)\")\n",
    "    print(\"   ‚Ä¢ Global pooling reduces 28√ó28√ó256 to just 256 values!\")\n",
    "    print(\"   ‚Ä¢ Without global pooling, FC layer would need 200K√ó more parameters!\")\n",
    "\n",
    "trace_cnn_with_pooling()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "modern-alternatives",
   "metadata": {},
   "source": [
    "---\n",
    "## üÜï Modern Alternatives to Pooling\n",
    "\n",
    "### ü§î Is Pooling Always Necessary?\n",
    "\n",
    "**Traditional wisdom**: Yes! Every CNN needs pooling.\n",
    "\n",
    "**Modern view**: Not always! There are alternatives.\n",
    "\n",
    "### üîÑ Alternative: Strided Convolutions\n",
    "\n",
    "Instead of:\n",
    "```\n",
    "Conv (stride=1) ‚Üí Pool (stride=2)\n",
    "```\n",
    "\n",
    "Use:\n",
    "```\n",
    "Conv (stride=2)\n",
    "```\n",
    "\n",
    "**Advantages:**\n",
    "- Learnable downsampling (can learn optimal way to reduce size)\n",
    "- Fewer layers (simpler architecture)\n",
    "- Still reduces spatial dimensions\n",
    "\n",
    "**Disadvantages:**\n",
    "- More parameters (convolution has weights)\n",
    "- Less translation invariance\n",
    "\n",
    "### üéØ When to Use What?\n",
    "\n",
    "**Use Max Pooling when:**\n",
    "- You want translation invariance\n",
    "- You want to minimize parameters\n",
    "- Classification tasks\n",
    "- Standard CNN architectures\n",
    "\n",
    "**Use Strided Convolutions when:**\n",
    "- You want learnable downsampling\n",
    "- Position matters (e.g., segmentation)\n",
    "- Modern architectures (ResNet uses both!)\n",
    "\n",
    "**Use Global Average Pooling when:**\n",
    "- Replacing fully-connected layers\n",
    "- Want to reduce parameters dramatically\n",
    "- Final layers of the network\n",
    "\n",
    "Let's compare these approaches!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compare-approaches",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare pooling vs strided convolution\n",
    "print(\"‚öñÔ∏è  Pooling vs Strided Convolution Comparison\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Scenario: Downsample 224√ó224√ó64 to 112√ó112√ó128\n",
    "print(\"\\nScenario: Downsample 224√ó224√ó64 ‚Üí 112√ó112√ó128\\n\")\n",
    "\n",
    "print(\"Approach 1: Conv (stride=1) + Max Pool\")\n",
    "print(\"‚îÄ\"*80)\n",
    "conv1_params = 3 * 3 * 64 * 128 + 128  # 3√ó3 conv\n",
    "pool_params = 0\n",
    "total1 = conv1_params + pool_params\n",
    "print(f\"  Conv (3√ó3, stride=1): {conv1_params:,} parameters\")\n",
    "print(f\"  Max Pool (2√ó2, stride=2): {pool_params:,} parameters\")\n",
    "print(f\"  Total: {total1:,} parameters\")\n",
    "\n",
    "print(\"\\nApproach 2: Strided Convolution Only\")\n",
    "print(\"‚îÄ\"*80)\n",
    "conv2_params = 3 * 3 * 64 * 128 + 128  # 3√ó3 conv with stride=2\n",
    "total2 = conv2_params\n",
    "print(f\"  Conv (3√ó3, stride=2): {conv2_params:,} parameters\")\n",
    "print(f\"  Total: {total2:,} parameters\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"\\nüìä Analysis:\")\n",
    "print(f\"   Parameter difference: {abs(total2 - total1):,} (same in this case!)\")\n",
    "print(\"   Both produce 112√ó112√ó128 output\")\n",
    "print(\"   Pooling provides more translation invariance\")\n",
    "print(\"   Strided conv allows learning optimal downsampling\")\n",
    "\n",
    "print(\"\\nüéØ Modern Practice:\")\n",
    "print(\"   ‚Ä¢ Early CNNs (AlexNet, VGG): Always use pooling\")\n",
    "print(\"   ‚Ä¢ Modern CNNs (ResNet, Inception): Mix both approaches\")\n",
    "print(\"   ‚Ä¢ Some networks (All-CNN): Replace all pooling with strided conv\")\n",
    "print(\"   ‚Ä¢ Choice depends on task and architecture goals\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary",
   "metadata": {},
   "source": [
    "---\n",
    "## üéØ Summary: Pooling Layers\n",
    "\n",
    "Congratulations! You now understand pooling - the downsampling hero of CNNs! üéâ\n",
    "\n",
    "### ‚úÖ What We Learned\n",
    "\n",
    "1. **What is Pooling:**\n",
    "   - Downsampling operation that reduces spatial dimensions\n",
    "   - No learnable parameters (just an operation)\n",
    "   - Helps manage computational cost\n",
    "\n",
    "2. **Max Pooling:**\n",
    "   - Takes maximum value from each window\n",
    "   - Preserves strongest activations\n",
    "   - Most common in CNNs\n",
    "   - Best for feature detection\n",
    "\n",
    "3. **Average Pooling:**\n",
    "   - Takes mean value from each window\n",
    "   - Smoother downsampling\n",
    "   - Used in some architectures\n",
    "   - Good for final layers\n",
    "\n",
    "4. **Translation Invariance:**\n",
    "   - Small shifts in input don't change output\n",
    "   - Key benefit of pooling\n",
    "   - Makes networks robust to object position\n",
    "\n",
    "5. **Global Pooling:**\n",
    "   - Pools entire feature map to single value\n",
    "   - Drastically reduces parameters\n",
    "   - Alternative to fully-connected layers\n",
    "\n",
    "6. **Modern Alternatives:**\n",
    "   - Strided convolutions can replace pooling\n",
    "   - Trade-offs between parameters and invariance\n",
    "   - Modern architectures use both\n",
    "\n",
    "### üßÆ Key Concepts\n",
    "\n",
    "**Standard Pooling:**\n",
    "```\n",
    "Output Size = (Input - Pool_Size) / Stride + 1\n",
    "```\n",
    "\n",
    "**Common Configuration:**\n",
    "- Pool size: 2√ó2\n",
    "- Stride: 2\n",
    "- Result: Halves spatial dimensions\n",
    "\n",
    "**Global Pooling:**\n",
    "```\n",
    "Input: H √ó W √ó C\n",
    "Output: 1 √ó 1 √ó C  (or just C values)\n",
    "```\n",
    "\n",
    "### üí° Design Guidelines\n",
    "\n",
    "**Use Max Pooling:**\n",
    "- After conv layers for downsampling\n",
    "- 2√ó2 window, stride 2 is standard\n",
    "- When you want translation invariance\n",
    "\n",
    "**Use Average Pooling:**\n",
    "- When you want smoother features\n",
    "- Less common than max pooling\n",
    "\n",
    "**Use Global Average Pooling:**\n",
    "- Replace fully-connected layers\n",
    "- Before final classification\n",
    "- Dramatically reduces parameters\n",
    "\n",
    "**Consider Strided Convolutions:**\n",
    "- When you want learnable downsampling\n",
    "- In modern architectures\n",
    "- When position information is important\n",
    "\n",
    "### üéì What's Next?\n",
    "\n",
    "Now that you understand both convolution and pooling, you're ready to:\n",
    "\n",
    "**Next Notebook: Building a Complete CNN**\n",
    "- Combine convolution, pooling, and FC layers\n",
    "- Train on MNIST or Fashion-MNIST\n",
    "- Visualize what the network learns\n",
    "- Understand the complete training pipeline\n",
    "\n",
    "Let's build our first complete CNN! üöÄ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "practice",
   "metadata": {},
   "source": [
    "---\n",
    "## üéÆ Practice Exercises\n",
    "\n",
    "Test your understanding with these exercises:\n",
    "\n",
    "### Exercise 1: Implement Different Pool Sizes\n",
    "Modify the max pooling function to support:\n",
    "- 3√ó3 pooling\n",
    "- Non-square pooling (e.g., 2√ó3)\n",
    "- Different strides\n",
    "\n",
    "### Exercise 2: Visualize Pooling Effect\n",
    "Create an image with various patterns (edges, spots, textures).\n",
    "Apply max and average pooling with different window sizes.\n",
    "Compare which features are preserved.\n",
    "\n",
    "### Exercise 3: Calculate Output Dimensions\n",
    "Given:\n",
    "- Input: 100√ó100 feature map\n",
    "- Pooling: 3√ó3 window\n",
    "- Stride: 2\n",
    "\n",
    "What is the output size? Write a function to verify.\n",
    "\n",
    "### Exercise 4: Implement Overlapping Pooling\n",
    "Implement max pooling with:\n",
    "- Window: 3√ó3\n",
    "- Stride: 2\n",
    "- Compare with non-overlapping (2√ó2, stride=2)\n",
    "\n",
    "### Exercise 5: Test Translation Invariance\n",
    "Create an image with a pattern.\n",
    "Shift the pattern by 1 pixel in different directions.\n",
    "Apply pooling and compare outputs.\n",
    "Measure how much the pooled output changes.\n",
    "\n",
    "### Exercise 6: Compare Parameter Counts\n",
    "For a network that goes from 224√ó224√ó64 to 112√ó112√ó128:\n",
    "- Calculate parameters for: Conv + Pool\n",
    "- Calculate parameters for: Strided Conv only\n",
    "- Compare the trade-offs\n",
    "\n",
    "**Try these exercises in the exercises.ipynb notebook!**\n",
    "\n",
    "---\n",
    "\n",
    "*Excellent work! You now understand both convolution AND pooling!* üí™\n",
    "\n",
    "*Ready to build a complete CNN? Let's go!* ‚Üí **[Next: Notebook 04 - Building a Complete CNN](04_building_complete_cnn.ipynb)**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
