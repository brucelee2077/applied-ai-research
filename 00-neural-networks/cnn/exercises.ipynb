{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks - Practice Exercises\n",
    "\n",
    "This notebook contains hands-on exercises to reinforce your understanding of CNNs. Work through these exercises to deepen your knowledge of convolutional neural networks, from basic convolution operations to advanced architectures.\n",
    "\n",
    "**Instructions:**\n",
    "- Each exercise builds on concepts from the CNN tutorial notebooks\n",
    "- Try to solve problems independently before checking hints\n",
    "- Solutions are available in `solutions.ipynb`\n",
    "- Experiment and explore beyond the basic requirements\n",
    "\n",
    "**Prerequisites:** Basic understanding of neural networks and the CNN fundamentals notebooks.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal, ndimage\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"‚úì Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercise 1: Implement Custom Convolution Filters\n",
    "\n",
    "**Objective:** Understand how different filters detect features in images.\n",
    "\n",
    "### Task 1.1: Implement Edge Detection Filters\n",
    "\n",
    "Create and apply the following edge detection filters:\n",
    "1. **Horizontal edge detector**\n",
    "2. **Vertical edge detector**\n",
    "3. **Sobel edge detector**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_filter(image, kernel):\n",
    "    \"\"\"\n",
    "    Apply a convolution filter to an image.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    image : np.ndarray, shape (H, W)\n",
    "        Input grayscale image\n",
    "    kernel : np.ndarray, shape (K, K)\n",
    "        Convolution kernel/filter\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    output : np.ndarray\n",
    "        Filtered image\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    # Hint: Use scipy.signal.convolve2d or implement manually\n",
    "    pass\n",
    "\n",
    "# Create a simple test image with horizontal and vertical edges\n",
    "test_image = np.zeros((100, 100))\n",
    "test_image[30:70, :] = 1  # Horizontal bar\n",
    "test_image[:, 30:70] = 1  # Vertical bar\n",
    "\n",
    "# TODO: Define your edge detection kernels\n",
    "horizontal_edge_kernel = np.array([\n",
    "    # YOUR CODE HERE\n",
    "    # Example structure:\n",
    "    # [[ 1,  1,  1],\n",
    "    #  [ ?,  ?,  ?],\n",
    "    #  [-1, -1, -1]]\n",
    "])\n",
    "\n",
    "vertical_edge_kernel = np.array([\n",
    "    # YOUR CODE HERE\n",
    "])\n",
    "\n",
    "sobel_x = np.array([\n",
    "    # YOUR CODE HERE\n",
    "    # Sobel X (vertical edges)\n",
    "])\n",
    "\n",
    "sobel_y = np.array([\n",
    "    # YOUR CODE HERE\n",
    "    # Sobel Y (horizontal edges)\n",
    "])\n",
    "\n",
    "# Apply filters\n",
    "# horizontal_edges = apply_filter(test_image, horizontal_edge_kernel)\n",
    "# vertical_edges = apply_filter(test_image, vertical_edge_kernel)\n",
    "# sobel_edges_x = apply_filter(test_image, sobel_x)\n",
    "# sobel_edges_y = apply_filter(test_image, sobel_y)\n",
    "\n",
    "# Visualize results\n",
    "# TODO: Create a subplot showing original and all filtered versions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><b>üí° Hint (Click to expand)</b></summary>\n",
    "\n",
    "**Horizontal Edge Detector:**\n",
    "```python\n",
    "[[ 1,  1,  1],\n",
    " [ 0,  0,  0],\n",
    " [-1, -1, -1]]\n",
    "```\n",
    "\n",
    "**Vertical Edge Detector:**\n",
    "```python\n",
    "[[ 1,  0, -1],\n",
    " [ 1,  0, -1],\n",
    " [ 1,  0, -1]]\n",
    "```\n",
    "\n",
    "**Sobel X (detects vertical edges):**\n",
    "```python\n",
    "[[-1,  0,  1],\n",
    " [-2,  0,  2],\n",
    " [-1,  0,  1]]\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1.2: Implement Emboss and Sharpen Filters\n",
    "\n",
    "Create filters that:\n",
    "1. **Emboss** the image (3D effect)\n",
    "2. **Sharpen** the image (enhance edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Define emboss and sharpen kernels\n",
    "emboss_kernel = np.array([\n",
    "    # YOUR CODE HERE\n",
    "])\n",
    "\n",
    "sharpen_kernel = np.array([\n",
    "    # YOUR CODE HERE\n",
    "])\n",
    "\n",
    "# Test on a more interesting image\n",
    "# Create a simple shape\n",
    "test_image2 = np.zeros((100, 100))\n",
    "for i in range(100):\n",
    "    for j in range(100):\n",
    "        if (i - 50)**2 + (j - 50)**2 < 400:\n",
    "            test_image2[i, j] = 1\n",
    "\n",
    "# YOUR CODE HERE: Apply filters and visualize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercise 2: Calculate Output Dimensions\n",
    "\n",
    "**Objective:** Master the formulas for computing output dimensions after convolution and pooling.\n",
    "\n",
    "### Task 2.1: Convolution Output Size\n",
    "\n",
    "The output size after convolution is:\n",
    "$$\\text{Output Size} = \\frac{W - K + 2P}{S} + 1$$\n",
    "\n",
    "Where:\n",
    "- W = Input width/height\n",
    "- K = Kernel size\n",
    "- P = Padding\n",
    "- S = Stride\n",
    "\n",
    "Calculate the output dimensions for the following configurations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_conv_output_size(input_size, kernel_size, padding=0, stride=1):\n",
    "    \"\"\"\n",
    "    Calculate output size after convolution.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    input_size : int\n",
    "        Width/height of input\n",
    "    kernel_size : int\n",
    "        Size of the convolution kernel\n",
    "    padding : int\n",
    "        Amount of padding\n",
    "    stride : int\n",
    "        Stride of convolution\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    output_size : int\n",
    "        Width/height of output\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    pass\n",
    "\n",
    "# Test cases\n",
    "test_cases = [\n",
    "    (32, 3, 0, 1),   # Case 1: 32x32 input, 3x3 kernel, no padding, stride 1\n",
    "    (32, 5, 2, 1),   # Case 2: 32x32 input, 5x5 kernel, padding 2, stride 1\n",
    "    (64, 3, 1, 2),   # Case 3: 64x64 input, 3x3 kernel, padding 1, stride 2\n",
    "    (28, 5, 0, 1),   # Case 4: 28x28 input (MNIST), 5x5 kernel, no padding, stride 1\n",
    "    (224, 7, 3, 2),  # Case 5: 224x224 input (ImageNet), 7x7 kernel, padding 3, stride 2\n",
    "]\n",
    "\n",
    "print(\"Testing Convolution Output Size Calculation:\")\n",
    "print(\"=\"*70)\n",
    "print(f\"{'Input':<10} {'Kernel':<10} {'Padding':<10} {'Stride':<10} {'Output':<10}\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for input_size, kernel_size, padding, stride in test_cases:\n",
    "    output = calculate_conv_output_size(input_size, kernel_size, padding, stride)\n",
    "    print(f\"{input_size:<10} {kernel_size:<10} {padding:<10} {stride:<10} {output:<10}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.2: Calculate \"Same\" Padding\n",
    "\n",
    "\"Same\" padding means the output size equals the input size (when stride=1).\n",
    "Calculate the required padding for different kernel sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_same_padding(kernel_size):\n",
    "    \"\"\"\n",
    "    Calculate padding needed for 'same' convolution (output_size = input_size).\n",
    "    Assumes stride = 1.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    kernel_size : int\n",
    "        Size of the convolution kernel\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    padding : int\n",
    "        Required padding\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    # Hint: For output = input, what padding makes the formula work?\n",
    "    pass\n",
    "\n",
    "# Test for common kernel sizes\n",
    "kernel_sizes = [3, 5, 7, 9, 11]\n",
    "\n",
    "print(\"\\nSame Padding Calculation:\")\n",
    "print(\"=\"*40)\n",
    "print(f\"{'Kernel Size':<20} {'Required Padding':<20}\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "for k in kernel_sizes:\n",
    "    padding = calculate_same_padding(k)\n",
    "    print(f\"{k:<20} {padding:<20}\")\n",
    "    \n",
    "    # Verify\n",
    "    test_input = 32\n",
    "    output = calculate_conv_output_size(test_input, k, padding, 1)\n",
    "    print(f\"  Verification: {test_input}x{test_input} -> {output}x{output}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.3: Trace Through a Complete CNN\n",
    "\n",
    "Given a CNN architecture, calculate output dimensions at each layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a CNN architecture\n",
    "architecture = [\n",
    "    ('input', {'size': 224, 'channels': 3}),\n",
    "    ('conv', {'kernel': 7, 'filters': 64, 'padding': 3, 'stride': 2}),\n",
    "    ('pool', {'kernel': 3, 'stride': 2, 'padding': 1}),\n",
    "    ('conv', {'kernel': 3, 'filters': 128, 'padding': 1, 'stride': 1}),\n",
    "    ('conv', {'kernel': 3, 'filters': 128, 'padding': 1, 'stride': 1}),\n",
    "    ('pool', {'kernel': 2, 'stride': 2, 'padding': 0}),\n",
    "    ('conv', {'kernel': 3, 'filters': 256, 'padding': 1, 'stride': 1}),\n",
    "    ('pool', {'kernel': 2, 'stride': 2, 'padding': 0}),\n",
    "]\n",
    "\n",
    "# YOUR CODE HERE:\n",
    "# Write code to trace through this architecture and print:\n",
    "# - Output size after each layer\n",
    "# - Number of channels after each layer\n",
    "# - Number of parameters in each conv layer\n",
    "\n",
    "def trace_cnn_architecture(architecture):\n",
    "    \"\"\"\n",
    "    Trace through CNN architecture and print dimensions.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    pass\n",
    "\n",
    "trace_cnn_architecture(architecture)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercise 3: Build a 3-Layer CNN from Scratch for CIFAR-10\n",
    "\n",
    "**Objective:** Implement a complete CNN using only NumPy.\n",
    "\n",
    "### Task 3.1: Implement Convolution Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvLayer:\n",
    "    \"\"\"\n",
    "    A convolutional layer implementation.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, n_filters, filter_size, n_channels, stride=1, padding=0):\n",
    "        \"\"\"\n",
    "        Initialize convolutional layer.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        n_filters : int\n",
    "            Number of filters (output channels)\n",
    "        filter_size : int\n",
    "            Size of each filter (assumed square)\n",
    "        n_channels : int\n",
    "            Number of input channels\n",
    "        stride : int\n",
    "            Stride of convolution\n",
    "        padding : int\n",
    "            Padding amount\n",
    "        \"\"\"\n",
    "        # Initialize filters with small random values\n",
    "        # Shape: (n_filters, n_channels, filter_size, filter_size)\n",
    "        # YOUR CODE HERE\n",
    "        self.filters = None\n",
    "        self.biases = None\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "    \n",
    "    def forward(self, input_data):\n",
    "        \"\"\"\n",
    "        Forward pass through conv layer.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        input_data : np.ndarray, shape (batch, channels, height, width)\n",
    "            Input data\n",
    "        \n",
    "        Returns:\n",
    "        --------\n",
    "        output : np.ndarray\n",
    "            Convolution output\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        # Steps:\n",
    "        # 1. Add padding if needed\n",
    "        # 2. Calculate output dimensions\n",
    "        # 3. Perform convolution (nested loops or im2col)\n",
    "        # 4. Add bias\n",
    "        pass\n",
    "\n",
    "# Test the conv layer\n",
    "test_input = np.random.randn(1, 3, 32, 32)  # 1 RGB image, 32x32\n",
    "conv = ConvLayer(n_filters=16, filter_size=3, n_channels=3, padding=1)\n",
    "# output = conv.forward(test_input)\n",
    "# print(f\"Input shape: {test_input.shape}\")\n",
    "# print(f\"Output shape: {output.shape}\")\n",
    "# print(f\"Expected: (1, 16, 32, 32)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><b>üí° Hint (Click to expand)</b></summary>\n",
    "\n",
    "For a simple implementation, use nested loops:\n",
    "```python\n",
    "for i in range(output_height):\n",
    "    for j in range(output_width):\n",
    "        for f in range(n_filters):\n",
    "            # Extract receptive field\n",
    "            h_start = i * stride\n",
    "            h_end = h_start + filter_size\n",
    "            w_start = j * stride\n",
    "            w_end = w_start + filter_size\n",
    "            \n",
    "            receptive_field = padded_input[:, h_start:h_end, w_start:w_end]\n",
    "            output[f, i, j] = np.sum(receptive_field * filters[f]) + biases[f]\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3.2: Implement Max Pooling Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaxPoolLayer:\n",
    "    \"\"\"\n",
    "    Max pooling layer implementation.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, pool_size=2, stride=2):\n",
    "        \"\"\"\n",
    "        Initialize max pooling layer.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        pool_size : int\n",
    "            Size of pooling window\n",
    "        stride : int\n",
    "            Stride for pooling\n",
    "        \"\"\"\n",
    "        self.pool_size = pool_size\n",
    "        self.stride = stride\n",
    "    \n",
    "    def forward(self, input_data):\n",
    "        \"\"\"\n",
    "        Forward pass through max pooling.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        input_data : np.ndarray, shape (batch, channels, height, width)\n",
    "            Input data\n",
    "        \n",
    "        Returns:\n",
    "        --------\n",
    "        output : np.ndarray\n",
    "            Pooled output\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        # Take maximum value in each pooling window\n",
    "        pass\n",
    "\n",
    "# Test max pooling\n",
    "test_input = np.random.randn(1, 16, 32, 32)\n",
    "pool = MaxPoolLayer(pool_size=2, stride=2)\n",
    "# output = pool.forward(test_input)\n",
    "# print(f\"Input shape: {test_input.shape}\")\n",
    "# print(f\"Output shape: {output.shape}\")\n",
    "# print(f\"Expected: (1, 16, 16, 16)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3.3: Build Complete CNN\n",
    "\n",
    "Combine layers into a complete network for CIFAR-10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN:\n",
    "    \"\"\"\n",
    "    Simple CNN for CIFAR-10 classification.\n",
    "    \n",
    "    Architecture:\n",
    "    - Conv 32 filters, 3x3, padding=1 -> ReLU -> MaxPool 2x2\n",
    "    - Conv 64 filters, 3x3, padding=1 -> ReLU -> MaxPool 2x2\n",
    "    - Conv 64 filters, 3x3, padding=1 -> ReLU -> MaxPool 2x2\n",
    "    - Flatten -> FC 10 (output)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # YOUR CODE HERE\n",
    "        # Initialize all layers\n",
    "        pass\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass through the network.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        x : np.ndarray, shape (batch, 3, 32, 32)\n",
    "            CIFAR-10 images\n",
    "        \n",
    "        Returns:\n",
    "        --------\n",
    "        output : np.ndarray, shape (batch, 10)\n",
    "            Class scores\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        pass\n",
    "\n",
    "# Test the network\n",
    "# model = SimpleCNN()\n",
    "# test_batch = np.random.randn(5, 3, 32, 32)\n",
    "# output = model.forward(test_batch)\n",
    "# print(f\"Output shape: {output.shape}\")\n",
    "# print(f\"Expected: (5, 10)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercise 4: Visualize and Interpret Learned Filters\n",
    "\n",
    "**Objective:** Understand what CNNs learn by visualizing filters.\n",
    "\n",
    "### Task 4.1: Visualize First Layer Filters\n",
    "\n",
    "Load a pre-trained CNN and visualize its first layer filters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For this exercise, we'll simulate learned filters\n",
    "# In practice, you'd load from a trained model\n",
    "\n",
    "def generate_example_filters(n_filters=16):\n",
    "    \"\"\"\n",
    "    Generate example filters that resemble learned filters.\n",
    "    \"\"\"\n",
    "    filters = []\n",
    "    \n",
    "    # Create different types of filters\n",
    "    # Edge detectors, color detectors, texture detectors, etc.\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    return np.array(filters)\n",
    "\n",
    "def visualize_filters(filters, title=\"Learned Filters\"):\n",
    "    \"\"\"\n",
    "    Visualize a set of convolutional filters.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    filters : np.ndarray, shape (n_filters, channels, height, width)\n",
    "        Convolutional filters\n",
    "    title : str\n",
    "        Plot title\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    # Create a grid of subplots showing each filter\n",
    "    # If RGB, show as color images\n",
    "    # If single channel, use grayscale\n",
    "    pass\n",
    "\n",
    "# Generate and visualize\n",
    "# filters = generate_example_filters(16)\n",
    "# visualize_filters(filters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4.2: Visualize Feature Maps\n",
    "\n",
    "Apply filters to an image and visualize the resulting feature maps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_feature_maps(image, filters, layer_name=\"Layer 1\"):\n",
    "    \"\"\"\n",
    "    Apply filters to an image and visualize feature maps.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    image : np.ndarray\n",
    "        Input image\n",
    "    filters : np.ndarray\n",
    "        Convolutional filters\n",
    "    layer_name : str\n",
    "        Name of the layer for the plot title\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    # 1. Apply each filter to the image\n",
    "    # 2. Create a grid showing:\n",
    "    #    - Original image\n",
    "    #    - Each resulting feature map\n",
    "    # 3. Add labels showing which filter produced which feature map\n",
    "    pass\n",
    "\n",
    "# Test with a sample image\n",
    "# Create or load a test image\n",
    "# test_image = ... (32x32x3 RGB image)\n",
    "# visualize_feature_maps(test_image, filters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercise 5: Compare Max Pooling vs Average Pooling\n",
    "\n",
    "**Objective:** Understand the difference between pooling strategies.\n",
    "\n",
    "### Task 5.1: Implement Average Pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AvgPoolLayer:\n",
    "    \"\"\"\n",
    "    Average pooling layer.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, pool_size=2, stride=2):\n",
    "        self.pool_size = pool_size\n",
    "        self.stride = stride\n",
    "    \n",
    "    def forward(self, input_data):\n",
    "        \"\"\"\n",
    "        Forward pass through average pooling.\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        # Take average instead of maximum\n",
    "        pass\n",
    "\n",
    "# Test\n",
    "test_input = np.random.randn(1, 1, 8, 8)\n",
    "max_pool = MaxPoolLayer(pool_size=2, stride=2)\n",
    "avg_pool = AvgPoolLayer(pool_size=2, stride=2)\n",
    "\n",
    "# max_output = max_pool.forward(test_input)\n",
    "# avg_output = avg_pool.forward(test_input)\n",
    "\n",
    "# print(f\"Input shape: {test_input.shape}\")\n",
    "# print(f\"Max pool output shape: {max_output.shape}\")\n",
    "# print(f\"Avg pool output shape: {avg_output.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5.2: Compare on Real Images\n",
    "\n",
    "Apply both pooling methods to images and compare results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_pooling_methods(image):\n",
    "    \"\"\"\n",
    "    Compare max pooling vs average pooling on an image.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    image : np.ndarray\n",
    "        Input image\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    # 1. Apply max pooling multiple times (show progressive downsampling)\n",
    "    # 2. Apply avg pooling multiple times\n",
    "    # 3. Visualize side-by-side comparison\n",
    "    # 4. Discuss differences:\n",
    "    #    - Which preserves edges better?\n",
    "    #    - Which is smoother?\n",
    "    #    - Which is more robust to noise?\n",
    "    pass\n",
    "\n",
    "# Create test image with edges and textures\n",
    "test_image = np.zeros((64, 64))\n",
    "test_image[10:30, 10:30] = 1\n",
    "test_image[40:60, 40:60] = 0.5\n",
    "# Add some noise\n",
    "test_image += np.random.randn(64, 64) * 0.1\n",
    "\n",
    "# compare_pooling_methods(test_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** When would you use max pooling vs average pooling? Write your answer below.\n",
    "\n",
    "**Your Answer:**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 6: Implement Data Augmentation\n",
    "\n",
    "**Objective:** Improve model generalization through data augmentation.\n",
    "\n",
    "### Task 6.1: Basic Augmentations\n",
    "\n",
    "Implement common augmentation techniques:\n",
    "1. Random horizontal flip\n",
    "2. Random rotation\n",
    "3. Random crop\n",
    "4. Color jitter (brightness, contrast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataAugmentation:\n",
    "    \"\"\"\n",
    "    Data augmentation for images.\n",
    "    \"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def random_flip(image, probability=0.5):\n",
    "        \"\"\"\n",
    "        Randomly flip image horizontally.\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        pass\n",
    "    \n",
    "    @staticmethod\n",
    "    def random_rotation(image, max_angle=15):\n",
    "        \"\"\"\n",
    "        Randomly rotate image by up to max_angle degrees.\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        # Hint: Use scipy.ndimage.rotate\n",
    "        pass\n",
    "    \n",
    "    @staticmethod\n",
    "    def random_crop(image, crop_size):\n",
    "        \"\"\"\n",
    "        Randomly crop a portion of the image.\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        pass\n",
    "    \n",
    "    @staticmethod\n",
    "    def adjust_brightness(image, factor):\n",
    "        \"\"\"\n",
    "        Adjust image brightness.\n",
    "        factor > 1: brighter\n",
    "        factor < 1: darker\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        pass\n",
    "    \n",
    "    @staticmethod\n",
    "    def adjust_contrast(image, factor):\n",
    "        \"\"\"\n",
    "        Adjust image contrast.\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        pass\n",
    "\n",
    "# Test augmentations\n",
    "# Create or load a sample image\n",
    "# test_image = ...\n",
    "\n",
    "# YOUR CODE HERE:\n",
    "# Show original image and all augmented versions in a grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 6.2: Create Augmentation Pipeline\n",
    "\n",
    "Combine multiple augmentations into a pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augmentation_pipeline(image, training=True):\n",
    "    \"\"\"\n",
    "    Apply a series of augmentations to an image.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    image : np.ndarray\n",
    "        Input image\n",
    "    training : bool\n",
    "        If True, apply augmentations. If False, only normalize.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    augmented_image : np.ndarray\n",
    "        Augmented image\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    # Apply multiple augmentations randomly\n",
    "    pass\n",
    "\n",
    "# Demonstrate pipeline\n",
    "# Show the same image augmented 10 different ways\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercise 7: Implement Simplified ResNet with Skip Connections\n",
    "\n",
    "**Objective:** Understand residual connections.\n",
    "\n",
    "### Task 7.1: Implement Residual Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock:\n",
    "    \"\"\"\n",
    "    A residual block with skip connection.\n",
    "    \n",
    "    F(x) + x where F(x) is conv -> relu -> conv\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, n_channels, kernel_size=3):\n",
    "        \"\"\"\n",
    "        Initialize residual block.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        n_channels : int\n",
    "            Number of input/output channels (must be same for skip connection)\n",
    "        kernel_size : int\n",
    "            Size of convolutional kernels\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        # Initialize two conv layers\n",
    "        pass\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass with skip connection.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        x : np.ndarray\n",
    "            Input tensor\n",
    "        \n",
    "        Returns:\n",
    "        --------\n",
    "        output : np.ndarray\n",
    "            Output tensor (same shape as input)\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        # 1. Save input for skip connection\n",
    "        # 2. Apply conv1 -> relu\n",
    "        # 3. Apply conv2\n",
    "        # 4. Add skip connection: output = F(x) + x\n",
    "        # 5. Apply final relu\n",
    "        pass\n",
    "\n",
    "# Test residual block\n",
    "# test_input = np.random.randn(1, 64, 32, 32)\n",
    "# res_block = ResidualBlock(n_channels=64)\n",
    "# output = res_block.forward(test_input)\n",
    "# print(f\"Input shape: {test_input.shape}\")\n",
    "# print(f\"Output shape: {output.shape}\")\n",
    "# print(f\"Shapes match (required for residual): {test_input.shape == output.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><b>üí° Hint (Click to expand)</b></summary>\n",
    "\n",
    "Residual block structure:\n",
    "```\n",
    "input (x)\n",
    "   |\n",
    "   v\n",
    "Conv -> ReLU -> Conv  (this is F(x))\n",
    "   |               |\n",
    "   +--------->-----+  (skip connection)\n",
    "   |               |\n",
    "   v               v\n",
    "      F(x) + x\n",
    "          |\n",
    "          v\n",
    "        ReLU\n",
    "          |\n",
    "          v\n",
    "       output\n",
    "```\n",
    "\n",
    "Key: The skip connection adds the input directly to the output, allowing gradients to flow more easily during backpropagation.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 7.2: Build Mini ResNet\n",
    "\n",
    "Create a small ResNet-style architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MiniResNet:\n",
    "    \"\"\"\n",
    "    A simplified ResNet for CIFAR-10.\n",
    "    \n",
    "    Architecture:\n",
    "    - Conv 32 filters\n",
    "    - Residual Block (32 filters) x 2\n",
    "    - Max Pool\n",
    "    - Residual Block (64 filters) x 2\n",
    "    - Max Pool\n",
    "    - Global Average Pool\n",
    "    - FC 10\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # YOUR CODE HERE\n",
    "        pass\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # YOUR CODE HERE\n",
    "        pass\n",
    "\n",
    "# Test the network\n",
    "# model = MiniResNet()\n",
    "# test_batch = np.random.randn(5, 3, 32, 32)\n",
    "# output = model.forward(test_batch)\n",
    "# print(f\"Output shape: {output.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Why do skip connections help with training deep networks?\n",
    "\n",
    "**Your Answer:**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 8: Transfer Learning on Custom Dataset\n",
    "\n",
    "**Objective:** Use a pre-trained model for a new task.\n",
    "\n",
    "### Task 8.1: Feature Extraction\n",
    "\n",
    "Use a pre-trained CNN as a feature extractor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a conceptual exercise since we don't have PyTorch/TensorFlow\n",
    "# But you should understand the concepts\n",
    "\n",
    "print(\"Transfer Learning Concepts:\")\n",
    "print(\"=\"*70)\n",
    "print()\n",
    "print(\"1. FEATURE EXTRACTION:\")\n",
    "print(\"   - Use pre-trained CNN (e.g., ResNet trained on ImageNet)\")\n",
    "print(\"   - Freeze all convolutional layers\")\n",
    "print(\"   - Replace final FC layer with new one for your task\")\n",
    "print(\"   - Train only the new FC layer\")\n",
    "print()\n",
    "print(\"2. FINE-TUNING:\")\n",
    "print(\"   - Start with pre-trained weights\")\n",
    "print(\"   - Unfreeze some/all layers\")\n",
    "print(\"   - Train with small learning rate\")\n",
    "print()\n",
    "print(\"3. WHEN TO USE EACH:\")\n",
    "print(\"   Feature Extraction:\")\n",
    "print(\"     - Small dataset\")\n",
    "print(\"     - Similar to pre-training dataset\")\n",
    "print(\"     - Fast training needed\")\n",
    "print()\n",
    "print(\"   Fine-Tuning:\")\n",
    "print(\"     - Larger dataset\")\n",
    "print(\"     - Different from pre-training dataset\")\n",
    "print(\"     - Need maximum performance\")\n",
    "print()\n",
    "\n",
    "# Pseudocode for transfer learning\n",
    "transfer_learning_pseudocode = \"\"\"\n",
    "# Feature Extraction Approach:\n",
    "pretrained_model = load_pretrained_resnet()\n",
    "for layer in pretrained_model.layers[:-1]:  # All except last layer\n",
    "    layer.trainable = False\n",
    "\n",
    "# Add new classifier\n",
    "new_classifier = FullyConnected(n_classes=YOUR_NUM_CLASSES)\n",
    "\n",
    "# Training loop\n",
    "for epoch in epochs:\n",
    "    features = pretrained_model.extract_features(images)\n",
    "    predictions = new_classifier(features)\n",
    "    loss = compute_loss(predictions, labels)\n",
    "    update_only(new_classifier)  # Don't update pretrained layers\n",
    "\"\"\"\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"PSEUDOCODE:\")\n",
    "print(transfer_learning_pseudocode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 8.2: Design Transfer Learning Strategy\n",
    "\n",
    "For each scenario, decide on the best transfer learning approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenarios = [\n",
    "    {\n",
    "        'name': 'Medical X-ray Classification',\n",
    "        'dataset_size': 500,\n",
    "        'similarity_to_imagenet': 'Low',\n",
    "        'computational_budget': 'Limited'\n",
    "    },\n",
    "    {\n",
    "        'name': 'Dog Breed Classification',\n",
    "        'dataset_size': 10000,\n",
    "        'similarity_to_imagenet': 'High',\n",
    "        'computational_budget': 'High'\n",
    "    },\n",
    "    {\n",
    "        'name': 'Satellite Image Classification',\n",
    "        'dataset_size': 100000,\n",
    "        'similarity_to_imagenet': 'Low',\n",
    "        'computational_budget': 'High'\n",
    "    },\n",
    "]\n",
    "\n",
    "# YOUR CODE HERE:\n",
    "# For each scenario, decide:\n",
    "# 1. Should you use transfer learning?\n",
    "# 2. Feature extraction or fine-tuning?\n",
    "# 3. Which layers to freeze/unfreeze?\n",
    "# 4. What learning rate?\n",
    "# 5. Any special considerations?\n",
    "\n",
    "print(\"Transfer Learning Strategy Analysis\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for scenario in scenarios:\n",
    "    print(f\"\\n{scenario['name']:}\")\n",
    "    print(f\"  Dataset size: {scenario['dataset_size']}\")\n",
    "    print(f\"  Similarity to ImageNet: {scenario['similarity_to_imagenet']}\")\n",
    "    print(f\"  Computational budget: {scenario['computational_budget']}\")\n",
    "    print(f\"  Recommended approach: ???\")  # Fill this in!\n",
    "    print(f\"  Reasoning: ???\")  # Explain your choice!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercise 9: Translate NumPy CNN to PyTorch\n",
    "\n",
    "**Objective:** Learn to work with modern deep learning frameworks.\n",
    "\n",
    "### Task 9.1: Implement CNN in PyTorch\n",
    "\n",
    "Translate your NumPy CNN to PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: This requires PyTorch to be installed\n",
    "# pip install torch torchvision\n",
    "\n",
    "try:\n",
    "    import torch\n",
    "    import torch.nn as nn\n",
    "    import torch.nn.functional as F\n",
    "    \n",
    "    class CNNPyTorch(nn.Module):\n",
    "        \"\"\"\n",
    "        PyTorch implementation of CNN for CIFAR-10.\n",
    "        \n",
    "        Should match the architecture from Exercise 3.\n",
    "        \"\"\"\n",
    "        \n",
    "        def __init__(self):\n",
    "            super(CNNPyTorch, self).__init__()\n",
    "            # YOUR CODE HERE\n",
    "            # Define layers using:\n",
    "            # - nn.Conv2d\n",
    "            # - nn.MaxPool2d\n",
    "            # - nn.Linear\n",
    "            pass\n",
    "        \n",
    "        def forward(self, x):\n",
    "            # YOUR CODE HERE\n",
    "            # Implement forward pass using:\n",
    "            # - F.relu()\n",
    "            # - self.conv layers\n",
    "            # - self.pool layers\n",
    "            # - x.view() or x.flatten() for flattening\n",
    "            pass\n",
    "    \n",
    "    # Test the model\n",
    "    # model = CNNPyTorch()\n",
    "    # test_input = torch.randn(5, 3, 32, 32)\n",
    "    # output = model(test_input)\n",
    "    # print(f\"Output shape: {output.shape}\")\n",
    "    # print(f\"Expected: torch.Size([5, 10])\")\n",
    "    \n",
    "    print(\"‚úì PyTorch is installed and ready!\")\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"‚ö† PyTorch not installed. Install with: pip install torch torchvision\")\n",
    "    print(\"For this exercise, write the code even if you can't run it.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><b>üí° Hint (Click to expand)</b></summary>\n",
    "\n",
    "Basic PyTorch CNN structure:\n",
    "```python\n",
    "def __init__(self):\n",
    "    super(CNNPyTorch, self).__init__()\n",
    "    self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1)\n",
    "    self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "    self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "    self.fc1 = nn.Linear(64 * 8 * 8, 10)\n",
    "\n",
    "def forward(self, x):\n",
    "    x = self.pool(F.relu(self.conv1(x)))  # 32x32 -> 16x16\n",
    "    x = self.pool(F.relu(self.conv2(x)))  # 16x16 -> 8x8\n",
    "    x = x.view(-1, 64 * 8 * 8)  # Flatten\n",
    "    x = self.fc1(x)\n",
    "    return x\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 9.2: Train PyTorch Model\n",
    "\n",
    "Implement a training loop with proper data loading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import torch.optim as optim\n",
    "    from torch.utils.data import DataLoader\n",
    "    \n",
    "    def train_pytorch_cnn(model, train_loader, val_loader, epochs=10, lr=0.001):\n",
    "        \"\"\"\n",
    "        Train PyTorch CNN.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        model : nn.Module\n",
    "            PyTorch model\n",
    "        train_loader : DataLoader\n",
    "            Training data loader\n",
    "        val_loader : DataLoader\n",
    "            Validation data loader\n",
    "        epochs : int\n",
    "            Number of epochs\n",
    "        lr : float\n",
    "            Learning rate\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        # 1. Define loss function (nn.CrossEntropyLoss)\n",
    "        # 2. Define optimizer (optim.Adam or optim.SGD)\n",
    "        # 3. Training loop:\n",
    "        #    - Iterate through batches\n",
    "        #    - Forward pass\n",
    "        #    - Compute loss\n",
    "        #    - Backward pass\n",
    "        #    - Update weights\n",
    "        # 4. Validation after each epoch\n",
    "        # 5. Track and return metrics\n",
    "        pass\n",
    "    \n",
    "    print(\"Training function ready!\")\n",
    "    print(\"Next: Load CIFAR-10 and train the model\")\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"Write the training loop even if you can't run it.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercise 10: Debug Broken CNN Training\n",
    "\n",
    "**Objective:** Develop debugging skills for CNNs.\n",
    "\n",
    "### Task 10.1: Find and Fix the Bugs\n",
    "\n",
    "The following CNN training code has **5 bugs**. Find and fix them!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BUGGY CODE - DO NOT TRUST!\n",
    "\n",
    "class BuggyCNN:\n",
    "    \"\"\"A CNN with bugs to fix.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # BUG #1: Wrong shapes somewhere here?\n",
    "        self.conv1_filters = np.random.randn(32, 3, 3, 3) * 0.01\n",
    "        self.conv1_bias = np.zeros(32)\n",
    "        \n",
    "        self.conv2_filters = np.random.randn(64, 32, 3, 3) * 0.01\n",
    "        self.conv2_bias = np.zeros(64)\n",
    "        \n",
    "        # After two pooling layers (2x2), 32x32 -> 8x8\n",
    "        self.fc_weights = np.random.randn(64 * 8 * 8, 10) * 0.01\n",
    "        self.fc_bias = np.zeros(10)\n",
    "    \n",
    "    def conv2d(self, input_data, filters, bias, stride=1, padding=0):\n",
    "        \"\"\"Convolution operation.\"\"\"\n",
    "        batch, in_channels, height, width = input_data.shape\n",
    "        n_filters, _, kernel_size, _ = filters.shape\n",
    "        \n",
    "        # BUG #2: Is this padding calculation correct?\n",
    "        if padding > 0:\n",
    "            input_data = np.pad(input_data, \n",
    "                              ((0, 0), (0, 0), (padding, padding), (padding, padding)),\n",
    "                              mode='constant')\n",
    "        \n",
    "        out_height = (height - kernel_size + 2 * padding) // stride + 1\n",
    "        out_width = (width - kernel_size + 2 * padding) // stride + 1\n",
    "        \n",
    "        output = np.zeros((batch, n_filters, out_height, out_width))\n",
    "        \n",
    "        # Simple convolution (slow but correct)\n",
    "        for b in range(batch):\n",
    "            for f in range(n_filters):\n",
    "                for i in range(out_height):\n",
    "                    for j in range(out_width):\n",
    "                        h_start = i * stride\n",
    "                        h_end = h_start + kernel_size\n",
    "                        w_start = j * stride\n",
    "                        w_end = w_start + kernel_size\n",
    "                        \n",
    "                        receptive_field = input_data[b, :, h_start:h_end, w_start:w_end]\n",
    "                        output[b, f, i, j] = np.sum(receptive_field * filters[f]) + bias[f]\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    def max_pool(self, input_data, pool_size=2, stride=2):\n",
    "        \"\"\"Max pooling operation.\"\"\"\n",
    "        batch, channels, height, width = input_data.shape\n",
    "        \n",
    "        # BUG #3: Check this calculation\n",
    "        out_height = height / pool_size  # Integer division?\n",
    "        out_width = width / pool_size\n",
    "        \n",
    "        output = np.zeros((batch, channels, int(out_height), int(out_width)))\n",
    "        \n",
    "        for b in range(batch):\n",
    "            for c in range(channels):\n",
    "                for i in range(int(out_height)):\n",
    "                    for j in range(int(out_width)):\n",
    "                        h_start = i * stride\n",
    "                        h_end = h_start + pool_size\n",
    "                        w_start = j * stride\n",
    "                        w_end = w_start + pool_size\n",
    "                        \n",
    "                        pool_region = input_data[b, c, h_start:h_end, w_start:w_end]\n",
    "                        output[b, c, i, j] = np.max(pool_region)\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward pass.\"\"\"\n",
    "        # Conv1 -> ReLU -> Pool\n",
    "        x = self.conv2d(x, self.conv1_filters, self.conv1_bias, padding=1)\n",
    "        x = np.maximum(0, x)  # ReLU\n",
    "        x = self.max_pool(x)\n",
    "        \n",
    "        # Conv2 -> ReLU -> Pool\n",
    "        x = self.conv2d(x, self.conv2_filters, self.conv2_bias, padding=1)\n",
    "        x = np.maximum(0, x)  # ReLU\n",
    "        x = self.max_pool(x)\n",
    "        \n",
    "        # BUG #4: Flattening - is this right?\n",
    "        batch_size = x.shape[0]\n",
    "        x = x.reshape(batch_size, -1)\n",
    "        \n",
    "        # Fully connected\n",
    "        x = x @ self.fc_weights + self.fc_bias\n",
    "        \n",
    "        # BUG #5: Should we apply softmax here?\n",
    "        # Softmax for probabilities\n",
    "        exp_x = np.exp(x)\n",
    "        return exp_x / np.sum(exp_x, axis=1, keepdims=True)\n",
    "\n",
    "# Test the buggy model\n",
    "print(\"Testing buggy CNN...\")\n",
    "print(\"If this crashes or produces wrong shapes, you found bugs!\")\n",
    "print()\n",
    "\n",
    "try:\n",
    "    buggy_model = BuggyCNN()\n",
    "    test_input = np.random.randn(2, 3, 32, 32)  # 2 images, RGB, 32x32\n",
    "    output = buggy_model.forward(test_input)\n",
    "    print(f\"Input shape: {test_input.shape}\")\n",
    "    print(f\"Output shape: {output.shape}\")\n",
    "    print(f\"Expected output shape: (2, 10)\")\n",
    "    print(f\"Shape correct: {output.shape == (2, 10)}\")\n",
    "    print()\n",
    "    print(\"Even if shapes are correct, there may be subtle bugs!\")\n",
    "    print(\"Check the code carefully.\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error: {e}\")\n",
    "    print(\"This error is a clue to one of the bugs!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><b>üí° Hints (Click to expand)</b></summary>\n",
    "\n",
    "**Bug #1:** Check filter initialization shapes. Should match (out_channels, in_channels, height, width)\n",
    "\n",
    "**Bug #2:** The padding is applied but then used in the dimension calculation again - double counting?\n",
    "\n",
    "**Bug #3:** Should use integer division (//), not float division (/)\n",
    "\n",
    "**Bug #4:** Actually, the flattening looks correct. Or is it?\n",
    "\n",
    "**Bug #5:** Applying softmax in the forward pass can cause numerical issues with some loss functions. Usually better to keep logits and combine softmax with loss.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 10.2: Write Tests\n",
    "\n",
    "Write unit tests to catch these bugs automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_conv_output_shape():\n",
    "    \"\"\"Test that convolution produces correct output shape.\"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    pass\n",
    "\n",
    "def test_pool_output_shape():\n",
    "    \"\"\"Test that pooling produces correct output shape.\"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    pass\n",
    "\n",
    "def test_gradient_flow():\n",
    "    \"\"\"Test that gradients can flow through the network.\"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    pass\n",
    "\n",
    "# Run tests\n",
    "# test_conv_output_shape()\n",
    "# test_pool_output_shape()\n",
    "# test_gradient_flow()\n",
    "# print(\"All tests passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Reflection Questions\n",
    "\n",
    "After completing these exercises, reflect on your learning:\n",
    "\n",
    "1. **What's the most important insight you gained about how CNNs work?**\n",
    "   \n",
    "   *Your answer:*\n",
    "\n",
    "2. **How do CNNs differ from fully-connected networks beyond just using convolution?**\n",
    "   \n",
    "   *Your answer:*\n",
    "\n",
    "3. **What challenges did you face implementing convolution from scratch?**\n",
    "   \n",
    "   *Your answer:*\n",
    "\n",
    "4. **When would you use transfer learning vs training from scratch?**\n",
    "   \n",
    "   *Your answer:*\n",
    "\n",
    "5. **What CNN architecture would you design for your own project?**\n",
    "   \n",
    "   *Your answer:*\n",
    "\n",
    "---\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "Congratulations on completing the CNN exercises! Here are some suggestions:\n",
    "\n",
    "1. üìö **Review** the solutions in `solutions.ipynb`\n",
    "2. üî¨ **Experiment** with different architectures and hyperparameters\n",
    "3. üèóÔ∏è **Build** a CNN project on a dataset you care about\n",
    "4. üìñ **Study** advanced architectures (ResNet, DenseNet, EfficientNet)\n",
    "5. üéØ **Try** other computer vision tasks (object detection, segmentation)\n",
    "6. ü§ù **Share** what you've learned\n",
    "\n",
    "### Recommended Projects\n",
    "\n",
    "- **Image Classification:** Build a classifier for a custom dataset\n",
    "- **Style Transfer:** Implement neural style transfer\n",
    "- **Object Detection:** Learn YOLO or Faster R-CNN\n",
    "- **Semantic Segmentation:** Try U-Net or Mask R-CNN\n",
    "- **Generative Models:** Explore GANs or Diffusion Models\n",
    "\n",
    "### Additional Resources\n",
    "\n",
    "- **Papers:** AlexNet, VGGNet, ResNet, Inception, EfficientNet\n",
    "- **Courses:** Stanford CS231n, Fast.ai\n",
    "- **Datasets:** CIFAR-10/100, ImageNet, COCO, Open Images\n",
    "- **Competitions:** Kaggle computer vision challenges\n",
    "\n",
    "Keep learning and building! üöÄ\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
