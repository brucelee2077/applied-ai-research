# Quantization

## Overview
Content to be added: Reducing model precision for faster inference.

## Key Concepts
- INT8 quantization
- INT4 quantization
- Post-training quantization
- Quantization-aware training

## Further Reading
- LLM.int8() (Dettmers et al., 2022)
