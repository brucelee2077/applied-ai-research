# üìö Resources

Curated collection of external resources for learning Large Language Model engineering, from foundational concepts to advanced techniques.

## Overview

This page provides links to high-quality learning materials, including courses, tutorials, papers, tools, and communities that complement the content in this repository.

---

## üìñ Courses & Tutorials

### Neural Networks & Deep Learning

**Free Courses:**
- [Deep Learning Specialization](https://www.coursera.org/specializations/deep-learning) by Andrew Ng (Coursera)
- [Neural Networks and Deep Learning](http://neuralnetworksanddeeplearning.com/) by Michael Nielsen
- [MIT 6.S191: Introduction to Deep Learning](http://introtodeeplearning.com/)
- [Fast.ai Practical Deep Learning](https://course.fast.ai/)
- [Stanford CS231n: CNNs for Visual Recognition](http://cs231n.stanford.edu/)
- [Stanford CS224n: NLP with Deep Learning](http://web.stanford.edu/class/cs224n/)

**Paid Courses:**
- [Deep Learning Nanodegree](https://www.udacity.com/course/deep-learning-nanodegree--nd101) (Udacity)
- [TensorFlow Developer Certificate](https://www.tensorflow.org/certificate) (TensorFlow)

### Large Language Models

**Courses:**
- [Hugging Face NLP Course](https://huggingface.co/learn/nlp-course/chapter1/1) (Free)
- [LLM University](https://docs.cohere.com/docs/llmu) by Cohere (Free)
- [Full Stack LLM Bootcamp](https://fullstackdeeplearning.com/llm-bootcamp/) (Free)
- [ChatGPT Prompt Engineering for Developers](https://www.deeplearning.ai/short-courses/chatgpt-prompt-engineering-for-developers/) by DeepLearning.AI

**YouTube Channels:**
- [Andrej Karpathy](https://www.youtube.com/@AndrejKarpathy)
- [StatQuest](https://www.youtube.com/@statquest)
- [3Blue1Brown](https://www.youtube.com/@3blue1brown)
- [Two Minute Papers](https://www.youtube.com/@TwoMinutePapers)

---

## üìÑ Books

### Foundational

**Free Online:**
- [Deep Learning](https://www.deeplearningbook.org/) by Goodfellow, Bengio, and Courville
- [Dive into Deep Learning](https://d2l.ai/) by Zhang et al.
- [Neural Networks and Deep Learning](http://neuralnetworksanddeeplearning.com/) by Michael Nielsen

**Paid:**
- "Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow" by Aur√©lien G√©ron
- "Deep Learning with Python" by Fran√ßois Chollet
- "Pattern Recognition and Machine Learning" by Christopher Bishop

### NLP & LLMs

- [Speech and Language Processing](https://web.stanford.edu/~jurafsky/slp3/) by Jurafsky and Martin (Free)
- "Natural Language Processing with Transformers" by Lewis Tunstall et al.
- "Build a Large Language Model (From Scratch)" by Sebastian Raschka

---

## üìù Key Papers

### Foundational Papers

**Neural Networks:**
- [Backpropagation](http://www.iro.umontreal.ca/~vincentp/ift3395/lectures/backprop_old.pdf) - Rumelhart et al., 1986
- [ImageNet Classification with Deep CNNs](https://papers.nips.cc/paper/2012/hash/c399862d3b9d6b76c8436e924a68c45b-Abstract.html) (AlexNet) - Krizhevsky et al., 2012
- [Deep Residual Learning](https://arxiv.org/abs/1512.03385) (ResNet) - He et al., 2015

**RNNs & LSTMs:**
- [Long Short-Term Memory](https://www.bioinf.jku.at/publications/older/2604.pdf) - Hochreiter & Schmidhuber, 1997
- [Sequence to Sequence Learning](https://arxiv.org/abs/1409.3215) - Sutskever et al., 2014

**Transformers:**
- [Attention Is All You Need](https://arxiv.org/abs/1706.03762) - Vaswani et al., 2017 ‚≠ê
- [BERT: Pre-training of Deep Bidirectional Transformers](https://arxiv.org/abs/1810.04805) - Devlin et al., 2018
- [GPT-3: Language Models are Few-Shot Learners](https://arxiv.org/abs/2005.14165) - Brown et al., 2020

**Fine-Tuning:**
- [LoRA: Low-Rank Adaptation](https://arxiv.org/abs/2106.09685) - Hu et al., 2021
- [QLoRA: Efficient Finetuning of Quantized LLMs](https://arxiv.org/abs/2305.14314) - Dettmers et al., 2023

**RAG:**
- [Retrieval-Augmented Generation](https://arxiv.org/abs/2005.11401) - Lewis et al., 2020
- [In-Context Retrieval-Augmented Language Models](https://arxiv.org/abs/2302.00083) - Ram et al., 2023

**Prompt Engineering:**
- [Chain-of-Thought Prompting](https://arxiv.org/abs/2201.11903) - Wei et al., 2022
- [Self-Consistency Improves Chain of Thought](https://arxiv.org/abs/2203.11171) - Wang et al., 2022

### Paper Repositories

- [Papers With Code](https://paperswithcode.com/)
- [arXiv.org](https://arxiv.org/) - CS section
- [Hugging Face Papers](https://huggingface.co/papers)
- [Google Scholar](https://scholar.google.com/)

---

## üõ†Ô∏è Tools & Libraries

### Deep Learning Frameworks

**Core Frameworks:**
- [PyTorch](https://pytorch.org/) - Primary DL framework
- [TensorFlow](https://www.tensorflow.org/) - Google's DL framework
- [JAX](https://github.com/google/jax) - High-performance numerical computing

**Transformers:**
- [Hugging Face Transformers](https://huggingface.co/docs/transformers) ‚≠ê
- [Hugging Face Datasets](https://huggingface.co/docs/datasets)
- [Hugging Face PEFT](https://huggingface.co/docs/peft)

### LLM Development

**Frameworks:**
- [LangChain](https://python.langchain.com/) - LLM application framework
- [LlamaIndex](https://www.llamaindex.ai/) - Data framework for LLMs
- [Haystack](https://haystack.deepset.ai/) - NLP framework

**Fine-Tuning:**
- [Axolotl](https://github.com/OpenAccess-AI-Collective/axolotl)
- [PEFT](https://github.com/huggingface/peft)
- [TRL (Transformer Reinforcement Learning)](https://github.com/huggingface/trl)

### Vector Databases

- [Pinecone](https://www.pinecone.io/)
- [Weaviate](https://weaviate.io/)
- [Chroma](https://www.trychroma.com/)
- [FAISS](https://github.com/facebookresearch/faiss)
- [Milvus](https://milvus.io/)

### Deployment & Optimization

- [vLLM](https://github.com/vllm-project/vllm) - Fast LLM inference
- [TensorRT](https://developer.nvidia.com/tensorrt)
- [ONNX Runtime](https://onnxruntime.ai/)
- [BentoML](https://www.bentoml.com/)

### Experiment Tracking

- [Weights & Biases](https://wandb.ai/) ‚≠ê
- [MLflow](https://mlflow.org/)
- [TensorBoard](https://www.tensorflow.org/tensorboard)
- [Neptune.ai](https://neptune.ai/)

### Data & Preprocessing

- [Pandas](https://pandas.pydata.org/)
- [Datasets (Hugging Face)](https://huggingface.co/docs/datasets)
- [DVC (Data Version Control)](https://dvc.org/)
- [Great Expectations](https://greatexpectations.io/)

---

## üíª Development Tools

### IDEs & Notebooks

- [Jupyter Lab](https://jupyter.org/)
- [Google Colab](https://colab.research.google.com/) - Free GPU access
- [VS Code](https://code.visualstudio.com/)
- [PyCharm](https://www.jetbrains.com/pycharm/)

### Compute Resources

**Free/Freemium:**
- [Google Colab](https://colab.research.google.com/) - Free GPU/TPU
- [Kaggle Notebooks](https://www.kaggle.com/code) - Free GPU
- [Lightning AI](https://lightning.ai/) - Free tier

**Paid:**
- [Paperspace Gradient](https://www.paperspace.com/)
- [Lambda Labs](https://lambdalabs.com/)
- [RunPod](https://www.runpod.io/)
- [Vast.ai](https://vast.ai/)

**Cloud Providers:**
- [AWS SageMaker](https://aws.amazon.com/sagemaker/)
- [Google Cloud AI Platform](https://cloud.google.com/ai-platform)
- [Azure Machine Learning](https://azure.microsoft.com/en-us/services/machine-learning/)

---

## üåê Communities

### Forums & Discussion

- [r/MachineLearning](https://www.reddit.com/r/MachineLearning/) (Reddit)
- [r/LanguageTechnology](https://www.reddit.com/r/LanguageTechnology/) (Reddit)
- [Hugging Face Forums](https://discuss.huggingface.co/)
- [PyTorch Forums](https://discuss.pytorch.org/)
- [Stack Overflow](https://stackoverflow.com/questions/tagged/deep-learning)

### Social Media

- [ML Twitter Community](https://twitter.com/i/communities/1707456668224147897)
- [LinkedIn AI Groups](https://www.linkedin.com/)
- [Discord Servers](https://discord.com/) - Various ML/AI communities

### Conferences

- [NeurIPS](https://neurips.cc/)
- [ICML](https://icml.cc/)
- [ICLR](https://iclr.cc/)
- [ACL](https://www.aclweb.org/)
- [EMNLP](https://2024.emnlp.org/)

---

## üì∞ Blogs & Newsletters

### Technical Blogs

- [The Batch](https://www.deeplearning.ai/the-batch/) by DeepLearning.AI
- [Hugging Face Blog](https://huggingface.co/blog)
- [OpenAI Blog](https://openai.com/blog/)
- [Google AI Blog](https://ai.googleblog.com/)
- [Meta AI Blog](https://ai.meta.com/blog/)
- [Anthropic Research](https://www.anthropic.com/research)

### Individual Blogs

- [Jay Alammar's Blog](https://jalammar.github.io/) - Visual explanations
- [Lil'Log](https://lilianweng.github.io/) by Lilian Weng
- [Sebastian Ruder's Blog](https://ruder.io/)
- [Distill.pub](https://distill.pub/) - Interactive ML explanations

### Newsletters

- [The Batch](https://www.deeplearning.ai/the-batch/)
- [Import AI](https://jack-clark.net/)
- [TLDR AI](https://tldr.tech/ai)
- [Papers with Code Newsletter](https://paperswithcode.com/)

---

## üéì Academic Resources

### Lecture Notes

- [Stanford CS229: Machine Learning](http://cs229.stanford.edu/)
- [Stanford CS231n: CNNs](http://cs231n.stanford.edu/)
- [Stanford CS224n: NLP](http://web.stanford.edu/class/cs224n/)
- [MIT 6.S191: Deep Learning](http://introtodeeplearning.com/)
- [Berkeley CS182: Deep Learning](https://cs182sp21.github.io/)

### Research Groups

- [Stanford NLP Group](https://nlp.stanford.edu/)
- [MIT CSAIL](https://www.csail.mit.edu/)
- [Berkeley AI Research](https://bair.berkeley.edu/)
- [CMU Language Technologies Institute](https://www.lti.cs.cmu.edu/)

---

## üóÇÔ∏è Datasets

### General NLP

- [The Pile](https://pile.eleuther.ai/)
- [C4 (Colossal Clean Crawled Corpus)](https://www.tensorflow.org/datasets/catalog/c4)
- [Common Crawl](https://commoncrawl.org/)

### Task-Specific

- [GLUE Benchmark](https://gluebenchmark.com/)
- [SuperGLUE](https://super.gluebenchmark.com/)
- [SQuAD](https://rajpurkar.github.io/SQuAD-explorer/)
- [MS MARCO](https://microsoft.github.io/msmarco/)

### Dataset Repositories

- [Hugging Face Datasets](https://huggingface.co/datasets)
- [Papers With Code Datasets](https://paperswithcode.com/datasets)
- [Google Dataset Search](https://datasetsearch.research.google.com/)
- [Kaggle Datasets](https://www.kaggle.com/datasets)

---

## üé• Video Content

### Playlists & Series

- [Neural Networks by 3Blue1Brown](https://www.youtube.com/playlist?list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi)
- [Stanford CS231n Lectures](https://www.youtube.com/playlist?list=PL3FW7Lu3i5JvHM8ljYj-zLfQRF3EO8sYv)
- [Andrej Karpathy's Neural Networks Course](https://www.youtube.com/playlist?list=PLAqhIrjkxbuWI23v9cThsA9GvCAUhRvKZ)

### Conference Talks

- [NeurIPS Videos](https://nips.cc/)
- [ICML Videos](https://icml.cc/)
- [Talks at Google](https://www.youtube.com/user/AtGoogleTalks)

---

## üîç Additional Resources

### Visualization Tools

- [TensorFlow Playground](https://playground.tensorflow.org/)
- [ConvNetJS](https://cs.stanford.edu/people/karpathy/convnetjs/)
- [Netron](https://netron.app/) - Model visualizer

### Cheat Sheets

- [ML Cheat Sheet](https://ml-cheatsheet.readthedocs.io/)
- [Stanford CS229 Cheat Sheets](https://stanford.edu/~shervine/teaching/cs-229/)
- [PyTorch Cheat Sheet](https://pytorch.org/tutorials/beginner/ptcheat.html)

---

## üåü Recommended Learning Path

1. **Foundation** ‚Üí Start with Deep Learning Specialization + Neural Networks book
2. **Implementation** ‚Üí Work through Fast.ai + Dive into Deep Learning
3. **Specialization** ‚Üí CS224n for NLP + Hugging Face course
4. **Advanced** ‚Üí Read key papers + implement from scratch
5. **Production** ‚Üí Full Stack Deep Learning + deployment tools
6. **Stay Current** ‚Üí Follow blogs, papers, conferences

---

## üìå Contributing

Found a valuable resource not listed here? Please:
1. Check if it fits the categories above
2. Verify the resource is high-quality and accessible
3. Submit a pull request with the addition
4. Include a brief description

---

*This resource list is continuously updated. Star ‚≠ê resources are particularly recommended for beginners.*